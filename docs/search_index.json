[
["index.html", "WISG Module 4: Computational Pipeline for WGS Data 1 Introduction 1.1 Schedule 1.2 Software requirements 1.3 Resources", " WISG Module 4: Computational Pipeline for WGS Data 2019-01-08 1 Introduction This site contains course materials for WISG Module 4: Computational Pipeline for WGS Data, January 23-24, 2019. Data used is located in the github repository from which the site is built, as well as in the TOPMed analysis pipeline. 1.1 Schedule Lecture slides Wednesday, January 23 Introduction Sequencing and data formats Sequencing overview Sequencing data formats Intro to Genomic Data Storage Exercises Association tests Methods and motivation (Parts 1-2) GENESIS for association tests Exercises Aggregate tests (Part 3) Exercises Thursday, January 24 Population structure and relatedness Population structure inference Relatedness inference R packages for PCA and relatedness Exercises Mixed model association testing Exercises Variant annotation Exercises Analysis pipeline on the cloud 1.2 Software requirements R 3.5.1 R packages SeqArray SeqVarTools GENESIS SNPRelate TopmedPipeline dplyr ggplot2 GGally survey CompQuadForm TxDb.Hsapiens.UCSC.hg19.knownGene Installation instructions install.packages(c(&quot;BiocManager&quot;, &quot;remotes&quot;), repos=&quot;https://cloud.r-project.org&quot;) BiocManager::install(c(&quot;SeqArray&quot;, &quot;SeqVarTools&quot;, &quot;SNPRelate&quot;, &quot;GENESIS&quot;, &quot;survey&quot;, &quot;CompQuadForm&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;, &quot;GGally&quot;, &quot;TxDb.Hsapiens.UCSC.hg19.knownGene&quot;)) remotes::install_github(&quot;UW-GAC/analysis_pipeline/TopmedPipeline&quot;) Download the workshop data and exercises: https://github.com/UW-GAC/WISG_2019/archive/master.zip 1.3 Resources If you are new to R, you might find the following material helpful: Graphics with ggplot2 tutorial Data manipulation with dplyr "],
["gds-format.html", "2 GDS format 2.1 Exploring a GDS file 2.2 Exercises", " 2 GDS format GDS is Genomic Data Structure, a storage format that can efficiently store genomic data and provide fast random access to subsets of the data. For more information on GDS for sequence data, read the SeqArray package vignette. 2.1 Exploring a GDS file To use the R packages developed at the University of Washington for sequence data, we first need to convert a VCF file to GDS. (If the file is BCF, use https://samtools.github.io/bcftools/bcftools.html to convert to VCF.) library(SeqArray) vcffile &lt;- &quot;data/1KG_phase3_subset_chr1.vcf.gz&quot; gdsfile &lt;- &quot;1KG_phase3_subset_chr1.gds&quot; seqVCF2GDS(vcffile, gdsfile, fmt.import=&quot;GT&quot;, storage.option=&quot;LZMA_RA&quot;, verbose=FALSE) We can interact with the GDS file using the SeqArray package. gds &lt;- seqOpen(gdsfile) gds ## Object of class &quot;SeqVarGDSClass&quot; ## File: /Users/stephanie/WISG_2019/WISG_2019/1KG_phase3_subset_chr1.gds (70.6K) ## + [ ] * ## |--+ description [ ] * ## |--+ sample.id { Str8 1126 LZMA_ra(9.66%), 877B } * ## |--+ variant.id { Int32 1120 LZMA_ra(17.5%), 793B } * ## |--+ position { Int32 1120 LZMA_ra(78.5%), 3.4K } * ## |--+ chromosome { Str8 1120 LZMA_ra(4.55%), 109B } * ## |--+ allele { Str8 1120 LZMA_ra(26.0%), 1.2K } * ## |--+ genotype [ ] * ## | |--+ data { Bit2 2x1126x1121 LZMA_ra(8.34%), 51.4K } * ## | |--+ extra.index { Int32 3x0 LZMA_ra, 18B } * ## | \\--+ extra { Int16 0 LZMA_ra, 18B } ## |--+ phase [ ] ## | |--+ data { Bit1 1126x1120 LZMA_ra(0.11%), 177B } * ## | |--+ extra.index { Int32 3x0 LZMA_ra, 18B } * ## | \\--+ extra { Bit1 0 LZMA_ra, 18B } ## |--+ annotation [ ] ## | |--+ id { Str8 1120 LZMA_ra(40.4%), 3.6K } * ## | |--+ qual { Float32 1120 LZMA_ra(2.46%), 117B } * ## | |--+ filter { Int32,factor 1120 LZMA_ra(2.46%), 117B } * ## | |--+ info [ ] ## | \\--+ format [ ] ## \\--+ sample.annotation [ ] # the unique sample identifier comes from the VCF header sample.id &lt;- seqGetData(gds, &quot;sample.id&quot;) length(sample.id) ## [1] 1126 head(sample.id) ## [1] &quot;HG00096&quot; &quot;HG00097&quot; &quot;HG00099&quot; &quot;HG00100&quot; &quot;HG00101&quot; &quot;HG00102&quot; # a unique integer ID is assigned to each variant variant.id &lt;- seqGetData(gds, &quot;variant.id&quot;) length(variant.id) ## [1] 1120 head(variant.id) ## [1] 1 2 3 4 5 6 # reference allele frequency of each variant afreq &lt;- seqAlleleFreq(gds) hist(afreq, breaks=50) We can define a filter on the gds object. After using the seqSetFilter command, all subsequent reads from the gds object are restricted to the selected subset of data, until a new filter is defined or seqResetFilter is called. seqSetFilter(gds, variant.id=1:10, sample.id=sample.id[1:5]) ## # of selected samples: 5 ## # of selected variants: 10 Genotype data is stored in a 3-dimensional array, where the first dimension is always 2 for diploid genotypes. The second and third dimensions are samples and variants, respectively. The values of the array denote alleles: 0 is the reference allele and 1 is the alternate allele. For multiallelic variants, other alternate alleles are represented as integers &gt; 1. geno &lt;- seqGetData(gds, &quot;genotype&quot;) dim(geno) ## [1] 2 5 10 geno[,,1:2] ## , , 1 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 2 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 The SeqVarTools package has some additional functions for interacting with SeqArray-format GDS files. library(SeqVarTools) # return genotypes in matrix format getGenotype(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00097 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00099 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00100 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00101 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; getGenotypeAlleles(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00097 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00099 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00100 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00101 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; refDosage(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 2 2 2 2 2 2 2 2 2 2 ## HG00097 2 2 2 2 2 2 2 2 2 2 ## HG00099 2 2 2 2 2 2 2 2 2 2 ## HG00100 2 2 2 2 2 2 2 2 2 2 ## HG00101 2 2 2 2 2 2 2 2 2 2 altDosage(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 0 0 0 0 0 0 0 0 0 0 ## HG00097 0 0 0 0 0 0 0 0 0 0 ## HG00099 0 0 0 0 0 0 0 0 0 0 ## HG00100 0 0 0 0 0 0 0 0 0 0 ## HG00101 0 0 0 0 0 0 0 0 0 0 # look at reference and alternate alleles refChar(gds) ## [1] &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;T&quot; &quot;G&quot; &quot;G&quot; &quot;A&quot; &quot;A&quot; &quot;C&quot; altChar(gds) ## [1] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;C&quot; &quot;A&quot; &quot;A&quot; &quot;T&quot; &quot;C&quot; &quot;T&quot; # data.frame of variant information variantInfo(gds) ## variant.id chr pos ref alt ## 1 1 1 970546 C G ## 2 2 1 985900 C T ## 3 3 1 1025045 C T ## 4 4 1 1265550 C T ## 5 5 1 1472676 T C ## 6 6 1 1735725 G A ## 7 7 1 2185887 G A ## 8 8 1 2283689 A T ## 9 9 1 2629401 A C ## 10 10 1 2710895 C T # reset the filter to all variants and samples seqResetFilter(gds) ## # of selected samples: 1,126 ## # of selected variants: 1,120 # how many alleles for each variant? n &lt;- seqNumAllele(gds) table(n) ## n ## 2 3 4 ## 1099 20 1 # some variants have more than one alternate allele multi.allelic &lt;- which(n &gt; 2) altChar(gds)[multi.allelic] ## [1] &quot;GT,G&quot; &quot;G,T&quot; &quot;A,T&quot; ## [4] &quot;A,T&quot; &quot;ATG,ATGTG&quot; &quot;C,G&quot; ## [7] &quot;A,T&quot; &quot;C,T&quot; &quot;A,C&quot; ## [10] &quot;TAA,T&quot; &quot;GTTA,GTTT&quot; &quot;GCC,GCCC,G&quot; ## [13] &quot;A,C&quot; &quot;A,C&quot; &quot;A,C&quot; ## [16] &quot;CAAGCAT,CGAGCAT&quot; &quot;CATTATT,C&quot; &quot;AT,C&quot; ## [19] &quot;TGTGA,C&quot; &quot;CCATT,CCATTCATT&quot; &quot;C,G&quot; # extract a particular alternate allele # first alternate altChar(gds, n=1)[multi.allelic] ## [1] &quot;GT&quot; &quot;G&quot; &quot;A&quot; &quot;A&quot; &quot;ATG&quot; &quot;C&quot; &quot;A&quot; ## [8] &quot;C&quot; &quot;A&quot; &quot;TAA&quot; &quot;GTTA&quot; &quot;GCC&quot; &quot;A&quot; &quot;A&quot; ## [15] &quot;A&quot; &quot;CAAGCAT&quot; &quot;CATTATT&quot; &quot;AT&quot; &quot;TGTGA&quot; &quot;CCATT&quot; &quot;C&quot; # second alternate altChar(gds, n=2)[multi.allelic] ## [1] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;ATGTG&quot; ## [6] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;C&quot; &quot;T&quot; ## [11] &quot;GTTT&quot; &quot;GCCC&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ## [16] &quot;CGAGCAT&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;CCATTCATT&quot; ## [21] &quot;G&quot; # how many variants are SNVs vs INDELs? table(isSNV(gds, biallelic=TRUE)) ## ## FALSE TRUE ## 110 1010 table(isSNV(gds, biallelic=FALSE)) ## ## FALSE TRUE ## 99 1021 # 11 SNVs are multi-allelic We can also return variant information as a GRanges object from the GenomicRanges package. This format for representing sequence data is common across many Bioconductor packages. Chromosome is stored in the seqnames column. The ranges column has variant position, which can be a single base pair or a range. gr &lt;- granges(gds) gr ## GRanges object with 1120 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## 1 1 970546 * ## 2 1 985900 * ## 3 1 1025045 * ## 4 1 1265550 * ## 5 1 1472676 * ## ... ... ... ... ## 1116 1 248715186 * ## 1117 1 248715606-248715610 * ## 1118 1 248761613 * ## 1119 1 248894546 * ## 1120 1 249149558 * ## ------- ## seqinfo: 1 sequence from an unspecified genome; no seqlengths 2.2 Exercises Set a filter selecting only multi-allelic variants. Inspect their genotypes using the different methods you learned above. Use the alleleDosage method to find dosage for the second (and third, etc.) alternate allele. Use the hwe function in SeqVarTools to run a Hardy-Weinberg Equilibrium test on each variant. Identify a variant with low p-value and inspect its genotypes. (Note that the HWE test is only valid for biallelic variants, and will return NA for multiallelic variants.) "],
["gds-solutions.html", "3 GDS - Solutions", " 3 GDS - Solutions Set a filter selecting only multi-allelic variants. Inspect their genotypes using the different methods you learned above. Use the alleleDosage method to find dosage for the second (and third, etc.) alternate allele. seqSetFilter(gds, variant.sel=multi.allelic) ## # of selected variants: 21 geno &lt;- seqGetData(gds, &quot;genotype&quot;) dim(geno) ## [1] 2 1126 21 geno[,1:5,] ## , , 1 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 1 1 0 1 1 ## [2,] 0 1 1 1 1 ## ## , , 2 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 3 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 4 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 1 0 0 1 0 ## [2,] 0 0 0 0 1 ## ## , , 5 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 6 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 7 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 8 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 9 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 2 ## [2,] 0 0 0 0 0 ## ## , , 10 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 0 0 1 ## [2,] 0 2 0 2 1 ## ## , , 11 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 1 0 0 ## [2,] 1 1 0 1 0 ## ## , , 12 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 1 1 3 ## [2,] 3 3 3 1 0 ## ## , , 13 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 2 0 ## [2,] 0 0 0 0 0 ## ## , , 14 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 15 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 2 0 0 0 2 ## [2,] 0 0 0 2 0 ## ## , , 16 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 2 2 2 2 2 ## [2,] 2 2 2 2 2 ## ## , , 17 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 2 2 2 2 2 ## [2,] 2 2 2 2 2 ## ## , , 18 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 19 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 20 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 1 ## [2,] 0 0 0 0 0 ## ## , , 21 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 2 0 geno &lt;- getGenotype(gds) dim(geno) ## [1] 1126 21 head(geno) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 ## HG00096 &quot;1|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; ## HG00097 &quot;1|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; ## HG00099 &quot;0|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00100 &quot;1|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|2&quot; ## HG00101 &quot;1|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|0&quot; &quot;1|1&quot; ## HG00102 &quot;0|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; ## variant ## sample 434 610 627 645 689 756 765 814 988 1014 ## HG00096 &quot;0|1&quot; &quot;3|3&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|0&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00097 &quot;0|1&quot; &quot;1|3&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00099 &quot;1|0&quot; &quot;1|3&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00100 &quot;0|1&quot; &quot;1|1&quot; &quot;2|0&quot; &quot;0|0&quot; &quot;0|2&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00101 &quot;0|0&quot; &quot;3|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|0&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; ## HG00102 &quot;0|1&quot; &quot;3|3&quot; &quot;0|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; &quot;1|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|1&quot; ## variant ## sample 1056 ## HG00096 &quot;0|0&quot; ## HG00097 &quot;0|0&quot; ## HG00099 &quot;0|0&quot; ## HG00100 &quot;0|2&quot; ## HG00101 &quot;0|0&quot; ## HG00102 &quot;0|2&quot; geno &lt;- getGenotypeAlleles(gds) head(geno) ## variant ## sample 30 69 73 161 162 195 243 253 407 ## HG00096 &quot;GT|GTT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;A|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## HG00097 &quot;GT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## HG00099 &quot;GTT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## HG00100 &quot;GT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;A|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## HG00101 &quot;GT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;G|A&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;C|T&quot; ## HG00102 &quot;GTT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;A|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## variant ## sample 431 434 610 627 645 689 756 ## HG00096 &quot;TAA|TA&quot; &quot;G|GTTA&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;C|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00097 &quot;T|T&quot; &quot;G|GTTA&quot; &quot;GCC|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00099 &quot;TA|TA&quot; &quot;GTTA|G&quot; &quot;GCC|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00100 &quot;TA|T&quot; &quot;G|GTTA&quot; &quot;GCC|GCC&quot; &quot;C|G&quot; &quot;G|G&quot; &quot;G|C&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00101 &quot;TAA|TAA&quot; &quot;G|G&quot; &quot;G|GC&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;C|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00102 &quot;T|T&quot; &quot;G|GTTA&quot; &quot;G|G&quot; &quot;G|C&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## variant ## sample 765 814 988 1014 1056 ## HG00096 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|C&quot; &quot;A|A&quot; ## HG00097 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|C&quot; &quot;A|A&quot; ## HG00099 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|C&quot; &quot;A|A&quot; ## HG00100 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|C&quot; &quot;A|G&quot; ## HG00101 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;CCATT|C&quot; &quot;A|A&quot; ## HG00102 &quot;CATTATT|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|CCATT&quot; &quot;A|G&quot; dos &lt;- refDosage(gds) head(dos) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 434 610 627 645 689 756 765 ## HG00096 1 2 2 1 2 2 2 2 2 1 1 0 2 2 1 0 0 ## HG00097 0 2 2 2 2 2 2 2 2 0 1 0 2 2 2 0 0 ## HG00099 1 2 2 2 2 2 2 2 2 2 1 0 2 2 2 0 0 ## HG00100 0 2 2 1 2 2 2 2 2 1 1 0 1 2 1 0 0 ## HG00101 0 2 2 1 2 2 2 2 1 0 2 1 2 2 1 0 0 ## HG00102 1 2 2 1 2 2 2 2 2 0 1 0 1 2 2 0 0 ## variant ## sample 814 988 1014 1056 ## HG00096 2 2 2 2 ## HG00097 2 2 2 2 ## HG00099 2 2 2 2 ## HG00100 2 2 2 1 ## HG00101 2 2 1 2 ## HG00102 2 2 1 1 dos &lt;- altDosage(gds) head(dos) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 434 610 627 645 689 756 765 ## HG00096 1 0 0 1 0 0 0 0 0 1 1 2 0 0 1 2 2 ## HG00097 2 0 0 0 0 0 0 0 0 2 1 2 0 0 0 2 2 ## HG00099 1 0 0 0 0 0 0 0 0 0 1 2 0 0 0 2 2 ## HG00100 2 0 0 1 0 0 0 0 0 1 1 2 1 0 1 2 2 ## HG00101 2 0 0 1 0 0 0 0 1 2 0 1 0 0 1 2 2 ## HG00102 1 0 0 1 0 0 0 0 0 2 1 2 1 0 0 2 2 ## variant ## sample 814 988 1014 1056 ## HG00096 0 0 0 0 ## HG00097 0 0 0 0 ## HG00099 0 0 0 0 ## HG00100 0 0 0 1 ## HG00101 0 0 1 0 ## HG00102 0 0 1 1 dos &lt;- alleleDosage(gds, n=2) head(dos) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 434 610 627 645 689 756 765 ## HG00096 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 ## HG00097 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 2 ## HG00099 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 ## HG00100 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 2 2 ## HG00101 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 2 2 ## HG00102 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 2 1 ## variant ## sample 814 988 1014 1056 ## HG00096 0 0 0 0 ## HG00097 0 0 0 0 ## HG00099 0 0 0 0 ## HG00100 0 0 0 1 ## HG00101 0 0 0 0 ## HG00102 0 0 0 1 dos &lt;- alleleDosage(gds, n=3) head(dos) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 434 610 627 645 689 756 765 ## HG00096 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 ## HG00097 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ## HG00099 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ## HG00100 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## HG00101 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ## HG00102 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 ## variant ## sample 814 988 1014 1056 ## HG00096 0 0 0 0 ## HG00097 0 0 0 0 ## HG00099 0 0 0 0 ## HG00100 0 0 0 0 ## HG00101 0 0 0 0 ## HG00102 0 0 0 0 Use the hwe function in SeqVarTools to run a Hardy-Weinberg Equilibrium test on each variant. Identify a variant with low p-value and inspect its genotypes. (Note that the HWE test is only valid for biallelic variants, and will return NA for multiallelic variants.) seqResetFilter(gds) ## # of selected samples: 1,126 ## # of selected variants: 1,120 hwe.res &lt;- hwe(gds) lowp &lt;- !is.na(hwe.res$p) &amp; hwe.res$p &lt; 1e-4 head(hwe.res[lowp,]) ## variant.id nAA nAa naa afreq p f ## 75 75 702 336 88 0.7726465 1.070663e-06 0.1506466 ## 92 92 632 381 113 0.7304618 3.558878e-06 0.1407120 ## 98 98 672 335 119 0.7455595 2.369695e-12 0.2158342 ## 105 105 93 272 761 0.2033748 7.851777e-16 0.2544970 ## 114 114 299 482 345 0.4795737 1.745346e-06 0.1424409 ## 150 150 471 447 208 0.6167851 8.020208e-08 0.1602251 seqSetFilter(gds, variant.id=75) ## # of selected variants: 1 table(getGenotype(gds)) ## ## 0|0 0|1 1|0 1|1 ## 702 165 171 88 table(refDosage(gds)) ## ## 0 1 2 ## 88 336 702 seqClose(gds) "],
["association-tests.html", "4 Association tests 4.1 Null model 4.2 Single-variant tests 4.3 Exercises 4.4 Sliding window tests 4.5 Exercise", " 4 Association tests These exercises introduce association testing: how to find which genetic variants are associated with a phenotype. 4.1 Null model The first step in an association test is to fit the null model. We will need an AnnotatedDataFrame with phenotypes. This data structure is provided by the Bioconductor Biobase package, and it contains both the data and metadata (descriptions of each column in the data). # sample annotation sampfile &lt;- &quot;data/sample_phenotype_annotation.RData&quot; annot &lt;- TopmedPipeline::getobj(sampfile) library(Biobase) # access the data with the pData() function head(pData(annot)) ## sample.id subject.id Population Population.Description sex ## 1 HG00096 HG00096 GBR British in England and Scotland M ## 2 HG00097 HG00097 GBR British in England and Scotland F ## 3 HG00099 HG00099 GBR British in England and Scotland F ## 4 HG00100 HG00100 GBR British in England and Scotland F ## 5 HG00101 HG00101 GBR British in England and Scotland M ## 6 HG00102 HG00102 GBR British in England and Scotland F ## status age height study ## 1 0 47 165.300 study_1 ## 2 1 47 144.780 study_3 ## 3 0 40 185.500 study_2 ## 4 1 45 150.622 study_3 ## 5 0 40 177.800 study_3 ## 6 0 49 169.100 study_1 # access the metadata with the varMetadata() function varMetadata(annot) ## labelDescription ## sample.id sample identifier ## subject.id subject identifier ## Population population abbreviation ## Population.Description population description ## sex sex ## status simulated case/control status ## age age at measurement of height ## height subject&#39;s height in cm ## study study identifier We will test for an association between genotype and height, adjusting for sex, age, and study as covariates. First, examine the data to see if the height distribution varies by study. library(ggplot2) ggplot(pData(annot), aes(study, height)) + geom_boxplot() From the boxplot, it is clear that the different studies have different mean and variance for height. However, it is possible that this could be the result of different sex and age distributions in each study. To check this, we run a model that adjusts height for age and sex. library(GENESIS) mod_1 &lt;- fitNullModel(annot, outcome=&quot;height&quot;, covars=c(&quot;sex&quot;, &quot;age&quot;), verbose=FALSE) The output of fitNullModel is a list with a number of named elements names(mod_1) ## [1] &quot;family&quot; &quot;hetResid&quot; &quot;varComp&quot; &quot;varCompCov&quot; ## [5] &quot;fixef&quot; &quot;betaCov&quot; &quot;fitted.values&quot; &quot;resid.marginal&quot; ## [9] &quot;logLik&quot; &quot;AIC&quot; &quot;workingY&quot; &quot;outcome&quot; ## [13] &quot;model.matrix&quot; &quot;group.idx&quot; &quot;cholSigmaInv&quot; &quot;converged&quot; ## [17] &quot;zeroFLAG&quot; &quot;RSS&quot; &quot;Ytilde&quot; &quot;resid&quot; ## [21] &quot;CX&quot; &quot;CXCXI&quot; &quot;sample.id&quot; The elements that we will work with in this exercise are: converged: an indicator of whether the model successfully converged model.matrix: The matrix of subject-covariate values used to fit the model fixef: The fitted fixed effects betaCov: The covariance of the fitted fixed effects resid.marginal: The (marginal) residuals from the model, which have been adjusted for the fixed effects but not for the covariance structure varComp: The fitted variance component for each input covariance matrix Make sure the model converged. mod_1$converged ## [1] TRUE Now, add the residuals to the phenotype data frame for plotting. annot$residuals &lt;- mod_1$resid.marginal We want to check if the different studies have the same mean height after adjustment for other covariates (here, age and sex). We will first do this qualitatively by making a boxplot of the residuals by study. ggplot(pData(annot), aes(study, residuals)) + geom_boxplot() Height still has different variances in each study, even after adjusting for age and sex Therefore, we allow the model to use heterogeneous variance among studies with the parameter group.var. nullmod &lt;- fitNullModel(annot, outcome=&quot;height&quot;, covars=c(&quot;sex&quot;, &quot;age&quot;, &quot;study&quot;), group.var=&quot;study&quot;, verbose=FALSE) save(nullmod, file=&quot;null_model.RData&quot;) The fixef element now includes effects for study: nullmod$fixef ## Est SE Stat pval ## (Intercept) 163.67175933 3.18936046 2633.542254 0.000000e+00 ## sexM 6.28764510 0.68812251 83.491933 6.397652e-20 ## age 0.07519782 0.06921691 1.180283 2.772984e-01 ## studystudy_2 10.63152325 0.82176939 167.375183 2.769991e-38 ## studystudy_3 -8.96183691 0.84479021 112.537257 2.724960e-26 We can also check the variance components (varComp) in the model, which are different for each study: nullmod$varComp ## study_1 study_3 study_2 ## 98.20192 168.82045 155.70722 The fitted values of the variance components are different for the different studies, indicating that the distributions of height in the three studies have different variance even after accounting for the other covariates. We also recommend taking an inverse normal transform of the residuals and refitting the model. This is done separately for each group, and the transformed residuals are rescaled. See the full procedure in the pipeline documenation. 4.2 Single-variant tests Now that we have a null model adjusting height for covariates, we can run an association test to look for genetic effects on height. Single-variant tests are the same as in GWAS. We use the assocTestSingle function in GENESIS. First, we have to create a SeqVarData object including both the GDS file and the sample annotation containing phenotypes. We then create a SeqVarBlockIterator object to iterate over blocks of variants. library(SeqVarTools) gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; gds &lt;- seqOpen(gdsfile) seqData &lt;- SeqVarData(gds, sampleData=annot) iterator &lt;- SeqVarBlockIterator(seqData, verbose=FALSE) assoc &lt;- assocTestSingle(iterator, nullmod) ## # of selected samples: 1,126 head(assoc) ## variant.id chr pos allele.index n.obs freq Score ## 1 1 1 970546 1 1126 0.0039964476 -0.1191236 ## 2 2 1 985900 1 1126 0.0492895204 -1.6707553 ## 3 3 1 1025045 1 1126 0.0004440497 -0.2795838 ## 4 4 1 1265550 1 1126 0.0008880995 -0.1105487 ## 5 5 1 1472676 1 1126 0.0071047957 0.3630992 ## 6 6 1 1735725 1 1126 0.0022202487 -0.1300405 ## Score.SE Score.Stat Score.pval ## 1 0.2577712 -0.4621292 0.643988703 ## 2 0.8841849 -1.8895995 0.058811539 ## 3 0.1007173 -2.7759261 0.005504472 ## 4 0.1085480 -1.0184319 0.308472754 ## 5 0.3456555 1.0504657 0.293504072 ## 6 0.1973175 -0.6590420 0.509868791 We make a QQ plot to examine the results. library(ggplot2) qqPlot &lt;- function(pval) { pval &lt;- pval[!is.na(pval)] n &lt;- length(pval) x &lt;- 1:n dat &lt;- data.frame(obs=sort(pval), exp=x/n, upper=qbeta(0.025, x, rev(x)), lower=qbeta(0.975, x, rev(x))) ggplot(dat, aes(-log10(exp), -log10(obs))) + geom_line(aes(-log10(exp), -log10(upper)), color=&quot;gray&quot;) + geom_line(aes(-log10(exp), -log10(lower)), color=&quot;gray&quot;) + geom_point() + geom_abline(intercept=0, slope=1, color=&quot;red&quot;) + xlab(expression(paste(-log[10], &quot;(expected P)&quot;))) + ylab(expression(paste(-log[10], &quot;(observed P)&quot;))) + theme_bw() } qqPlot(assoc$Score.pval) 4.3 Exercises Logistic regression: fitNullModel can use a binary phenotype as the outcome variable by specifying the argument family=binomial. Use the status column in the sample annotation to fit a null model for simulated case/control status, with sex and Population as covariates. Then run a single-variant test using this model. Inverse normal transform: use the function nullModelInvNorm to perform an inverse normal transform on the height variable. For each study separately, compute a null model and do the inverse normal transform using just the values for that study. Compare these residuals with the initial residuals you obtained for that study by transforming all studies together. 4.4 Sliding window tests For rare variants, we can do burden tests or SKAT using the GENESIS function assocTestAggregate. We restrict the test to variants with alternate allele frequency &lt; 0.1. (For real data, this threshold would be lower.) We use a flat weighting scheme. We define a sliding window across the genome using a SeqVarWindowIterator. seqResetFilter(seqData, verbose=FALSE) iterator &lt;- SeqVarWindowIterator(seqData, windowSize=5000, windowShift=2000, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;Burden&quot;, AF.max=0.1, weight.beta=c(1,1)) ## # of selected samples: 1,126 names(assoc) ## [1] &quot;results&quot; &quot;variantInfo&quot; head(assoc$results) ## chr start end n.site n.alt n.sample.alt Score Score.SE ## 1 1 966001 971000 1 9 9 -0.1191236 0.2577712 ## 2 1 982001 987000 1 111 107 -1.6707553 0.8841849 ## 3 1 1022001 1027000 1 1 1 -0.2795838 0.1007173 ## 4 1 1262001 1267000 1 2 2 -0.1105487 0.1085480 ## 5 1 1468001 1473000 1 16 16 0.3630992 0.3456555 ## 6 1 1732001 1737000 1 5 5 -0.1300405 0.1973175 ## Score.Stat Score.pval ## 1 -0.4621292 0.643988703 ## 2 -1.8895995 0.058811539 ## 3 -2.7759261 0.005504472 ## 4 -1.0184319 0.308472754 ## 5 1.0504657 0.293504072 ## 6 -0.6590420 0.509868791 head(assoc$variantInfo) ## [[1]] ## variant.id chr pos allele.index n.obs freq weight ## 1 1 1 970546 1 1126 0.003996448 1 ## ## [[2]] ## variant.id chr pos allele.index n.obs freq weight ## 1 2 1 985900 1 1126 0.04928952 1 ## ## [[3]] ## variant.id chr pos allele.index n.obs freq weight ## 1 3 1 1025045 1 1126 0.0004440497 1 ## ## [[4]] ## variant.id chr pos allele.index n.obs freq weight ## 1 4 1 1265550 1 1126 0.0008880995 1 ## ## [[5]] ## variant.id chr pos allele.index n.obs freq weight ## 1 5 1 1472676 1 1126 0.007104796 1 ## ## [[6]] ## variant.id chr pos allele.index n.obs freq weight ## 1 6 1 1735725 1 1126 0.002220249 1 qqPlot(assoc$results$Score.pval) For SKAT, we use the Wu weights. seqResetFilter(seqData, verbose=FALSE) iterator &lt;- SeqVarWindowIterator(seqData, windowSize=5000, windowShift=2000, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;SKAT&quot;, AF.max=0.1, weight.beta=c(1,25)) ## # of selected samples: 1,126 head(assoc$results) ## chr start end n.site n.alt n.sample.alt Q_0 pval_0 ## 1 1 966001 971000 1 9 9 7.318094 0.643988703 ## 2 1 982001 987000 1 111 107 154.178280 0.058811539 ## 3 1 1022001 1027000 1 1 1 47.823916 0.005504472 ## 4 1 1262001 1267000 1 2 2 7.319239 0.308472754 ## 5 1 1468001 1473000 1 16 16 58.518662 0.293504072 ## 6 1 1732001 1737000 1 5 5 9.499539 0.509868791 ## err_0 ## 1 0 ## 2 0 ## 3 0 ## 4 0 ## 5 0 ## 6 0 head(assoc$variantInfo) ## [[1]] ## variant.id chr pos allele.index n.obs freq weight ## 1 1 1 970546 1 1126 0.003996448 22.70917 ## ## [[2]] ## variant.id chr pos allele.index n.obs freq weight ## 1 2 1 985900 1 1126 0.04928952 7.431881 ## ## [[3]] ## variant.id chr pos allele.index n.obs freq weight ## 1 3 1 1025045 1 1126 0.0004440497 24.73493 ## ## [[4]] ## variant.id chr pos allele.index n.obs freq weight ## 1 4 1 1265550 1 1126 0.0008880995 24.47255 ## ## [[5]] ## variant.id chr pos allele.index n.obs freq weight ## 1 5 1 1472676 1 1126 0.007104796 21.06793 ## ## [[6]] ## variant.id chr pos allele.index n.obs freq weight ## 1 6 1 1735725 1 1126 0.002220249 23.70132 qqPlot(assoc$results$pval_0) 4.5 Exercise Repeat the previous exercise on logistic regression, this time running a sliding-window test. "],
["association-tests-solutions.html", "5 Association tests - Solutions", " 5 Association tests - Solutions Logistic regression: fitNullModel can use a binary phenotype as the outcome variable by specifying the argument family=binomial. Use the status column in the sample annotation to fit a null model for simulated case/control status, with sex and Population as covariates. Then run a single-variant test using this model. nullmod.status &lt;- fitNullModel(annot, outcome=&quot;status&quot;, covars=c(&quot;sex&quot;, &quot;Population&quot;), family=binomial, verbose=FALSE) resetIterator(iterator, verbose=FALSE) assoc &lt;- assocTestSingle(iterator, nullmod.status, test=&quot;Score&quot;) ## # of selected samples: 1,126 head(assoc) ## variant.id chr pos allele.index n.obs freq Score ## 1 1 1 970546 1 1126 0.0039964476 0.20256722 ## 2 2 1 985900 1 1126 0.0492895204 -2.64169956 ## 3 3 1 1025045 1 1126 0.0004440497 -0.09916904 ## 4 4 1 1265550 1 1126 0.0008880995 0.81717324 ## 5 5 1 1472676 1 1126 0.0071047957 0.64418361 ## 6 6 1 1735725 1 1126 0.0022202487 -0.46319177 ## Score.SE Score.Stat Score.pval ## 1 0.8351783 0.2425437 0.80835892 ## 2 2.6522412 -0.9960254 0.31923781 ## 3 0.2972472 -0.3336248 0.73866267 ## 4 0.4033577 2.0259271 0.04277226 ## 5 1.0778277 0.5976685 0.55006117 ## 6 0.6396675 -0.7241134 0.46899613 Inverse normal transform: use the function nullModelInvNorm to perform an inverse normal transform on the height variable. For each study separately, compute a null model and do the inverse normal transform using just the values for that study. Compare these residuals with the initial residuals you obtained for that study by transforming all studies together. nullmod.norm.all &lt;- nullModelInvNorm(nullmod, norm.option=&quot;all&quot;) ## [1] 9.820192e+01 1.688205e+02 1.557072e+02 -1.625119e+03 7.522449e-03 ## [1] 6.599572e+01 1.133072e+02 1.041243e+02 -1.624934e+03 1.121317e-02 ## [1] 3.256661e+01 1.404193e+01 2.035900e+01 -1.640616e+03 5.041184e-02 ## [1] 0.4827084 8.3327542 8.0689110 -2114.3471115 0.7725792 ## [1] 0.5140578 0.7039764 0.9389426 -1625.4237578 1.4788832 ## [1] 0.7644879 0.9131510 0.9975131 -1611.9395485 1.1370448 ## [1] 0.9457491 0.9938303 1.0016039 -1608.6378674 1.0224502 ## [1] 0.998731 1.001647 1.001767 -1608.455879 1.001069 ## [1] 1.001807 1.001730 1.001805 -1608.455310 1.000003 ## [1] 1.001813 1.001731 1.001807 -1608.455310 1.000000 dat.all &lt;- data.frame(sample.id=nullmod.norm.all$sample.id, resid.norm=nullmod.norm.all$resid.marginal, study=annot$study, run=&quot;combined&quot;) nullmod.norm.group &lt;- nullModelInvNorm(nullmod, norm.option=&quot;by.group&quot;) ## [1] 9.820192e+01 1.688205e+02 1.557072e+02 -1.624686e+03 7.516645e-03 ## [1] 6.599547e+01 1.133069e+02 1.041241e+02 -1.624502e+03 1.120455e-02 ## [1] 3.254107e+01 1.394878e+01 2.030342e+01 -1.640619e+03 5.058311e-02 ## [1] 0.4823649 8.3127679 8.0728042 -2113.8412464 0.7725567 ## [1] 0.5136907 0.7135928 0.9316405 -1624.7322739 1.4746195 ## [1] 0.7639307 0.9183081 0.9959743 -1611.5285780 1.1349499 ## [1] 0.9450453 0.9939501 1.0009186 -1608.2035095 1.0221048 ## [1] 0.9979798 1.0007589 1.0010808 -1608.0188191 1.0010636 ## [1] 1.001052 1.000829 1.001116 -1608.018248 1.000003 ## [1] 1.001058 1.000831 1.001118 -1608.018248 1.000000 dat.group &lt;- data.frame(sample.id=nullmod.norm.group$sample.id, resid.norm=nullmod.norm.group$resid.marginal, study=annot$study, run=&quot;separate&quot;) dat &lt;- rbind(dat.all, dat.group) ggplot(dat, aes(study, resid.norm, fill=run)) + geom_boxplot() Repeat the previous exercise on logistic regression, this time running a sliding-window test. nullmod.status &lt;- fitNullModel(annot, outcome=&quot;status&quot;, covars=c(&quot;sex&quot;, &quot;Population&quot;), family=binomial, verbose=FALSE) seqResetFilter(seqData, verbose=FALSE) iterator &lt;- SeqVarWindowIterator(seqData, windowSize=5000, windowShift=2000, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;SKAT&quot;, AF.max=0.1, weight.beta=c(1,25)) ## # of selected samples: 1,126 head(assoc$results) ## chr start end n.site n.alt n.sample.alt Q_0 pval_0 ## 1 1 966001 971000 1 9 9 7.318094 0.643988703 ## 2 1 982001 987000 1 111 107 154.178280 0.058811539 ## 3 1 1022001 1027000 1 1 1 47.823916 0.005504472 ## 4 1 1262001 1267000 1 2 2 7.319239 0.308472754 ## 5 1 1468001 1473000 1 16 16 58.518662 0.293504072 ## 6 1 1732001 1737000 1 5 5 9.499539 0.509868791 ## err_0 ## 1 0 ## 2 0 ## 3 0 ## 4 0 ## 5 0 ## 6 0 seqClose(gds) "],
["computing-a-grm.html", "6 Computing a GRM", " 6 Computing a GRM We can use the SNPRelate package to compute a Genetic Relationship matrix (GRM). This method combines relatedness due to more distant ancestry and recent kinship into a single matrix. library(SeqArray) gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; gds &lt;- seqOpen(gdsfile) library(SNPRelate) grm &lt;- snpgdsGRM(gds, method=&quot;GCTA&quot;) ## Genetic Relationship Matrix (GRM, GCTA): ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Excluding 13 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 1,126 samples, 1,107 SNVs ## using 1 (CPU) core ## CPU capabilities: Double-Precision SSE2 ## Tue Jan 8 14:28:25 2019 (internal increment: 664) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Tue Jan 8 14:28:25 2019 Done. names(grm) ## [1] &quot;sample.id&quot; &quot;snp.id&quot; &quot;method&quot; &quot;grm&quot; dim(grm$grm) ## [1] 1126 1126 seqClose(gds) "],
["pc-relate.html", "7 PC-Relate 7.1 KING 7.2 PC-AiR 7.3 PC-Relate 7.4 Comparison with pedigree 7.5 Exercise", " 7 PC-Relate To disentangle ancestry from recent familial relatedness, we use the PC-Relate method. 7.1 KING Step 1 is to get initial estimates of kinship using KING, which is robust to population structure but not admixture. The KING algorithm is available in SNPRelate. We select a subset of variants for this calculation with LD pruning. # use a GDS file with all chromosomes library(SeqArray) gdsfile &lt;- &quot;data/1KG_phase3_subset.gds&quot; gds &lt;- seqOpen(gdsfile) # use a subset of 100 samples to make things run faster sampfile &lt;- &quot;data/samples_subset100.RData&quot; sample.id &lt;- TopmedPipeline::getobj(sampfile) # LD pruning to get variant set library(SNPRelate) set.seed(100) # LD pruning has a random element; so make this reproducible snpset &lt;- snpgdsLDpruning(gds, sample.id=sample.id, method=&quot;corr&quot;, slide.max.bp=10e6, ld.threshold=sqrt(0.1)) ## SNV pruning based on LD: ## Excluding 1,120 SNVs on non-autosomes ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 1s ## Excluding 13,673 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 100 samples, 10,967 SNVs ## using 1 (CPU) core ## sliding window: 10,000,000 basepairs, Inf SNPs ## |LD| threshold: 0.316228 ## method: correlation ## Chromosome 1: 31.25%, 350/1,120 ## Chromosome 2: 31.61%, 354/1,120 ## Chromosome 3: 31.07%, 348/1,120 ## Chromosome 4: 31.25%, 350/1,120 ## Chromosome 5: 29.82%, 334/1,120 ## Chromosome 6: 31.25%, 350/1,120 ## Chromosome 7: 28.39%, 318/1,120 ## Chromosome 8: 26.16%, 293/1,120 ## Chromosome 9: 28.39%, 318/1,120 ## Chromosome 10: 28.30%, 317/1,120 ## Chromosome 11: 26.88%, 301/1,120 ## Chromosome 12: 28.57%, 320/1,120 ## Chromosome 13: 25.27%, 283/1,120 ## Chromosome 14: 24.29%, 272/1,120 ## Chromosome 15: 22.59%, 253/1,120 ## Chromosome 16: 22.41%, 251/1,120 ## Chromosome 17: 22.32%, 250/1,120 ## Chromosome 18: 23.75%, 266/1,120 ## Chromosome 19: 21.96%, 246/1,120 ## Chromosome 20: 20.80%, 233/1,120 ## Chromosome 21: 17.95%, 201/1,120 ## Chromosome 22: 17.41%, 195/1,120 ## 6,403 markers are selected in total. sapply(snpset, length) ## chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 ## 350 354 348 350 334 350 318 293 318 317 301 320 ## chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 ## 283 272 253 251 250 266 246 233 201 195 pruned &lt;- unlist(snpset, use.names=FALSE) # KING king &lt;- snpgdsIBDKING(gds, sample.id=sample.id, snp.id=pruned) ## IBD analysis (KING method of moment) on genotypes: ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 1s ## Working space: 100 samples, 6,403 SNVs ## using 1 (CPU) core ## No family is specified, and all individuals are treated as singletons. ## Relationship inference in the presence of population stratification. ## CPU capabilities: Double-Precision SSE2 ## Tue Jan 8 14:28:27 2019 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Tue Jan 8 14:28:27 2019 Done. names(king) ## [1] &quot;sample.id&quot; &quot;snp.id&quot; &quot;afreq&quot; &quot;IBS0&quot; &quot;kinship&quot; dim(king$kinship) ## [1] 100 100 kingMat &lt;- king$kinship colnames(kingMat) &lt;- rownames(kingMat) &lt;- king$sample.id We extract pairwise kinship estimates and IBS0 to plot. kinship &lt;- snpgdsIBDSelection(king) head(kinship) ## ID1 ID2 IBS0 kinship ## 1 HG00110 HG00116 0.02530064 -0.01532452 ## 2 HG00110 HG00120 0.02748712 -0.02974760 ## 3 HG00110 HG00128 0.02483211 -0.01852977 ## 4 HG00110 HG00136 0.03014212 -0.05048077 ## 5 HG00110 HG00137 0.02701859 -0.03846154 ## 6 HG00110 HG00141 0.02920506 -0.04657452 library(ggplot2) ggplot(kinship, aes(IBS0, kinship)) + geom_hline(yintercept=2^(-seq(3,9,2)/2), linetype=&quot;dashed&quot;, color=&quot;grey&quot;) + geom_point(alpha=0.5) + ylab(&quot;kinship estimate&quot;) + theme_bw() 7.2 PC-AiR The next step is PC-AiR, in which we select a set of unrelated samples that is maximally informative about all ancestries in the sample. We use this unrelated set for Principal Component Analysis (PCA), then project the relatives onto the PCs. First, we partition the samples into a related and unrelated set. We use a kinship threshold of degree 3, which corresponds to first cousins. This defines anyone less related than first cousins as “unrelated”. We load the GENESIS package. In the first iteration, we use the KING estimates for both kinship (kinMat) and ancestry divergence (divMat). KING kinship estimates are negative for samples with different ancestry. library(GENESIS) sampset &lt;- pcairPartition(kinobj=kingMat, kin.thresh=2^(-9/2), divobj=kingMat, div.thresh=-2^(-9/2)) names(sampset) ## [1] &quot;rels&quot; &quot;unrels&quot; sapply(sampset, length) ## rels unrels ## 14 86 Using the SNPRelate package, we run PCA on the unrelated set and project values for the related set. We use the same LD pruned set of variants again. # run PCA on unrelated set pca.unrel &lt;- snpgdsPCA(gds, sample.id=sampset$unrels, snp.id=pruned) ## Principal Component Analysis (PCA) on genotypes: ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Excluding 222 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 86 samples, 6,181 SNVs ## using 1 (CPU) core ## CPU capabilities: Double-Precision SSE2 ## Tue Jan 8 14:28:28 2019 (internal increment: 8712) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Tue Jan 8 14:28:28 2019 Begin (eigenvalues and eigenvectors) ## Tue Jan 8 14:28:28 2019 Done. # project values for relatives snp.load &lt;- snpgdsPCASNPLoading(pca.unrel, gdsobj=gds) ## SNP loading: ## Working space: 86 samples, 6181 SNPs ## using 1 (CPU) core ## using the top 32 eigenvectors ## Tue Jan 8 14:28:28 2019 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Tue Jan 8 14:28:28 2019 Done. samp.load &lt;- snpgdsPCASampLoading(snp.load, gdsobj=gds, sample.id=sampset$rels) ## Sample loading: ## Working space: 14 samples, 6181 SNPs ## using 1 (CPU) core ## using the top 32 eigenvectors ## Tue Jan 8 14:28:28 2019 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Tue Jan 8 14:28:28 2019 Done. # combine unrelated and related PCs and order as in GDS file pcs &lt;- rbind(pca.unrel$eigenvect, samp.load$eigenvect) rownames(pcs) &lt;- c(pca.unrel$sample.id, samp.load$sample.id) samp.ord &lt;- match(sample.id, rownames(pcs)) pcs &lt;- pcs[samp.ord,] We need to determine which PCs are ancestry informative. To do this we need population information for the 1000 Genomes samples. This information is stored in an AnnotatedDataFrame, which is a data.frame with optional metadata describing the columns. The class is defined in the Biobase package. We load the stored object using the getobj function from the TopmedPipeline package. library(Biobase) sampfile &lt;- &quot;data/sample_annotation.RData&quot; annot &lt;- TopmedPipeline::getobj(sampfile) annot ## An object of class &#39;AnnotatedDataFrame&#39; ## rowNames: 1 2 ... 2504 (1126 total) ## varLabels: sample.id subject.id ... status (6 total) ## varMetadata: labelDescription head(pData(annot)) ## sample.id subject.id Population Population.Description sex ## 1 HG00096 HG00096 GBR British in England and Scotland M ## 2 HG00097 HG00097 GBR British in England and Scotland F ## 3 HG00099 HG00099 GBR British in England and Scotland F ## 4 HG00100 HG00100 GBR British in England and Scotland F ## 5 HG00101 HG00101 GBR British in England and Scotland M ## 6 HG00102 HG00102 GBR British in England and Scotland F ## status ## 1 0 ## 2 1 ## 3 0 ## 4 1 ## 5 0 ## 6 0 varMetadata(annot) ## labelDescription ## sample.id sample identifier ## subject.id subject identifier ## Population population abbreviation ## Population.Description population description ## sex sex ## status simulated case/control status We make a parallel coordinates plot, color-coding by 1000 Genomes population. We load the dplyr package for data.frame manipulation. pc.df &lt;- as.data.frame(pcs) names(pc.df) &lt;- 1:ncol(pcs) pc.df$sample.id &lt;- row.names(pcs) library(dplyr) annot &lt;- pData(annot) %&gt;% dplyr::select(sample.id, Population) pc.df &lt;- left_join(pc.df, annot, by=&quot;sample.id&quot;) library(GGally) library(RColorBrewer) pop.cols &lt;- setNames(brewer.pal(12, &quot;Paired&quot;), c(&quot;ACB&quot;, &quot;ASW&quot;, &quot;CEU&quot;, &quot;GBR&quot;, &quot;CHB&quot;, &quot;JPT&quot;, &quot;CLM&quot;, &quot;MXL&quot;, &quot;LWK&quot;, &quot;YRI&quot;, &quot;GIH&quot;, &quot;PUR&quot;)) ggparcoord(pc.df, columns=1:12, groupColumn=&quot;Population&quot;, scale=&quot;uniminmax&quot;) + scale_color_manual(values=pop.cols) + xlab(&quot;PC&quot;) + ylab(&quot;&quot;) 7.3 PC-Relate The first 2 PCs separate populations, so we use them to compute kinship estimates adjusting for ancestry. The PC-Relate function expects a SeqVarData object, which allows linking sample and variant annotation with a GDS file in a single object. We will cover these in more detail later for association testing, but for now we create a bare object with no annotation. seqResetFilter(gds, verbose=FALSE) library(SeqVarTools) seqData &lt;- SeqVarData(gds) seqSetFilter(seqData, variant.id=pruned) ## # of selected variants: 6,403 iterator &lt;- SeqVarBlockIterator(seqData, verbose=FALSE) pcrel &lt;- pcrelate(iterator, pcs=pcs[,1:2], training.set=sampset$unrels, sample.include=sample.id) names(pcrel) ## [1] &quot;kinBtwn&quot; &quot;kinSelf&quot; PC-Relate is an iterative method. Now that we have ancestry-adjusted kinship estimates, we can use them to better adjust for ancestry in the PCs. This time we use the pcair function, which combines partitioning the sample set and running PCA in one step. First we need to make a kinship matrix from the PC-Relate results. The KING matrix is still used for ancestry divergence. pcrelMat &lt;- pcrelateToMatrix(pcrel, scaleKin=1, verbose=FALSE) seqResetFilter(seqData, verbose=FALSE) pca &lt;- pcair(seqData, kinobj=pcrelMat, kin.thresh=2^(-9/2), divobj=kingMat, div.thresh=-2^(-9/2), sample.include=sample.id, snp.include=pruned, verbose=FALSE) names(pca) ## [1] &quot;vectors&quot; &quot;values&quot; &quot;rels&quot; &quot;unrels&quot; &quot;kin.thresh&quot; ## [6] &quot;div.thresh&quot; &quot;sample.id&quot; &quot;nsamp&quot; &quot;nsnps&quot; &quot;varprop&quot; ## [11] &quot;call&quot; &quot;method&quot; pcs &lt;- pca$vectors pc.df &lt;- as.data.frame(pcs) names(pc.df) &lt;- paste0(&quot;PC&quot;, 1:ncol(pcs)) pc.df$sample.id &lt;- row.names(pcs) pc.df &lt;- left_join(pc.df, annot, by=&quot;sample.id&quot;) ggplot(pc.df, aes(PC1, PC2, color=Population)) + geom_point() + scale_color_manual(values=pop.cols) Now we use the revised PCs to compute new kinship estimates. One can run the iteration multiple times and check for conversion, but usually two rounds are sufficient. seqSetFilter(seqData, variant.id=pruned) ## # of selected variants: 6,403 iterator &lt;- SeqVarBlockIterator(seqData, verbose=FALSE) pcrel &lt;- pcrelate(iterator, pcs=pcs[,1:2], training.set=pca$unrels, sample.include=sample.id) save(pcrel, file=&quot;data/pcrelate_kinship.RData&quot;) We plot the kinship estimates from PC-Relate, and notice that the values for less related pairs are much better behaved. kinship &lt;- pcrel$kinBtwn ggplot(kinship, aes(k0, kin)) + geom_hline(yintercept=2^(-seq(3,9,2)/2), linetype=&quot;dashed&quot;, color=&quot;grey&quot;) + geom_point(alpha=0.5) + ylab(&quot;kinship estimate&quot;) + theme_bw() seqClose(gds) 7.4 Comparison with pedigree We can detect pedigree errors and sample identity problems by comparing the pedigree with empirical kinship estimates. We use a function from the GWASTools package, pedigreePairwiseRelatedness, to get expected pairwise relationships based on the pedigree. pedfile &lt;- &quot;data/pedigree.RData&quot; if (!file.exists(pedfile)) download.file(file.path(workshop.path, pedfile), pedfile) ped &lt;- TopmedPipeline::getobj(pedfile) head(ped) ## family individ father mother sex ## 1 BB01 HG01879 0 0 M ## 2 BB01 HG01880 0 0 F ## 3 BB01 HG01881 HG01879 HG01880 F ## 4 BB02 HG01882 0 0 M ## 5 BB02 HG01883 0 0 F ## 6 BB02 HG01888 HG01882 HG01883 M pw &lt;- GWASTools::pedigreePairwiseRelatedness(ped) names(pw) ## [1] &quot;inbred.fam&quot; &quot;inbred.KC&quot; &quot;relativeprs&quot; rel &lt;- pw$relativeprs head(rel) ## Individ1 Individ2 relation kinship family ## 1 HG01879 HG01880 U 0.00 BB01 ## 2 HG01879 HG01881 PO 0.25 BB01 ## 3 HG01880 HG01881 PO 0.25 BB01 ## 4 HG01882 HG01883 U 0.00 BB02 ## 5 HG01882 HG01888 PO 0.25 BB02 ## 6 HG01883 HG01888 PO 0.25 BB02 table(rel$relation) ## ## Av FS GpGc HAv HS PO U ## 2 6 16 1 3 616 330 distinct(rel, relation, kinship) %&gt;% arrange(-kinship) ## relation kinship ## 1 PO 0.2500 ## 2 FS 0.2500 ## 3 HS 0.1250 ## 4 GpGc 0.1250 ## 5 Av 0.1250 ## 6 HAv 0.0625 ## 7 U 0.0000 ## assign degrees to expected relationship pairs rel &lt;- rel %&gt;% mutate(exp.rel=ifelse(kinship == 0.125, &quot;Deg2&quot;, ifelse(kinship == 0.0625, &quot;Deg3&quot;, relation)), pair=GWASTools::pasteSorted(Individ1, Individ2)) %&gt;% select(pair, family, relation, exp.rel) ## assign degrees to observed relationship pairs cut.dup &lt;- 1/(2^(3/2)) cut.deg1 &lt;- 1/(2^(5/2)) cut.deg2 &lt;- 1/(2^(7/2)) cut.deg3 &lt;- 1/(2^(9/2)) cut.k0 &lt;- 0.1 kinship &lt;- kinship %&gt;% mutate(obs.rel=ifelse(kin &gt; cut.dup, &quot;Dup&quot;, ifelse(kin &gt; cut.deg1 &amp; k0 &lt; cut.k0, &quot;PO&quot;, ifelse(kin &gt; cut.deg1, &quot;FS&quot;, ifelse(kin &gt; cut.deg2, &quot;Deg2&quot;, ifelse(kin &gt; cut.deg3, &quot;Deg3&quot;, &quot;U&quot;)))))) table(kinship$obs.rel) ## ## Deg2 Deg3 FS PO U ## 3 6 2 7 4932 # merge observed and expected relationships kin.obs &lt;- kinship %&gt;% select(ID1, ID2, kin, k0, obs.rel) %&gt;% mutate(pair=GWASTools::pasteSorted(ID1, ID2)) %&gt;% left_join(rel, by=&quot;pair&quot;) %&gt;% select(-pair) %&gt;% mutate(exp.rel=ifelse(is.na(exp.rel), &quot;U&quot;, exp.rel)) %&gt;% filter(!(exp.rel == &quot;U&quot; &amp; obs.rel == &quot;U&quot;)) table(kin.obs$exp.rel, kin.obs$obs.rel) ## ## Deg2 Deg3 FS PO ## U 3 6 2 7 ggplot(kin.obs, aes(k0, kin, color=obs.rel)) + geom_point() All the observed relationships were unexpected. These samples are from 1000 Genomes sequencing, and known relatives were excluded from the released data. Here we have detected some cryptic relatives that were not annotated in the pedigree. 7.5 Exercise Complete one round of iteration using all samples from the test dataset and plot the results. Be sure to examine the parallel coordinates plot to determine the appropriate number of PCs to give as an argument to pcrelate. "],
["mixed-models.html", "8 Mixed models 8.1 Null model 8.2 Single-variant tests 8.3 Exercise", " 8 Mixed models These exercises introduce relatedness to association testing with mixed models. 8.1 Null model The first step in an association test is to fit the null model. In addition to the AnnotatedDataFrame with phenotypes we used previously, we will need the principal components and kinship. We will use the first five PCs to adjust for ancestry. # sample annotation sampfile &lt;- &quot;data/sample_phenotype_annotation.RData&quot; annot &lt;- TopmedPipeline::getobj(sampfile) library(Biobase) head(pData(annot)) ## sample.id subject.id Population Population.Description sex ## 1 HG00096 HG00096 GBR British in England and Scotland M ## 2 HG00097 HG00097 GBR British in England and Scotland F ## 3 HG00099 HG00099 GBR British in England and Scotland F ## 4 HG00100 HG00100 GBR British in England and Scotland F ## 5 HG00101 HG00101 GBR British in England and Scotland M ## 6 HG00102 HG00102 GBR British in England and Scotland F ## status age height study ## 1 0 47 165.300 study_1 ## 2 1 47 144.780 study_3 ## 3 0 40 185.500 study_2 ## 4 1 45 150.622 study_3 ## 5 0 40 177.800 study_3 ## 6 0 49 169.100 study_1 # load the PCs pcfile &lt;- &quot;data/pcs.RData&quot; pcs &lt;- TopmedPipeline::getobj(pcfile) pcs &lt;- pcs[,c(&quot;sample.id&quot;, &quot;PC1&quot;, &quot;PC2&quot;, &quot;PC3&quot;, &quot;PC4&quot;, &quot;PC5&quot;)] head(pcs) ## sample.id PC1 PC2 PC3 PC4 PC5 ## 1 HG00096 -0.02098435 -0.03716014 -0.007539234 -0.004984352 -0.03920777 ## 2 HG00097 -0.01929295 -0.03289496 -0.009176117 -0.005328914 -0.03297778 ## 3 HG00099 -0.02042444 -0.03371227 -0.010983795 -0.004856350 -0.03208595 ## 4 HG00100 -0.01970348 -0.03978044 -0.013302258 -0.004340841 -0.04208343 ## 5 HG00101 -0.01959563 -0.03431033 -0.008571074 -0.002220712 -0.03260015 ## 6 HG00102 -0.02041573 -0.03941142 -0.010696762 0.001506639 -0.02913023 # add PCs to the sample annotation dat &lt;- left_join(pData(annot), pcs, by=&quot;sample.id&quot;) pData(annot) &lt;- dat save(annot, file=&quot;sample_phenotype_pcs.RData&quot;) We create a kinship matrix from the output of pcrelate. We multiply the kinship values by 2 to get values equivalent to a GRM. This matrix is represented in R as a symmetric matrix object from the Matrix package. kinfile &lt;- &quot;data/pcrelate_kinship.RData&quot; pcrel &lt;- TopmedPipeline::getobj(kinfile) kinship &lt;- pcrelateToMatrix(pcrel, scaleKin=2, verbose=FALSE) dim(kinship) ## [1] 100 100 kinship[1:5,1:5] ## 5 x 5 Matrix of class &quot;dsyMatrix&quot; ## HG00110 HG00116 HG00120 HG00128 HG00136 ## HG00110 1.062086715 0.02049398 -0.006412347 0.010199379 -0.026171731 ## HG00116 0.020493975 0.92914833 0.176596566 0.012580254 -0.020707995 ## HG00120 -0.006412347 0.17659657 0.969533982 -0.007387808 -0.056610406 ## HG00128 0.010199379 0.01258025 -0.007387808 0.935900451 0.003227475 ## HG00136 -0.026171731 -0.02070799 -0.056610406 0.003227475 1.011102071 We fit the null model, adding the PCs to the list of covariates, and specifying the kinship as the covariance matrix with the cov.mat argument. As before, we use study as a grouping variable. library(GENESIS) nullmod &lt;- fitNullModel(annot, outcome=&quot;height&quot;, covars=c(&quot;sex&quot;, &quot;age&quot;, &quot;study&quot;, paste0(&quot;PC&quot;, 1:5)), cov.mat=kinship, group.var=&quot;study&quot;, verbose=FALSE) save(nullmod, file=&quot;null_mixed_model.RData&quot;) 8.2 Single-variant tests Now we can run a single-variant test, accounting for relatedness between the subjects. library(SeqVarTools) gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; gds &lt;- seqOpen(gdsfile) seqData &lt;- SeqVarData(gds, sampleData=annot) iterator &lt;- SeqVarBlockIterator(seqData, verbose=FALSE) assoc &lt;- assocTestSingle(iterator, nullmod) ## # of selected samples: 100 head(assoc) ## variant.id chr pos allele.index n.obs freq Score Score.SE ## 1 1 1 970546 1 100 0.015 -0.08720781 0.1419917 ## 2 2 1 985900 1 100 0.045 -0.22392313 0.2316274 ## 3 3 1 1025045 1 100 0.000 NA NA ## 4 4 1 1265550 1 100 0.000 NA NA ## 5 5 1 1472676 1 100 0.005 -0.08044594 0.0867442 ## 6 6 1 1735725 1 100 0.000 NA NA ## Score.Stat Score.pval ## 1 -0.6141754 0.5390994 ## 2 -0.9667385 0.3336748 ## 3 NA NA ## 4 NA NA ## 5 -0.9273927 0.3537227 ## 6 NA NA qqPlot(assoc$Score.pval) 8.3 Exercise Run a sliding window test using the mixed model and make a QQ plot. "],
["mixed-models-solutions.html", "9 Mixed models - Solutions", " 9 Mixed models - Solutions Run a sliding window test using the mixed model and make a QQ plot. seqResetFilter(seqData, verbose=FALSE) iterator &lt;- SeqVarWindowIterator(seqData, windowSize=5000, windowShift=2000, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;Burden&quot;, AF.max=0.1, weight.beta=c(1,1)) ## # of selected samples: 100 head(assoc$results) ## chr start end n.site n.alt n.sample.alt Score Score.SE ## 1 1 966001 971000 1 3 3 -0.08720781 0.1419917 ## 2 1 982001 987000 1 9 9 -0.22392313 0.2316274 ## 3 1 1022001 1027000 0 0 0 NA NA ## 4 1 1262001 1267000 0 0 0 NA NA ## 5 1 1468001 1473000 1 1 1 -0.08044594 0.0867442 ## 6 1 1732001 1737000 0 0 0 NA NA ## Score.Stat Score.pval ## 1 -0.6141754 0.5390994 ## 2 -0.9667385 0.3336748 ## 3 NA NA ## 4 NA NA ## 5 -0.9273927 0.3537227 ## 6 NA NA head(assoc$variantInfo) ## [[1]] ## variant.id chr pos allele.index n.obs freq weight ## 1 1 1 970546 1 100 0.015 1 ## ## [[2]] ## variant.id chr pos allele.index n.obs freq weight ## 1 2 1 985900 1 100 0.045 1 ## ## [[3]] ## [1] variant.id chr pos allele.index n.obs ## [6] freq weight ## &lt;0 rows&gt; (or 0-length row.names) ## ## [[4]] ## [1] variant.id chr pos allele.index n.obs ## [6] freq weight ## &lt;0 rows&gt; (or 0-length row.names) ## ## [[5]] ## variant.id chr pos allele.index n.obs freq weight ## 1 5 1 1472676 1 100 0.005 1 ## ## [[6]] ## [1] variant.id chr pos allele.index n.obs ## [6] freq weight ## &lt;0 rows&gt; (or 0-length row.names) qqPlot(assoc$results$Score.pval) seqClose(gds) "],
["variant-annotation.html", "10 Variant annotation 10.1 Using Bioconductor annotation resources 10.2 Aggregating and filtering variants using annotation 10.3 Aggregate unit for association testing exercise 10.4 Association testing with aggregate units 10.5 Exercise", " 10 Variant annotation 10.1 Using Bioconductor annotation resources In this example, we illustrate defining aggregate units based on known genes. First, we load the null mixed model and open the GDS file. modfile &lt;- &quot;data/null_mixed_model.RData&quot; nullmod &lt;- TopmedPipeline::getobj(modfile) sampfile &lt;- &quot;data/sample_phenotype_annotation.RData&quot; annot &lt;- TopmedPipeline::getobj(sampfile) gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; library(SeqVarTools) gds &lt;- seqOpen(gdsfile) seqData &lt;- SeqVarData(gds, sampleData=annot) We use the human genome annotation from Bioconductor to identify genes. library(GenomicRanges) library(TxDb.Hsapiens.UCSC.hg19.knownGene) # return the variants in seqData as a GRanges object gr &lt;- granges(gds) gr ## GRanges object with 1120 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## 1 1 970546 * ## 2 1 985900 * ## 3 1 1025045 * ## 4 1 1265550 * ## 5 1 1472676 * ## ... ... ... ... ## 1116 1 248715186 * ## 1117 1 248715606-248715610 * ## 1118 1 248761613 * ## 1119 1 248894546 * ## 1120 1 249149558 * ## ------- ## seqinfo: 1 sequence from an unspecified genome; no seqlengths # find variants that overlap with each gene txdb &lt;- TxDb.Hsapiens.UCSC.hg19.knownGene gr &lt;- renameSeqlevels(gr, paste0(&quot;chr&quot;, seqlevels(gr))) ts &lt;- transcriptsByOverlaps(txdb, gr, columns=&quot;GENEID&quot;) # simplistic example - define genes as overlapping transcripts genes &lt;- reduce(ts) genes &lt;- renameSeqlevels(genes, sub(&quot;chr&quot;, &quot;&quot;, seqlevels(genes))) genes ## GRanges object with 384 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## [1] 1 955503-991499 + ## [2] 1 2160134-2241652 + ## [3] 1 2985742-3355185 + ## [4] 1 6484848-6521004 + ## [5] 1 6845384-7829766 + ## ... ... ... ... ## [380] 1 245912642-246670644 - ## [381] 1 246703863-246729565 - ## [382] 1 247108849-247242115 - ## [383] 1 247463622-247495045 - ## [384] 1 249144203-249153315 - ## ------- ## seqinfo: 93 sequences (1 circular) from hg19 genome We run a burden test, setting a maximum alternate allele frequency to exclude common variants. # create an iterator where each successive unit is a different gene iterator &lt;- SeqVarRangeIterator(seqData, variantRanges=genes, verbose=FALSE) # do a burden test on the rare variants in each gene assoc &lt;- assocTestAggregate(iterator, nullmod, AF.max=0.05, test=&quot;Burden&quot;) ## # of selected samples: 100 head(assoc$results) ## n.site n.alt n.sample.alt Score Score.SE Score.Stat Score.pval ## 1 2 12 12 -0.311130943 0.26363332 -1.18016548 0.23793441 ## 2 1 1 1 0.025421814 0.07341585 0.34627148 0.72913870 ## 3 1 2 2 0.201648520 0.11806291 1.70797520 0.08764094 ## 4 2 4 4 -0.004437774 0.16591324 -0.02674756 0.97866108 ## 5 1 8 8 0.028460319 0.21098460 0.13489287 0.89269657 ## 6 0 0 0 NA NA NA NA head(assoc$variantInfo) ## [[1]] ## variant.id chr pos allele.index n.obs freq weight ## 1 1 1 970546 1 100 0.015 1 ## 2 2 1 985900 1 100 0.045 1 ## ## [[2]] ## variant.id chr pos allele.index n.obs freq weight ## 1 7 1 2185887 1 100 0.005 1 ## ## [[3]] ## variant.id chr pos allele.index n.obs freq weight ## 2 15 1 3293503 1 100 0.01 1 ## ## [[4]] ## variant.id chr pos allele.index n.obs freq weight ## 1 36 1 6489967 1 100 0.01 1 ## 2 37 1 6503405 1 100 0.01 1 ## ## [[5]] ## variant.id chr pos allele.index n.obs freq weight ## 2 39 1 7056029 1 100 0.04 1 ## ## [[6]] ## [1] variant.id chr pos allele.index n.obs ## [6] freq weight ## &lt;0 rows&gt; (or 0-length row.names) 10.2 Aggregating and filtering variants using annotation Alternatively, we may want to import annotation from other software, such as ANNOVAR or WGSA. The output formats of variant annotation software can be quite complex, but for this exercise we use fairly simple tab-separated text files. library(dplyr) snv_annotation &lt;- read.table(&quot;data/snv_parsed.tsv&quot;, sep=&quot;\\t&quot;, na.strings=&quot;.&quot;, header=TRUE, as.is=TRUE) indel_annotation &lt;- read.table(&quot;data/indel_parsed.tsv&quot;, sep=&quot;\\t&quot;, na.strings=&quot;.&quot;, header=TRUE, as.is=TRUE) combined_annotation &lt;- bind_rows(snv_annotation, indel_annotation) Here we remove variants that are not associated with a gene, group the variants by gene, and filter the variants for intron_variants with a CADD_phred score greater than 3 in just a few lines of code: combined_annotation %&gt;% filter(VEP_ensembl_Gene_ID != &quot;.&quot;) %&gt;% # remove variants not annotated with a Gene_ID group_by(VEP_ensembl_Gene_ID) %&gt;% # aggregate by gene filter(CADD_phred &gt; 3) %&gt;% # filter variants to keep only CADD_phred greater than 3 filter(stringr::str_detect(VEP_ensembl_Consequence, &quot;intron_variant&quot;)) %&gt;% # keep intron variants glimpse() # view the result - 592 variants ## Observations: 592 ## Variables: 7 ## $ CHROM &lt;int&gt; 22, 22, 22, 22, 22, 22, 22, 22, 22, 22... ## $ POS &lt;int&gt; 15699830, 15699830, 16437047, 16445862... ## $ REF &lt;chr&gt; &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;C&quot;, &quot;C&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;... ## $ ALT &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;T&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... ## $ VEP_ensembl_Gene_ID &lt;chr&gt; &quot;ENSG00000198062&quot;, &quot;ENSG00000198062&quot;, ... ## $ VEP_ensembl_Consequence &lt;chr&gt; &quot;intron_variant,NMD_transcript_variant... ## $ CADD_phred &lt;dbl&gt; 3.612, 3.612, 9.729, 3.895, 7.530, 5.3... Now that you’ve got a set of variants that you can aggregate into genic units, the data needs to be reformatted for input to the GENESIS analysis pipeline. The input to the GENESIS pipeline is a data frame with variables called group_id, chr, pos, ref, and alt. Prepare this data frame and save it for testing (You do not need to filter the variants for this exercise): aggregates &lt;- combined_annotation %&gt;% filter(VEP_ensembl_Gene_ID != &quot;.&quot;) %&gt;% # remove variants not annotated with a Gene_ID group_by(VEP_ensembl_Gene_ID) %&gt;% # aggregate by gene dplyr::select(group_id = VEP_ensembl_Gene_ID, chr = CHROM, pos = POS, ref = REF, alt = ALT) %&gt;% glimpse # inspect the tibble ## Observations: 2,603 ## Variables: 5 ## $ group_id &lt;chr&gt; &quot;ENSG00000230643&quot;, &quot;ENSG00000226474&quot;, &quot;ENSG0000023156... ## $ chr &lt;int&gt; 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 2... ## $ pos &lt;int&gt; 15589963, 15613723, 15613723, 15628559, 15699830, 156... ## $ ref &lt;chr&gt; &quot;G&quot;, &quot;A&quot;, &quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;... ## $ alt &lt;chr&gt; &quot;T&quot;, &quot;G&quot;, &quot;G&quot;, &quot;T&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;T&quot;, &quot;T&quot;, &quot;T&quot;... You can also compute some summary information about these aggregates, such as counting how many genic units we’re using: length(unique(aggregates$group_id)) ## [1] 598 We can look at the distribution of the number of variants per aggregation unit: counts &lt;- aggregates %&gt;% group_by(group_id) %&gt;% summarize(n = n()) ggplot(counts, aes(x = n)) + geom_bar() 10.3 Aggregate unit for association testing exercise Now you can proceed to an assocation testing exercise. You will be using a slightly different gene-based aggregation unit for the assocation testing exercise. In this exercise, the genic units include SNP variants from all chromosomes (no indels, and not just chromosome 22 as before), each genic unit is expanded to include the set of SNPs falling within a GENCODE-defined gene along with 20 kb flanking regions upstream and downstream of that range, and the positions are in genome build hg19 (so that the annotation positions are consistent with the build used for genotyping data in the workshop). This set of aggregation units is not filtered by CADD score or consequence. As before, the aggregation units are defined in an R dataframe. Each row of the dataframe specifies a variant (chr, pos, ref, alt) and the group identifier (group_id) it is a part of. Mutiple rows with different group identifiers can be specified to assign a variant to different groups (a variant can be assigned to mutiple genes). Begin by loading the aggregation units using TopmedPipeline::getobj(): aggfile &lt;- &quot;data/variants_by_gene.RData&quot; aggunit &lt;- TopmedPipeline::getobj(aggfile) names(aggunit) ## [1] &quot;group_id&quot; &quot;chr&quot; &quot;pos&quot; &quot;ref&quot; &quot;alt&quot; head(aggunit) ## # A tibble: 6 x 5 ## group_id chr pos ref alt ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ENSG00000131591.13 1 1025045 C T ## 2 ENSG00000169962.4 1 1265550 C T ## 3 ENSG00000205090.4 1 1472676 T C ## 4 ENSG00000171603.12 1 9788518 G A ## 5 ENSG00000204624.6 1 11593461 C T ## 6 ENSG00000270914.1 1 12068870 G A # an example of variant that is present in mutiple groups mult &lt;- aggunit %&gt;% group_by(chr, pos) %&gt;% summarise(n=n()) %&gt;% filter(n &gt; 1) inner_join(aggunit, mult[2,1:2]) ## # A tibble: 2 x 5 ## group_id chr pos ref alt ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ENSG00000187952.8 1 21742183 G A ## 2 ENSG00000227001.2 1 21742183 G A 10.4 Association testing with aggregate units We can run a burden test or SKAT on each of these units using assocTestAggregate. We define a SeqVarListIterator object where each list element is an aggregate unit. The constructor expects a GRangesList, so we use the TopmedPipeline function aggregateGRangesList to quickly convert our single dataframe to the required format. This function can account for multiallelic variants (the same chromosome, position, and ref, but different alt alleles). library(TopmedPipeline) library(SeqVarTools) if (exists(&quot;seqData&quot;)) { seqResetFilter(seqData, verbose=FALSE) } else { gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; gds &lt;- seqOpen(gdsfile) annotfile &lt;- &quot;data/sample_phenotype_pcs.RData&quot; annot &lt;- getobj(annotfile) seqData &lt;- SeqVarData(gds, sampleData=annot) } # subset to chromosome 1 aggunit &lt;- filter(aggunit, chr == 1) aggVarList &lt;- aggregateGRangesList(aggunit) length(aggVarList) ## [1] 127 head(names(aggVarList)) ## [1] &quot;ENSG00000131591.13&quot; &quot;ENSG00000169962.4&quot; &quot;ENSG00000205090.4&quot; ## [4] &quot;ENSG00000171603.12&quot; &quot;ENSG00000204624.6&quot; &quot;ENSG00000270914.1&quot; aggVarList[[1]] ## GRanges object with 1 range and 2 metadata columns: ## seqnames ranges strand | ref alt ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | &lt;character&gt; &lt;character&gt; ## [1] 1 1025045 * | C T ## ------- ## seqinfo: 23 sequences from an unspecified genome; no seqlengths iterator &lt;- SeqVarListIterator(seqData, variantRanges=aggVarList, verbose=FALSE) As in the previous section, we must load the null model before running the association test. if (!exists(&quot;nullmod&quot;)) { nmfile &lt;- &quot;data/null_mixed_model.RData&quot; nullmod &lt;- getobj(nmfile) } assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;Burden&quot;, AF.max=0.1, weight.beta=c(1,1)) ## # of selected samples: 100 names(assoc) ## [1] &quot;results&quot; &quot;variantInfo&quot; head(assoc$results) ## n.site n.alt n.sample.alt Score Score.SE ## ENSG00000131591.13 0 0 0 NA NA ## ENSG00000169962.4 0 0 0 NA NA ## ENSG00000205090.4 1 1 1 -0.08044594 0.08674420 ## ENSG00000171603.12 0 0 0 NA NA ## ENSG00000204624.6 0 0 0 NA NA ## ENSG00000270914.1 1 1 1 -0.05332431 0.08057418 ## Score.Stat Score.pval ## ENSG00000131591.13 NA NA ## ENSG00000169962.4 NA NA ## ENSG00000205090.4 -0.9273927 0.3537227 ## ENSG00000171603.12 NA NA ## ENSG00000204624.6 NA NA ## ENSG00000270914.1 -0.6618040 0.5080969 head(names(assoc$variantInfo)) ## [1] &quot;ENSG00000131591.13&quot; &quot;ENSG00000169962.4&quot; &quot;ENSG00000205090.4&quot; ## [4] &quot;ENSG00000171603.12&quot; &quot;ENSG00000204624.6&quot; &quot;ENSG00000270914.1&quot; head(assoc$variantInfo[[1]]) ## [1] variant.id chr pos ref alt ## [6] allele.index n.obs freq weight ## &lt;0 rows&gt; (or 0-length row.names) qqPlot(assoc$results$Score.pval) 10.5 Exercise Since we are working with a subset of the data, many of the genes listed in group_id have a very small number of variants. Create a new set of units based on position rather than gene name, using the TopmedPipeline function aggregateGRanges. Then run SKAT using those units and a SeqVarRangeIterator. "],
["annotation-solutions.html", "11 Annotation - Solutions", " 11 Annotation - Solutions Since we are working with a subset of the data, many of the genes listed in group_id have a very small number of variants. Create a new set of units based on position rather than gene name, using the TopmedPipeline function aggregateGRanges. Then run SKAT using those units and a SeqVarRangeIterator. agg2 &lt;- aggunit %&gt;% mutate(chr=factor(chr, levels=c(1:22, &quot;X&quot;))) %&gt;% distinct(chr, pos) %&gt;% group_by(chr) %&gt;% summarise(min=min(pos), max=max(pos)) head(agg2) ## # A tibble: 1 x 3 ## chr min max ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1025045 248761613 aggByPos &lt;- bind_rows(lapply(1:nrow(agg2), function(i) { data.frame(chr=agg2$chr[i], start=seq(agg2$min[i], agg2$max[i]-1e6, length.out=10), end=seq(agg2$min[i]+1e6, agg2$max[i], length.out=10)) })) %&gt;% mutate(group_id=1:n()) head(aggByPos) ## chr start end group_id ## 1 1 1025045 2025045 1 ## 2 1 28440219 29440219 2 ## 3 1 55855393 56855393 3 ## 4 1 83270568 84270568 4 ## 5 1 110685742 111685742 5 ## 6 1 138100916 139100916 6 aggVarList &lt;- aggregateGRanges(aggByPos) aggVarList[1:2] ## GRanges object with 2 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## 1 1 1025045-2025045 * ## 2 1 28440219-29440219 * ## ------- ## seqinfo: 23 sequences from an unspecified genome; no seqlengths seqResetFilter(seqData, verbose=FALSE) iterator &lt;- SeqVarRangeIterator(seqData, variantRanges=aggVarList, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;SKAT&quot;, AF.max=0.1, weight.beta=c(1,25)) ## # of selected samples: 100 head(assoc$results) ## n.site n.alt n.sample.alt Q_0 pval_0 err_0 ## 1 1 1 1 3.1797730 0.3537227 0 ## 2 3 11 10 4.0159256 0.8066574 0 ## 3 1 5 5 1.5950777 0.5908120 0 ## 4 2 3 3 0.8873271 0.8919105 0 ## 5 0 0 0 NA NA NA ## 6 0 0 0 NA NA NA seqClose(gds) "]
]

[
["index.html", "SISG Module 17: Computational Pipeline for WGS Data 1 Introduction 1.1 Schedule 1.2 R packages used 1.3 Resources", " SISG Module 17: Computational Pipeline for WGS Data 2019-06-13 1 Introduction This site contains course materials for Course materials for SISG Module 17: Computational Pipeline for WGS Data, July 24-26, 2019 . Data used is located in the github repository from which the site is built, as well as in the TOPMed analysis pipeline. 1.1 Schedule Lecture slides Wednesday, July 24 Introduction Sequencing and data formats Sequencing overview Sequencing data formats Intro to Genomic Data Storage Exercises Phenotype harmonization Exercises Association tests Methods and motivation (Part 1) Thursday, July 25 Association tests Methods and motivation (Part 2) GENESIS for association tests Exercises Aggregate tests (Part 3) Exercises Population structure and relatedness Population structure inference Relatedness inference R packages for PCA and relatedness Exercises Mixed model association testing Exercises Friday, July 26 Variant annotation Exercises Analysis pipeline on the cloud Cloud platforms Analysis Commons Fair4Cures Terra Download the workshop data and exercises: https://github.com/UW-GAC/SISG_2019/archive/master.zip 1.2 R packages used SeqArray SeqVarTools GENESIS SNPRelate TopmedPipeline wgsaparsr tidyverse GGally survey CompQuadForm 1.3 Resources If you are new to R, you might find the following material helpful: Introduction to R materials from SISG Module 3 Graphics with ggplot2 tutorial Data manipulation with dplyr "],
["gds-format.html", "2 GDS format 2.1 Exploring a GDS file 2.2 Exercises", " 2 GDS format GDS is Genomic Data Structure, a storage format that can efficiently store genomic data and provide fast random access to subsets of the data. For more information on GDS for sequence data, read the SeqArray package vignette. 2.1 Exploring a GDS file To use the R packages developed at the University of Washington for sequence data, we first need to convert a VCF file to GDS. (If the file is BCF, use https://samtools.github.io/bcftools/bcftools.html to convert to VCF.) library(SeqArray) vcffile &lt;- &quot;data/1KG_phase3_subset_chr1.vcf.gz&quot; gdsfile &lt;- &quot;1KG_phase3_subset_chr1.gds&quot; seqVCF2GDS(vcffile, gdsfile, fmt.import=&quot;GT&quot;, storage.option=&quot;LZMA_RA&quot;, verbose=FALSE) We can interact with the GDS file using the SeqArray package. gds &lt;- seqOpen(gdsfile) gds ## Object of class &quot;SeqVarGDSClass&quot; ## File: /Users/stephanie/SISG/SISG_2019/SISG_2019/1KG_phase3_subset_chr1.gds (70.6K) ## + [ ] * ## |--+ description [ ] * ## |--+ sample.id { Str8 1126 LZMA_ra(9.66%), 877B } * ## |--+ variant.id { Int32 1120 LZMA_ra(17.5%), 793B } * ## |--+ position { Int32 1120 LZMA_ra(78.5%), 3.4K } * ## |--+ chromosome { Str8 1120 LZMA_ra(4.55%), 109B } * ## |--+ allele { Str8 1120 LZMA_ra(26.0%), 1.2K } * ## |--+ genotype [ ] * ## | |--+ data { Bit2 2x1126x1121 LZMA_ra(8.34%), 51.4K } * ## | |--+ extra.index { Int32 3x0 LZMA_ra, 18B } * ## | \\--+ extra { Int16 0 LZMA_ra, 18B } ## |--+ phase [ ] ## | |--+ data { Bit1 1126x1120 LZMA_ra(0.11%), 177B } * ## | |--+ extra.index { Int32 3x0 LZMA_ra, 18B } * ## | \\--+ extra { Bit1 0 LZMA_ra, 18B } ## |--+ annotation [ ] ## | |--+ id { Str8 1120 LZMA_ra(40.4%), 3.6K } * ## | |--+ qual { Float32 1120 LZMA_ra(2.46%), 117B } * ## | |--+ filter { Int32,factor 1120 LZMA_ra(2.46%), 117B } * ## | |--+ info [ ] ## | \\--+ format [ ] ## \\--+ sample.annotation [ ] # the unique sample identifier comes from the VCF header sample.id &lt;- seqGetData(gds, &quot;sample.id&quot;) length(sample.id) ## [1] 1126 head(sample.id) ## [1] &quot;HG00096&quot; &quot;HG00097&quot; &quot;HG00099&quot; &quot;HG00100&quot; &quot;HG00101&quot; &quot;HG00102&quot; # a unique integer ID is assigned to each variant variant.id &lt;- seqGetData(gds, &quot;variant.id&quot;) length(variant.id) ## [1] 1120 head(variant.id) ## [1] 1 2 3 4 5 6 # reference allele frequency of each variant afreq &lt;- seqAlleleFreq(gds) hist(afreq, breaks=50) We can define a filter on the gds object. After using the seqSetFilter command, all subsequent reads from the gds object are restricted to the selected subset of data, until a new filter is defined or seqResetFilter is called. seqSetFilter(gds, variant.id=1:10, sample.id=sample.id[1:5]) ## # of selected samples: 5 ## # of selected variants: 10 Genotype data is stored in a 3-dimensional array, where the first dimension is always 2 for diploid genotypes. The second and third dimensions are samples and variants, respectively. The values of the array denote alleles: 0 is the reference allele and 1 is the alternate allele. For multiallelic variants, other alternate alleles are represented as integers &gt; 1. geno &lt;- seqGetData(gds, &quot;genotype&quot;) dim(geno) ## [1] 2 5 10 geno[,,1:2] ## , , 1 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 2 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 The SeqVarTools package has some additional functions for interacting with SeqArray-format GDS files. library(SeqVarTools) # return genotypes in matrix format getGenotype(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00097 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00099 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00100 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00101 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; getGenotypeAlleles(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00097 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00099 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00100 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00101 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; refDosage(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 2 2 2 2 2 2 2 2 2 2 ## HG00097 2 2 2 2 2 2 2 2 2 2 ## HG00099 2 2 2 2 2 2 2 2 2 2 ## HG00100 2 2 2 2 2 2 2 2 2 2 ## HG00101 2 2 2 2 2 2 2 2 2 2 altDosage(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 0 0 0 0 0 0 0 0 0 0 ## HG00097 0 0 0 0 0 0 0 0 0 0 ## HG00099 0 0 0 0 0 0 0 0 0 0 ## HG00100 0 0 0 0 0 0 0 0 0 0 ## HG00101 0 0 0 0 0 0 0 0 0 0 # look at reference and alternate alleles refChar(gds) ## [1] &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;T&quot; &quot;G&quot; &quot;G&quot; &quot;A&quot; &quot;A&quot; &quot;C&quot; altChar(gds) ## [1] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;C&quot; &quot;A&quot; &quot;A&quot; &quot;T&quot; &quot;C&quot; &quot;T&quot; # data.frame of variant information variantInfo(gds) ## variant.id chr pos ref alt ## 1 1 1 970546 C G ## 2 2 1 985900 C T ## 3 3 1 1025045 C T ## 4 4 1 1265550 C T ## 5 5 1 1472676 T C ## 6 6 1 1735725 G A ## 7 7 1 2185887 G A ## 8 8 1 2283689 A T ## 9 9 1 2629401 A C ## 10 10 1 2710895 C T # reset the filter to all variants and samples seqResetFilter(gds) ## # of selected samples: 1,126 ## # of selected variants: 1,120 # how many alleles for each variant? n &lt;- seqNumAllele(gds) table(n) ## n ## 2 3 4 ## 1099 20 1 # some variants have more than one alternate allele multi.allelic &lt;- which(n &gt; 2) altChar(gds)[multi.allelic] ## [1] &quot;GT,G&quot; &quot;G,T&quot; &quot;A,T&quot; ## [4] &quot;A,T&quot; &quot;ATG,ATGTG&quot; &quot;C,G&quot; ## [7] &quot;A,T&quot; &quot;C,T&quot; &quot;A,C&quot; ## [10] &quot;TAA,T&quot; &quot;GTTA,GTTT&quot; &quot;GCC,GCCC,G&quot; ## [13] &quot;A,C&quot; &quot;A,C&quot; &quot;A,C&quot; ## [16] &quot;CAAGCAT,CGAGCAT&quot; &quot;CATTATT,C&quot; &quot;AT,C&quot; ## [19] &quot;TGTGA,C&quot; &quot;CCATT,CCATTCATT&quot; &quot;C,G&quot; # extract a particular alternate allele # first alternate altChar(gds, n=1)[multi.allelic] ## [1] &quot;GT&quot; &quot;G&quot; &quot;A&quot; &quot;A&quot; &quot;ATG&quot; &quot;C&quot; &quot;A&quot; ## [8] &quot;C&quot; &quot;A&quot; &quot;TAA&quot; &quot;GTTA&quot; &quot;GCC&quot; &quot;A&quot; &quot;A&quot; ## [15] &quot;A&quot; &quot;CAAGCAT&quot; &quot;CATTATT&quot; &quot;AT&quot; &quot;TGTGA&quot; &quot;CCATT&quot; &quot;C&quot; # second alternate altChar(gds, n=2)[multi.allelic] ## [1] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;ATGTG&quot; ## [6] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;C&quot; &quot;T&quot; ## [11] &quot;GTTT&quot; &quot;GCCC&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ## [16] &quot;CGAGCAT&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;CCATTCATT&quot; ## [21] &quot;G&quot; # how many variants are SNVs vs INDELs? table(isSNV(gds, biallelic=TRUE)) ## ## FALSE TRUE ## 110 1010 table(isSNV(gds, biallelic=FALSE)) ## ## FALSE TRUE ## 99 1021 # 11 SNVs are multi-allelic We can also return variant information as a GRanges object from the GenomicRanges package. This format for representing sequence data is common across many Bioconductor packages. Chromosome is stored in the seqnames column. The ranges column has variant position, which can be a single base pair or a range. gr &lt;- granges(gds) gr ## GRanges object with 1120 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## 1 1 970546 * ## 2 1 985900 * ## 3 1 1025045 * ## 4 1 1265550 * ## 5 1 1472676 * ## ... ... ... ... ## 1116 1 248715186 * ## 1117 1 248715606-248715610 * ## 1118 1 248761613 * ## 1119 1 248894546 * ## 1120 1 249149558 * ## ------- ## seqinfo: 1 sequence from an unspecified genome; no seqlengths 2.2 Exercises Set a filter selecting only multi-allelic variants. Inspect their genotypes using the different methods you learned above. Use the alleleDosage method to find dosage for the second (and third, etc.) alternate allele. Use the hwe function in SeqVarTools to run a Hardy-Weinberg Equilibrium test on each variant. Identify a variant with low p-value and inspect its genotypes. (Note that the HWE test is only valid for biallelic variants, and will return NA for multiallelic variants.) "],
["gds-solutions.html", "3 GDS - Solutions", " 3 GDS - Solutions Set a filter selecting only multi-allelic variants. Inspect their genotypes using the different methods you learned above. Use the alleleDosage method to find dosage for the second (and third, etc.) alternate allele. seqSetFilter(gds, variant.sel=multi.allelic) ## # of selected variants: 21 geno &lt;- seqGetData(gds, &quot;genotype&quot;) dim(geno) ## [1] 2 1126 21 geno[,1:5,] ## , , 1 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 1 1 0 1 1 ## [2,] 0 1 1 1 1 ## ## , , 2 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 3 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 4 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 1 0 0 1 0 ## [2,] 0 0 0 0 1 ## ## , , 5 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 6 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 7 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 8 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 9 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 2 ## [2,] 0 0 0 0 0 ## ## , , 10 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 0 0 1 ## [2,] 0 2 0 2 1 ## ## , , 11 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 1 0 0 ## [2,] 1 1 0 1 0 ## ## , , 12 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 3 1 1 1 3 ## [2,] 3 3 3 1 0 ## ## , , 13 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 2 0 ## [2,] 0 0 0 0 0 ## ## , , 14 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 15 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 2 0 0 0 2 ## [2,] 0 0 0 2 0 ## ## , , 16 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 2 2 2 2 2 ## [2,] 2 2 2 2 2 ## ## , , 17 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 2 2 2 2 2 ## [2,] 2 2 2 2 2 ## ## , , 18 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 19 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 20 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 1 ## [2,] 0 0 0 0 0 ## ## , , 21 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 2 0 geno &lt;- getGenotype(gds) dim(geno) ## [1] 1126 21 head(geno) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 ## HG00096 &quot;1|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; ## HG00097 &quot;1|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; ## HG00099 &quot;0|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00100 &quot;1|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|2&quot; ## HG00101 &quot;1|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|0&quot; &quot;1|1&quot; ## HG00102 &quot;0|1&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; ## variant ## sample 434 610 627 645 689 756 765 814 988 1014 ## HG00096 &quot;0|1&quot; &quot;3|3&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|0&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00097 &quot;0|1&quot; &quot;1|3&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00099 &quot;1|0&quot; &quot;1|3&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00100 &quot;0|1&quot; &quot;1|1&quot; &quot;2|0&quot; &quot;0|0&quot; &quot;0|2&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00101 &quot;0|0&quot; &quot;3|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|0&quot; &quot;2|2&quot; &quot;2|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;1|0&quot; ## HG00102 &quot;0|1&quot; &quot;3|3&quot; &quot;0|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;2|2&quot; &quot;1|2&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|1&quot; ## variant ## sample 1056 ## HG00096 &quot;0|0&quot; ## HG00097 &quot;0|0&quot; ## HG00099 &quot;0|0&quot; ## HG00100 &quot;0|2&quot; ## HG00101 &quot;0|0&quot; ## HG00102 &quot;0|2&quot; geno &lt;- getGenotypeAlleles(gds) head(geno) ## variant ## sample 30 69 73 161 162 195 243 253 407 ## HG00096 &quot;GT|GTT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;A|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## HG00097 &quot;GT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## HG00099 &quot;GTT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## HG00100 &quot;GT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;A|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## HG00101 &quot;GT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;G|A&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;C|T&quot; ## HG00102 &quot;GTT|GT&quot; &quot;A|A&quot; &quot;G|G&quot; &quot;A|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; &quot;G|G&quot; &quot;T|T&quot; ## variant ## sample 431 434 610 627 645 689 756 ## HG00096 &quot;TAA|TA&quot; &quot;G|GTTA&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;C|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00097 &quot;T|T&quot; &quot;G|GTTA&quot; &quot;GCC|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00099 &quot;TA|TA&quot; &quot;GTTA|G&quot; &quot;GCC|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00100 &quot;TA|T&quot; &quot;G|GTTA&quot; &quot;GCC|GCC&quot; &quot;C|G&quot; &quot;G|G&quot; &quot;G|C&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00101 &quot;TAA|TAA&quot; &quot;G|G&quot; &quot;G|GC&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;C|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## HG00102 &quot;T|T&quot; &quot;G|GTTA&quot; &quot;G|G&quot; &quot;G|C&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;CGAGCAT|CGAGCAT&quot; ## variant ## sample 765 814 988 1014 1056 ## HG00096 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|C&quot; &quot;A|A&quot; ## HG00097 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|C&quot; &quot;A|A&quot; ## HG00099 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|C&quot; &quot;A|A&quot; ## HG00100 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|C&quot; &quot;A|G&quot; ## HG00101 &quot;C|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;CCATT|C&quot; &quot;A|A&quot; ## HG00102 &quot;CATTATT|C&quot; &quot;CT|CT&quot; &quot;CGTGA|CGTGA&quot; &quot;C|CCATT&quot; &quot;A|G&quot; dos &lt;- refDosage(gds) head(dos) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 434 610 627 645 689 756 765 ## HG00096 1 2 2 1 2 2 2 2 2 1 1 0 2 2 1 0 0 ## HG00097 0 2 2 2 2 2 2 2 2 0 1 0 2 2 2 0 0 ## HG00099 1 2 2 2 2 2 2 2 2 2 1 0 2 2 2 0 0 ## HG00100 0 2 2 1 2 2 2 2 2 1 1 0 1 2 1 0 0 ## HG00101 0 2 2 1 2 2 2 2 1 0 2 1 2 2 1 0 0 ## HG00102 1 2 2 1 2 2 2 2 2 0 1 0 1 2 2 0 0 ## variant ## sample 814 988 1014 1056 ## HG00096 2 2 2 2 ## HG00097 2 2 2 2 ## HG00099 2 2 2 2 ## HG00100 2 2 2 1 ## HG00101 2 2 1 2 ## HG00102 2 2 1 1 dos &lt;- altDosage(gds) head(dos) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 434 610 627 645 689 756 765 ## HG00096 1 0 0 1 0 0 0 0 0 1 1 2 0 0 1 2 2 ## HG00097 2 0 0 0 0 0 0 0 0 2 1 2 0 0 0 2 2 ## HG00099 1 0 0 0 0 0 0 0 0 0 1 2 0 0 0 2 2 ## HG00100 2 0 0 1 0 0 0 0 0 1 1 2 1 0 1 2 2 ## HG00101 2 0 0 1 0 0 0 0 1 2 0 1 0 0 1 2 2 ## HG00102 1 0 0 1 0 0 0 0 0 2 1 2 1 0 0 2 2 ## variant ## sample 814 988 1014 1056 ## HG00096 0 0 0 0 ## HG00097 0 0 0 0 ## HG00099 0 0 0 0 ## HG00100 0 0 0 1 ## HG00101 0 0 1 0 ## HG00102 0 0 1 1 dos &lt;- alleleDosage(gds, n=2) head(dos) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 434 610 627 645 689 756 765 ## HG00096 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 ## HG00097 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 2 ## HG00099 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 ## HG00100 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 2 2 ## HG00101 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 2 2 ## HG00102 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 2 1 ## variant ## sample 814 988 1014 1056 ## HG00096 0 0 0 0 ## HG00097 0 0 0 0 ## HG00099 0 0 0 0 ## HG00100 0 0 0 1 ## HG00101 0 0 0 0 ## HG00102 0 0 0 1 dos &lt;- alleleDosage(gds, n=3) head(dos) ## variant ## sample 30 69 73 161 162 195 243 253 407 431 434 610 627 645 689 756 765 ## HG00096 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 ## HG00097 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ## HG00099 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ## HG00100 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## HG00101 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ## HG00102 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 ## variant ## sample 814 988 1014 1056 ## HG00096 0 0 0 0 ## HG00097 0 0 0 0 ## HG00099 0 0 0 0 ## HG00100 0 0 0 0 ## HG00101 0 0 0 0 ## HG00102 0 0 0 0 Use the hwe function in SeqVarTools to run a Hardy-Weinberg Equilibrium test on each variant. Identify a variant with low p-value and inspect its genotypes. (Note that the HWE test is only valid for biallelic variants, and will return NA for multiallelic variants.) seqResetFilter(gds) ## # of selected samples: 1,126 ## # of selected variants: 1,120 hwe.res &lt;- hwe(gds) lowp &lt;- !is.na(hwe.res$p) &amp; hwe.res$p &lt; 1e-4 head(hwe.res[lowp,]) ## variant.id nAA nAa naa afreq p f ## 75 75 702 336 88 0.7726465 1.070663e-06 0.1506466 ## 92 92 632 381 113 0.7304618 3.558878e-06 0.1407120 ## 98 98 672 335 119 0.7455595 2.369695e-12 0.2158342 ## 105 105 93 272 761 0.2033748 7.851777e-16 0.2544970 ## 114 114 299 482 345 0.4795737 1.745346e-06 0.1424409 ## 150 150 471 447 208 0.6167851 8.020208e-08 0.1602251 seqSetFilter(gds, variant.id=75) ## # of selected variants: 1 table(getGenotype(gds)) ## ## 0|0 0|1 1|0 1|1 ## 702 165 171 88 table(refDosage(gds)) ## ## 0 1 2 ## 88 336 702 seqClose(gds) "],
["phenotype-harmonization.html", "4 Phenotype Harmonization 4.1 Inspect individual study data in R 4.2 Compare study values 4.3 Using null models to compare studies 4.4 Final considerations", " 4 Phenotype Harmonization To increase your sample set, you may need to combine phenotype data from different studies in order to run a cross-study analysis. The studies involved may have collected data in different ways, used different protocols or measurement units, or used different cutpoints to determine case status. The process of manipulating the phenotype data from different studies so that they can be analyzed together is called “phenotype harmonization”. In this exercise, we assume that you have created a phenotype harmonization plan for height, sent it to members from three studies to perform the harmonization, and received a harmonized phenotype file from each study. We will generate some diagnostic information about the harmonized phenotype. The exercise uses 1000 Genomes data, with simulated phenotypes for study, age, and height. The example phenotype files shown here are very simplified compared to how actual studies store and organize their their data. In this exercise, we will be using dplyr for a lot of the data manipulation, so load it now. library(dplyr) 4.1 Inspect individual study data in R The first step is to read the files into R for processing. Before we begin, you need to download the data from github so you have access to it. repo_path &lt;- &quot;https://github.com/UW-GAC/topmed_workshop_2018/raw/master&quot; pheno_files &lt;- c(&quot;data/pheno_data_study_1.txt&quot;, &quot;data/pheno_data_study_2.txt&quot;, &quot;data/pheno_data_study_3.txt&quot;) if (!dir.exists(&quot;data&quot;)) dir.create(&quot;data&quot;) for (pheno_file in pheno_files) { if (!file.exists(pheno_file)) download.file(file.path(repo_path, pheno_file), pheno_file) } Next, read the study phenotype files into R. In this case, each file is tab-delimited. study_1 &lt;- read.table(&quot;data/pheno_data_study_1.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, as.is = TRUE) head(study_1) ## subject_id sex age height ## 1 HG00096 M 47 165.3 ## 2 HG00102 F 49 169.1 ## 3 HG00112 M 46 167.9 ## 4 HG00114 M 49 169.5 ## 5 HG00115 M 35 161.1 ## 6 HG00116 M 37 182.2 study_2 &lt;- read.table(&quot;data/pheno_data_study_2.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, as.is = TRUE) head(study_2) ## subject_id Sex Age Height ## 1 HG00099 F 40 185.5 ## 2 HG00103 M 50 190.8 ## 3 HG00106 F 51 165.5 ## 4 HG00107 M 39 195.8 ## 5 HG00109 M 48 181.5 ## 6 HG00111 F 42 194.9 study_3 &lt;- read.table(&quot;data/pheno_data_study_3.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, as.is = TRUE) head(study_3) ## subject_id sex age height ## 1 HG00097 F 47 57.0 ## 2 HG00100 F 45 59.3 ## 3 HG00101 M 40 70.0 ## 4 HG00105 M 34 62.4 ## 5 HG00108 M 47 66.3 ## 6 HG00110 F 44 62.7 Look carefully at the output and see if anything looks suspicious. You may have noticed that one of the studies has given their variables slightly different names than the others. Rename them as appropriate. names(study_2) ## [1] &quot;subject_id&quot; &quot;Sex&quot; &quot;Age&quot; &quot;Height&quot; study_2 &lt;- study_2 %&gt;% rename(sex = Sex, age = Age, height = Height) # Check that they are correct. names(study_2) ## [1] &quot;subject_id&quot; &quot;sex&quot; &quot;age&quot; &quot;height&quot; You’ll also want to calculate summaries of the data values to see if anything looks very different than what you expect. summary(study_1$height) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 139.6 163.8 169.9 170.2 176.7 200.3 summary(study_2$height) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 142.1 171.8 181.3 180.8 190.5 218.6 summary(study_3$height) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 47.00 59.60 63.40 63.42 67.10 79.60 Here, the values that study_3 has given you don’t seem to have the same range as those from study_1 and study_2. In cases like this, you’ll want to follow up with whoever provided the harmonized data to see what’s going on. It could represent an error in calculating the harmonized data values, a true property of the study (e.g., a study containing all children), or something else. In this case, the values were measured in inches instead of centimeters, so they will need to be converted to centimeters to be compatible with the other studies. study_3 &lt;- study_3 %&gt;% mutate(height = height * 2.54) Calculate the summary again and compare it to the other studies above. summary(study_3$height) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 119.4 151.4 161.0 161.1 170.4 202.2 The corrected values look much more similar now. Note that this sort of error is easy to correct, but it is not uncommon to have more subtle issues that need to be addressed when working with phenotype data. Knowledge of the study design as well as the phenotype area of interest is essential to address them properly. Additionally, different decisions may need to be made for different analyses based on the specific questions they are trying to answer. 4.2 Compare study values Next we will make some more direct comparisons between the three studies, so we will combine the data into one data frame. First, add a study identifier to the data frame for organizational purposes. study_1$study &lt;- &quot;study_1&quot; study_2$study &lt;- &quot;study_2&quot; study_3$study &lt;- &quot;study_3&quot; Combine the three different study data frames into one large data frame for joint analysis. Double check that all column names are the same. all.equal(names(study_1), names(study_2)) ## [1] TRUE all.equal(names(study_1), names(study_3)) ## [1] TRUE phen &lt;- dplyr::bind_rows(study_1, study_2, study_3) We can look at the distribution of phenotype data with text-based reports or with plots. First, inspect distributions with table for categorical traits and with summary for quantitative traits. The commads are shown here for study_1, but you should run them for study_2 and study_3 as well to see if you can see any differences. table(study_1$sex) ## ## F M ## 190 185 summary(study_1$age) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 32.00 41.00 45.00 45.17 49.00 62.00 summary(study_1$height) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 139.6 163.8 169.9 170.2 176.7 200.3 It is also helpful to use plots to inspect the distributions of phenotype data. Here, we will look at boxplots of height by study. library(ggplot2) ggplot(phen, aes(x = study, y = height)) + geom_boxplot() You may also want to see the difference in height when you include both study and sex: ggplot(phen, aes(x = study, fill = sex, y = height)) + geom_boxplot() These diagnostics are helpful to get a feel for the data. They can help you see if one study is vastly different from the others or detect outlier values that you may want to look into further. Some of the differences could also be accounted for by covariates. 4.3 Using null models to compare studies The quick diagnostics in the previous section let you see if the data from one study are completely different from the others, but such differences could be due to other factors that could be adjusted for in analysis. To account for these other factors, we need to fit a statistical model to the data. Because some of the studies in TOPMed have related individuals, we need to fit a null model to account for the correlation in the data. In this case, because the phenotype is quantitative, we will use a linear model. We use the GENESIS R package for fitting the null model. It is also the same package that we use for the association analyses, so this exercise provides a brief introduction to the package and some of the associated data structures. 4.3.1 Create an Annotated Data Frame The first step in fitting the null model is to create an AnnotatedDataFrame. This data structure is provided by the Bioconductor Biobase package, and it contains both the data and metadata. You should include a description of each variable in the metadata. library(Biobase) metadata &lt;- data.frame(labelDescription = c( &quot;subject identifier&quot;, &quot;subject&#39;s sex&quot;, &quot;age at measurement of height&quot;, &quot;subject&#39;s height in cm&quot;, &quot;study identifier&quot; )) annot &lt;- AnnotatedDataFrame(phen, metadata) # access the data with the pData() function head(pData(annot)) ## subject_id sex age height study ## 1 HG00096 M 47 165.3 study_1 ## 2 HG00102 F 49 169.1 study_1 ## 3 HG00112 M 46 167.9 study_1 ## 4 HG00114 M 49 169.5 study_1 ## 5 HG00115 M 35 161.1 study_1 ## 6 HG00116 M 37 182.2 study_1 # access the metadata with the varMetadata() function varMetadata(annot) ## labelDescription ## subject_id subject identifier ## sex subject&#39;s sex ## age age at measurement of height ## height subject&#39;s height in cm ## study study identifier Save the AnnotatedDataFrame for future use. save(annot, file = &quot;data/phenotype_annotation.RData&quot;) The GENESIS code to fit the null model also requires a sample.id column. Typically the sample.id column represents a sample identifier, not a subject id. In this case, we are only working with subject-level data, so we can use the subject identifier as the sample identifier for model-fitting purposes. annot$sample.id &lt;- annot$subject_id 4.3.2 Fit a null model without study We will first fit a null model that allows us to see if the mean of the height phenotype is different by study after adjusting for other covariates. In this case, we will adjust for age and sex, but not for study, because we are interested in seeing differences in mean height by study. We will also include the genetic relatedness matrix as a random effect to account for relatedness between the participants. outcome &lt;- &quot;height&quot; covars &lt;- c(&quot;sex&quot;, &quot;age&quot;) library(GENESIS) mod_1 &lt;- GENESIS::fitNullModel(annot, outcome = outcome, covars = covars) The output of fitNullModel is a list with a number of named elements names(mod_1) ## [1] &quot;family&quot; &quot;hetResid&quot; &quot;varComp&quot; &quot;varCompCov&quot; ## [5] &quot;fixef&quot; &quot;betaCov&quot; &quot;fitted.values&quot; &quot;resid.marginal&quot; ## [9] &quot;logLik&quot; &quot;AIC&quot; &quot;workingY&quot; &quot;outcome&quot; ## [13] &quot;model.matrix&quot; &quot;group.idx&quot; &quot;cholSigmaInv&quot; &quot;converged&quot; ## [17] &quot;zeroFLAG&quot; &quot;RSS&quot; &quot;Ytilde&quot; &quot;resid&quot; ## [21] &quot;CX&quot; &quot;CXCXI&quot; &quot;sample.id&quot; The elements that we will work with in this exercise are: converged: an indicator of whether the model successfully converged model.matrix: The matrix of subject-covariate values used to fit the model fixef: The fitted fixed effects betaCov: The covariance of the fitted fixed effects resid.marginal: The (marginal) residuals from the model, which have been adjusted for the fixed effects but not for the covariance structure varComp: The fitted variance components Make sure the model converged. mod_1$converged ## [1] TRUE Now, add the residuals to the phenotype data frame for plotting. We need to make sure that we are matching each residual value to the correct subject. In this case, we already ordered the AnnotatedDataFrame to match the genetic relatedness marix, but this may not always be the case (for example, if subjects are excluded due to missing phentoype data). To match the same subject’s values together, we use the row names of the model.matrix element of the output, which are in the same order as the residual matrix, and the subject_id column of the annotated data frame. We then match the row names (and therefore the residuals) to the subject identifier in the phenotype file using the base R function match. j &lt;- match(annot$subject_id, rownames(mod_1$model.matrix)) annot$residuals &lt;- mod_1$resid.marginal[j] Next, we want to check if the different studies have the same mean height after adjustment for other covariates (here, age and sex). We will first do this qualitatively by making a boxplot of the residuals by study. ggplot(pData(annot), aes(x = study, y = residuals)) + geom_boxplot() From the boxplot, it is clear that the different studies have different mean heights, even after adjustment for sex and age. At this point, you would need to determine if the differences are acceptable for use in a combined analysis. 4.3.3 Fit a model with study Next, we can look at a model that adjusts for other covariates as well as study. This model allows us to run a statistical test on the fitted study means and to qualitatively check if the variances are the same after adjusting for mean effects. The outcome is the same, but we now add the study as a covariate. We also allow for group-specific residual variance by study using the group.var argument to fitNullModel. # include the study in the covariates covars &lt;- c(&quot;age&quot;, &quot;sex&quot;, &quot;study&quot;) mod_2 &lt;- GENESIS::fitNullModel(annot, outcome = outcome, covars = covars, group.var = &quot;study&quot;) The fixef element now includes effects for study: mod_2$fixef ## Est SE Stat pval ## (Intercept) 163.67175933 3.18936046 2633.542254 0.000000e+00 ## age 0.07519782 0.06921691 1.180283 2.772984e-01 ## sexM 6.28764510 0.68812251 83.491933 6.397652e-20 ## studystudy_2 10.63152325 0.82176939 167.375183 2.769991e-38 ## studystudy_3 -8.96183691 0.84479021 112.537257 2.724960e-26 The null model also shows the differences in mean height by study. Finally, we want to check if the height distributions from the different studies have the same variance. Start by looking at the variance components (varComp) element of the model. mod_2$varComp ## study_1 study_2 study_3 ## 98.20192 155.70722 168.82045 The variance components (V_study_1, V_study_2, and V_study_3) represent the residual variance in each study. The fitted values of the variance components are different for the different studies, indicating that the distributions of height in the three studies have different variance even after accounting for the other covariates. We can also show the same information by plotting the residuals by study. We first have to add the residuals from this model to the AnnotatedDataFrame. annot$residuals &lt;- mod_2$resid.marginal Next make a boxplot of the residuals by study. ggplot(pData(annot), aes(x = study, y = residuals)) + geom_boxplot() Both methods of looking at the variance components indicate that study 1 has a smaller residual variance than the others. 4.4 Final considerations We have determined that the different studies have both different mean and different variance by study for height. Before performing genotype-phenotype association tests with these data, you would need to think carefully about whether the phenotype is homogeneous enough to be analyzed together. In some cases, there may be a valid reason for different means or variances, for example: different heights in different study populations, such as a study composed primarily of Asian participants vs. a study with primarily European participants or a study of all men vs. a study of all women; possible secular trends in height, such as comparing the Framingham Original cohort from ~1950 to a cohort from the present day. In other cases, there may be good reasons to exclude one or more studies, for example: a systematic measurement error in one study miscalculation or misinterpretation of the harmonization algorithm study populations that are too different to be compared, such as trying to include a study composed primarily of children with one composed of adults in a height analysis It may be necessary to look at other variables that you had not previously considered. Studies may have used different measurement equipment or calibrated their data differently. There might also be other batch effects due to lab procedures or assays that could result in differences in the variance or mean by study. The other variables that you may need to consider are highly dependent both on the phenotype being harmonized and on how a given study has been designed. Unfortunately there is no single set of guidelines you can use to decide how to proceed with analysis of a phenotype. It is necessary to involve both domain experts and study experts to determine whether the phenotype is homogeneous enough to use in cross-study analysis. "],
["association-tests.html", "5 Association tests 5.1 Null model 5.2 Single-variant tests 5.3 Exercises 5.4 Sliding window tests 5.5 Exercise", " 5 Association tests These exercises introduce association testing: how to find which genetic variants are associated with a phenotype. 5.1 Null model The first step in an association test is to fit the null model. We will need an AnnotatedDataFrame with phenotypes. We have a sample annotation with a sample.id column matched to the GDS file, and a phenotype file with subject_id. (In this example, we use the 1000 Genomes IDs for both sample and subject ID.) For TOPMed data, it is also important to match by study, as subject IDs are not unique across studies. # sample annotation workshop.path &lt;- &quot;https://github.com/UW-GAC/topmed_workshop_2018/raw/master&quot; sampfile &lt;- &quot;data/sample_annotation.RData&quot; if (!dir.exists(&quot;data&quot;)) dir.create(&quot;data&quot;) if (!file.exists(sampfile)) download.file(file.path(workshop.path, sampfile), sampfile) annot &lt;- TopmedPipeline::getobj(sampfile) library(Biobase) head(pData(annot)) ## sample.id subject.id Population Population.Description sex ## 1 HG00096 HG00096 GBR British in England and Scotland M ## 2 HG00097 HG00097 GBR British in England and Scotland F ## 3 HG00099 HG00099 GBR British in England and Scotland F ## 4 HG00100 HG00100 GBR British in England and Scotland F ## 5 HG00101 HG00101 GBR British in England and Scotland M ## 6 HG00102 HG00102 GBR British in England and Scotland F ## status ## 1 0 ## 2 1 ## 3 0 ## 4 1 ## 5 0 ## 6 0 # phenotypes by subject ID phenfile &lt;- &quot;data/phenotype_annotation.RData&quot; if (!file.exists(phenfile)) download.file(file.path(workshop.path, phenfile), phenfile) phen &lt;- TopmedPipeline::getobj(phenfile) # access the data with the pData() function head(pData(phen)) ## subject_id sex age height study ## 1 HG00096 M 47 165.3 study_1 ## 2 HG00102 F 49 169.1 study_1 ## 3 HG00112 M 46 167.9 study_1 ## 4 HG00114 M 49 169.5 study_1 ## 5 HG00115 M 35 161.1 study_1 ## 6 HG00116 M 37 182.2 study_1 # access the metadata with the varMetadata() function varMetadata(phen) ## labelDescription ## subject_id subject identifier ## sex subject&#39;s sex ## age age at measurement of height ## height subject&#39;s height in cm ## study study identifier # merge sample annotation with phenotypes library(dplyr) dat &lt;- pData(annot) %&gt;% left_join(pData(phen), by=c(&quot;subject.id&quot;=&quot;subject_id&quot;, &quot;sex&quot;=&quot;sex&quot;)) meta &lt;- bind_rows(varMetadata(annot), varMetadata(phen)[3:5,,drop=FALSE]) annot &lt;- AnnotatedDataFrame(dat, meta) save(annot, file=&quot;data/sample_phenotype_annotation.RData&quot;) We will test for an association between genotype and height, adjusting for sex, age, and study as covariates. If the sample set involves multiple distinct groups with different variances for the phenotype, we recommend allowing the model to use heterogeneous variance among groups with the parameter group.var. We saw in a previous exercise that the variance differs by study. library(GENESIS) nullmod &lt;- fitNullModel(annot, outcome=&quot;height&quot;, covars=c(&quot;sex&quot;, &quot;age&quot;, &quot;study&quot;), group.var=&quot;study&quot;, verbose=FALSE) save(nullmod, file=&quot;data/null_model.RData&quot;) We also recommend taking an inverse normal transform of the residuals and refitting the model. See the full procedure in the pipeline documentation. 5.2 Single-variant tests Now that we have a null model adjusting height for covariates, we can run an association test to look for genetic effects on height. Single-variant tests are the same as in GWAS. We use the assocTestSingle function in GENESIS. First, we have to create a SeqVarData object including both the GDS file and the sample annotation containing phenotypes. We then create a SeqVarBlockIterator object to iterate over blocks of variants. library(SeqVarTools) gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; if (!file.exists(gdsfile)) download.file(file.path(data.path, basename(gdsfile)), gdsfile) gds &lt;- seqOpen(gdsfile) seqData &lt;- SeqVarData(gds, sampleData=annot) iterator &lt;- SeqVarBlockIterator(seqData, verbose=FALSE) assoc &lt;- assocTestSingle(iterator, nullmod) ## # of selected samples: 1,126 head(assoc) ## variant.id chr pos allele.index n.obs freq Score ## 1 1 1 970546 1 1126 0.0039964476 -0.1191236 ## 2 2 1 985900 1 1126 0.0492895204 -1.6707553 ## 3 3 1 1025045 1 1126 0.0004440497 -0.2795838 ## 4 4 1 1265550 1 1126 0.0008880995 -0.1105487 ## 5 5 1 1472676 1 1126 0.0071047957 0.3630992 ## 6 6 1 1735725 1 1126 0.0022202487 -0.1300405 ## Score.SE Score.Stat Score.pval ## 1 0.2577712 -0.4621292 0.643988703 ## 2 0.8841849 -1.8895995 0.058811539 ## 3 0.1007173 -2.7759261 0.005504472 ## 4 0.1085480 -1.0184319 0.308472754 ## 5 0.3456555 1.0504657 0.293504072 ## 6 0.1973175 -0.6590420 0.509868791 We make a QQ plot to examine the results. library(ggplot2) qqPlot &lt;- function(pval) { pval &lt;- pval[!is.na(pval)] n &lt;- length(pval) x &lt;- 1:n dat &lt;- data.frame(obs=sort(pval), exp=x/n, upper=qbeta(0.025, x, rev(x)), lower=qbeta(0.975, x, rev(x))) ggplot(dat, aes(-log10(exp), -log10(obs))) + geom_line(aes(-log10(exp), -log10(upper)), color=&quot;gray&quot;) + geom_line(aes(-log10(exp), -log10(lower)), color=&quot;gray&quot;) + geom_point() + geom_abline(intercept=0, slope=1, color=&quot;red&quot;) + xlab(expression(paste(-log[10], &quot;(expected P)&quot;))) + ylab(expression(paste(-log[10], &quot;(observed P)&quot;))) + theme_bw() } qqPlot(assoc$Score.pval) 5.3 Exercises Logistic regression: fitNullModel can use a binary phenotype as the outcome variable by specifying the argument family=binomial. Use the status column in the sample annotation to fit a null model for simulated case/control status, with sex and Population as covariates. Then run a single-variant test using this model. Inverse normal transform: use the function nullModelInvNorm to perform an inverse normal transform on the height variable. For each study separately, compute a null model and do the inverse normal transform using just the values for that study. Compare these residuals with the initial residuals you obtained for that study by transforming all studies together. 5.4 Sliding window tests For rare variants, we can do burden tests or SKAT using the GENESIS function assocTestAggregate. We restrict the test to variants with alternate allele frequency &lt; 0.1. (For real data, this threshold would be lower.) We use a flat weighting scheme. We define a sliding window across the genome using a SeqVarWindowIterator. seqResetFilter(seqData, verbose=FALSE) seqSetFilter(seqData, variant.sel=1:100) # temporary for build speed ## # of selected variants: 100 iterator &lt;- SeqVarWindowIterator(seqData, windowSize=5000, windowShift=2000, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;Burden&quot;, AF.max=0.1, weight.beta=c(1,1)) ## # of selected samples: 1,126 names(assoc) ## [1] &quot;results&quot; &quot;variantInfo&quot; head(assoc$results) ## chr start end n.site n.alt n.sample.alt Score Score.SE ## 1 1 966001 971000 1 9 9 -0.1191236 0.2577712 ## 2 1 982001 987000 1 111 107 -1.6707553 0.8841849 ## 3 1 1022001 1027000 1 1 1 -0.2795838 0.1007173 ## 4 1 1262001 1267000 1 2 2 -0.1105487 0.1085480 ## 5 1 1468001 1473000 1 16 16 0.3630992 0.3456555 ## 6 1 1732001 1737000 1 5 5 -0.1300405 0.1973175 ## Score.Stat Score.pval ## 1 -0.4621292 0.643988703 ## 2 -1.8895995 0.058811539 ## 3 -2.7759261 0.005504472 ## 4 -1.0184319 0.308472754 ## 5 1.0504657 0.293504072 ## 6 -0.6590420 0.509868791 head(assoc$variantInfo) ## [[1]] ## variant.id chr pos allele.index n.obs freq weight ## 1 1 1 970546 1 1126 0.003996448 1 ## ## [[2]] ## variant.id chr pos allele.index n.obs freq weight ## 1 2 1 985900 1 1126 0.04928952 1 ## ## [[3]] ## variant.id chr pos allele.index n.obs freq weight ## 1 3 1 1025045 1 1126 0.0004440497 1 ## ## [[4]] ## variant.id chr pos allele.index n.obs freq weight ## 1 4 1 1265550 1 1126 0.0008880995 1 ## ## [[5]] ## variant.id chr pos allele.index n.obs freq weight ## 1 5 1 1472676 1 1126 0.007104796 1 ## ## [[6]] ## variant.id chr pos allele.index n.obs freq weight ## 1 6 1 1735725 1 1126 0.002220249 1 qqPlot(assoc$results$Score.pval) For SKAT, we use the Wu weights. seqResetFilter(seqData, verbose=FALSE) seqSetFilter(seqData, variant.sel=1:100) # temporary for build speed ## # of selected variants: 100 iterator &lt;- SeqVarWindowIterator(seqData, windowSize=5000, windowShift=2000, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;SKAT&quot;, AF.max=0.1, weight.beta=c(1,25)) ## # of selected samples: 1,126 head(assoc$results) ## chr start end n.site n.alt n.sample.alt Q_0 pval_0 ## 1 1 966001 971000 1 9 9 7.318094 0.643988703 ## 2 1 982001 987000 1 111 107 154.178280 0.058811539 ## 3 1 1022001 1027000 1 1 1 47.823916 0.005504472 ## 4 1 1262001 1267000 1 2 2 7.319239 0.308472754 ## 5 1 1468001 1473000 1 16 16 58.518662 0.293504072 ## 6 1 1732001 1737000 1 5 5 9.499539 0.509868791 ## err_0 ## 1 0 ## 2 0 ## 3 0 ## 4 0 ## 5 0 ## 6 0 head(assoc$variantInfo) ## [[1]] ## variant.id chr pos allele.index n.obs freq weight ## 1 1 1 970546 1 1126 0.003996448 22.70917 ## ## [[2]] ## variant.id chr pos allele.index n.obs freq weight ## 1 2 1 985900 1 1126 0.04928952 7.431881 ## ## [[3]] ## variant.id chr pos allele.index n.obs freq weight ## 1 3 1 1025045 1 1126 0.0004440497 24.73493 ## ## [[4]] ## variant.id chr pos allele.index n.obs freq weight ## 1 4 1 1265550 1 1126 0.0008880995 24.47255 ## ## [[5]] ## variant.id chr pos allele.index n.obs freq weight ## 1 5 1 1472676 1 1126 0.007104796 21.06793 ## ## [[6]] ## variant.id chr pos allele.index n.obs freq weight ## 1 6 1 1735725 1 1126 0.002220249 23.70132 qqPlot(assoc$results$pval) 5.5 Exercise Repeat the previous exercise on logistic regression, this time running a sliding-window test. "],
["association-tests-solutions.html", "6 Association tests - Solutions", " 6 Association tests - Solutions Logistic regression: fitNullModel can use a binary phenotype as the outcome variable by specifying the argument family=binomial. Use the status column in the sample annotation to fit a null model for simulated case/control status, with sex and Population as covariates. Then run a single-variant test using this model. nullmod.status &lt;- fitNullModel(annot, outcome=&quot;status&quot;, covars=c(&quot;sex&quot;, &quot;Population&quot;), family=binomial, verbose=FALSE) resetIterator(iterator, verbose=FALSE) assoc &lt;- assocTestSingle(iterator, nullmod.status, test=&quot;Score&quot;) ## # of selected samples: 1,126 head(assoc) ## variant.id chr pos allele.index n.obs freq Score ## 1 1 1 970546 1 1126 0.0039964476 0.20256722 ## 2 2 1 985900 1 1126 0.0492895204 -2.64169956 ## 3 3 1 1025045 1 1126 0.0004440497 -0.09916904 ## 4 4 1 1265550 1 1126 0.0008880995 0.81717324 ## 5 5 1 1472676 1 1126 0.0071047957 0.64418361 ## 6 6 1 1735725 1 1126 0.0022202487 -0.46319177 ## Score.SE Score.Stat Score.pval ## 1 0.8351783 0.2425437 0.80835892 ## 2 2.6522412 -0.9960254 0.31923781 ## 3 0.2972472 -0.3336248 0.73866267 ## 4 0.4033577 2.0259271 0.04277226 ## 5 1.0778277 0.5976685 0.55006117 ## 6 0.6396675 -0.7241134 0.46899613 Inverse normal transform: use the function nullModelInvNorm to perform an inverse normal transform on the height variable. For each study separately, compute a null model and do the inverse normal transform using just the values for that study. Compare these residuals with the initial residuals you obtained for that study by transforming all studies together. nullmod.norm.all &lt;- nullModelInvNorm(nullmod, norm.option=&quot;all&quot;) ## [1] 9.820192e+01 1.688205e+02 1.557072e+02 -1.594449e+03 7.121886e-03 ## [1] 6.589593e+01 1.133736e+02 1.041592e+02 -1.594448e+03 1.062165e-02 ## [1] 1.803149e+01 3.074952e+01 2.833099e+01 -1.594449e+03 3.900962e-02 ## [1] 4.1049491 7.1379995 6.5358236 -1594.4570600 0.1694962 ## [1] 1.6142560 2.7337514 2.5244988 -1594.4552547 0.4374396 ## [1] 0.5632642 0.9931480 0.9053847 -1594.4853681 1.2257174 ## [1] 0.674084 1.166026 1.069539 -1594.451312 1.035168 ## [1] 0.7001643 1.2013683 1.1047080 -1594.4476450 1.0011670 ## [1] 0.7012065 1.2024767 1.1059074 -1594.4476292 1.0000014 ## [1] 0.7012077 1.2024780 1.1059090 -1594.4476292 1.0000000 dat.all &lt;- data.frame(sample.id=nullmod.norm.all$sample.id, resid.norm=nullmod.norm.all$resid.marginal, study=annot$study, run=&quot;combined&quot;) nullmod.norm.group &lt;- nullModelInvNorm(nullmod, norm.option=&quot;by.group&quot;) ## [1] 9.820192e+01 1.688205e+02 1.557072e+02 -1.624686e+03 7.516645e-03 ## [1] 6.599547e+01 1.133069e+02 1.041241e+02 -1.624502e+03 1.120455e-02 ## [1] 3.254107e+01 1.394878e+01 2.030342e+01 -1.640619e+03 5.058311e-02 ## [1] 0.4823649 8.3127679 8.0728042 -2113.8412464 0.7725567 ## [1] 0.5136907 0.7135928 0.9316405 -1624.7322739 1.4746195 ## [1] 0.7639307 0.9183081 0.9959743 -1611.5285780 1.1349499 ## [1] 0.9450453 0.9939501 1.0009186 -1608.2035095 1.0221048 ## [1] 0.9979798 1.0007589 1.0010808 -1608.0188191 1.0010636 ## [1] 1.001052 1.000829 1.001116 -1608.018248 1.000003 ## [1] 1.001058 1.000831 1.001118 -1608.018248 1.000000 dat.group &lt;- data.frame(sample.id=nullmod.norm.group$sample.id, resid.norm=nullmod.norm.group$resid.marginal, study=annot$study, run=&quot;separate&quot;) dat &lt;- rbind(dat.all, dat.group) ggplot(dat, aes(study, resid.norm, fill=run)) + geom_boxplot() Repeat the previous exercise on logistic regression, this time running a sliding-window test. nullmod.status &lt;- fitNullModel(annot, outcome=&quot;status&quot;, covars=c(&quot;sex&quot;, &quot;Population&quot;), family=binomial, verbose=FALSE) seqResetFilter(seqData, verbose=FALSE) seqSetFilter(seqData, variant.sel=1:100) # temporary for build speed ## # of selected variants: 100 iterator &lt;- SeqVarWindowIterator(seqData, windowSize=5000, windowShift=2000, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;SKAT&quot;, AF.max=0.1, weight.beta=c(1,25)) ## # of selected samples: 1,126 head(assoc$results) ## chr start end n.site n.alt n.sample.alt Q_0 pval_0 ## 1 1 966001 971000 1 9 9 7.318094 0.643988703 ## 2 1 982001 987000 1 111 107 154.178280 0.058811539 ## 3 1 1022001 1027000 1 1 1 47.823916 0.005504472 ## 4 1 1262001 1267000 1 2 2 7.319239 0.308472754 ## 5 1 1468001 1473000 1 16 16 58.518662 0.293504072 ## 6 1 1732001 1737000 1 5 5 9.499539 0.509868791 ## err_0 ## 1 0 ## 2 0 ## 3 0 ## 4 0 ## 5 0 ## 6 0 seqClose(gds) "],
["computing-a-grm.html", "7 Computing a GRM", " 7 Computing a GRM We can use the SNPRelate package to compute a Genetic Relationship matrix (GRM). This method combines relatedness due to more distant ancestry and recent kinship into a single matrix. library(SeqArray) gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; gds &lt;- seqOpen(gdsfile) library(SNPRelate) grm &lt;- snpgdsGRM(gds, method=&quot;GCTA&quot;) ## Genetic Relationship Matrix (GRM, GCTA): ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Excluding 13 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 1,126 samples, 1,107 SNVs ## using 1 (CPU) core ## CPU capabilities: Double-Precision SSE2 ## Thu Jun 13 15:19:24 2019 (internal increment: 664) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Thu Jun 13 15:19:24 2019 Done. names(grm) ## [1] &quot;sample.id&quot; &quot;snp.id&quot; &quot;method&quot; &quot;grm&quot; dim(grm$grm) ## [1] 1126 1126 seqClose(gds) "],
["pc-relate.html", "8 PC-Relate 8.1 KING 8.2 PC-AiR 8.3 PC-Relate 8.4 Comparison with pedigree 8.5 Exercise", " 8 PC-Relate To disentangle ancestry from recent familial relatedness, we use the PC-Relate method. 8.1 KING Step 1 is to get initial estimates of kinship using KING, which is robust to population structure but not admixture. The KING algorithm is available in SNPRelate. We select a subset of variants for this calculation with LD pruning. # use a GDS file with all chromosomes library(SeqArray) gdsfile &lt;- &quot;data/1KG_phase3_subset.gds&quot; gds &lt;- seqOpen(gdsfile) # use a subset of 100 samples to make things run faster sampfile &lt;- &quot;data/samples_subset100.RData&quot; sample.id &lt;- TopmedPipeline::getobj(sampfile) # LD pruning to get variant set library(SNPRelate) set.seed(100) # LD pruning has a random element; so make this reproducible snpset &lt;- snpgdsLDpruning(gds, sample.id=sample.id, method=&quot;corr&quot;, slide.max.bp=10e6, ld.threshold=sqrt(0.1)) ## SNV pruning based on LD: ## Excluding 1,120 SNVs on non-autosomes ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 1s ## Excluding 13,673 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 100 samples, 10,967 SNVs ## using 1 (CPU) core ## sliding window: 10,000,000 basepairs, Inf SNPs ## |LD| threshold: 0.316228 ## method: correlation ## Chromosome 1: 31.34%, 351/1,120 ## Chromosome 2: 31.43%, 352/1,120 ## Chromosome 3: 30.98%, 347/1,120 ## Chromosome 4: 31.16%, 349/1,120 ## Chromosome 5: 29.64%, 332/1,120 ## Chromosome 6: 31.43%, 352/1,120 ## Chromosome 7: 28.66%, 321/1,120 ## Chromosome 8: 25.62%, 287/1,120 ## Chromosome 9: 27.32%, 306/1,120 ## Chromosome 10: 28.57%, 320/1,120 ## Chromosome 11: 26.79%, 300/1,120 ## Chromosome 12: 28.66%, 321/1,120 ## Chromosome 13: 25.54%, 286/1,120 ## Chromosome 14: 24.29%, 272/1,120 ## Chromosome 15: 22.59%, 253/1,120 ## Chromosome 16: 21.88%, 245/1,120 ## Chromosome 17: 21.79%, 244/1,120 ## Chromosome 18: 23.57%, 264/1,120 ## Chromosome 19: 21.25%, 238/1,120 ## Chromosome 20: 20.00%, 224/1,120 ## Chromosome 21: 17.50%, 196/1,120 ## Chromosome 22: 17.50%, 196/1,120 ## 6,356 markers are selected in total. sapply(snpset, length) ## chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 ## 351 352 347 349 332 352 321 287 306 320 300 321 ## chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 ## 286 272 253 245 244 264 238 224 196 196 pruned &lt;- unlist(snpset, use.names=FALSE) # KING king &lt;- snpgdsIBDKING(gds, sample.id=sample.id, snp.id=pruned) ## IBD analysis (KING method of moment) on genotypes: ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Working space: 100 samples, 6,356 SNVs ## using 1 (CPU) core ## No family is specified, and all individuals are treated as singletons. ## Relationship inference in the presence of population stratification. ## CPU capabilities: Double-Precision SSE2 ## Thu Jun 13 15:19:25 2019 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 1s ## Thu Jun 13 15:19:26 2019 Done. names(king) ## [1] &quot;sample.id&quot; &quot;snp.id&quot; &quot;afreq&quot; &quot;IBS0&quot; &quot;kinship&quot; dim(king$kinship) ## [1] 100 100 kingMat &lt;- king$kinship colnames(kingMat) &lt;- rownames(kingMat) &lt;- king$sample.id We extract pairwise kinship estimates and IBS0 to plot. kinship &lt;- snpgdsIBDSelection(king) head(kinship) ## ID1 ID2 IBS0 kinship ## 1 HG00110 HG00116 0.02564506 -0.01271186 ## 2 HG00110 HG00120 0.02721838 -0.02814770 ## 3 HG00110 HG00128 0.02454374 -0.01150121 ## 4 HG00110 HG00136 0.02926369 -0.04388620 ## 5 HG00110 HG00137 0.02737571 -0.03510896 ## 6 HG00110 HG00141 0.02769037 -0.03843826 library(ggplot2) ggplot(kinship, aes(IBS0, kinship)) + geom_hline(yintercept=2^(-seq(3,9,2)/2), linetype=&quot;dashed&quot;, color=&quot;grey&quot;) + geom_point(alpha=0.5) + ylab(&quot;kinship estimate&quot;) + theme_bw() 8.2 PC-AiR The next step is PC-AiR, in which we select a set of unrelated samples that is maximally informative about all ancestries in the sample. We use this unrelated set for Principal Component Analysis (PCA), then project the relatives onto the PCs. First, we partition the samples into a related and unrelated set. We use a kinship threshold of degree 3, which corresponds to first cousins. This defines anyone less related than first cousins as “unrelated”. We load the GENESIS package. In the first iteration, we use the KING estimates for both kinship (kinMat) and ancestry divergence (divMat). KING kinship estimates are negative for samples with different ancestry. library(GENESIS) sampset &lt;- pcairPartition(kinobj=kingMat, kin.thresh=2^(-9/2), divobj=kingMat, div.thresh=-2^(-9/2)) names(sampset) ## [1] &quot;rels&quot; &quot;unrels&quot; sapply(sampset, length) ## rels unrels ## 15 85 Using the SNPRelate package, we run PCA on the unrelated set and project values for the related set. We use the same LD pruned set of variants again. # run PCA on unrelated set pca.unrel &lt;- snpgdsPCA(gds, sample.id=sampset$unrels, snp.id=pruned) ## Principal Component Analysis (PCA) on genotypes: ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Excluding 223 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 85 samples, 6,133 SNVs ## using 1 (CPU) core ## CPU capabilities: Double-Precision SSE2 ## Thu Jun 13 15:19:26 2019 (internal increment: 8816) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 1s ## Thu Jun 13 15:19:27 2019 Begin (eigenvalues and eigenvectors) ## Thu Jun 13 15:19:27 2019 Done. # project values for relatives snp.load &lt;- snpgdsPCASNPLoading(pca.unrel, gdsobj=gds) ## SNP loading: ## Working space: 85 samples, 6133 SNPs ## using 1 (CPU) core ## using the top 32 eigenvectors ## Thu Jun 13 15:19:27 2019 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Thu Jun 13 15:19:27 2019 Done. samp.load &lt;- snpgdsPCASampLoading(snp.load, gdsobj=gds, sample.id=sampset$rels) ## Sample loading: ## Working space: 15 samples, 6133 SNPs ## using 1 (CPU) core ## using the top 32 eigenvectors ## Thu Jun 13 15:19:27 2019 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Thu Jun 13 15:19:27 2019 Done. # combine unrelated and related PCs and order as in GDS file pcs &lt;- rbind(pca.unrel$eigenvect, samp.load$eigenvect) rownames(pcs) &lt;- c(pca.unrel$sample.id, samp.load$sample.id) samp.ord &lt;- match(sample.id, rownames(pcs)) pcs &lt;- pcs[samp.ord,] We need to determine which PCs are ancestry informative. To do this we need population information for the 1000 Genomes samples. This information is stored in an AnnotatedDataFrame, which is a data.frame with optional metadata describing the columns. The class is defined in the Biobase package. We load the stored object using the getobj function from the TopmedPipeline package. library(Biobase) sampfile &lt;- &quot;data/sample_annotation.RData&quot; annot &lt;- TopmedPipeline::getobj(sampfile) annot ## An object of class &#39;AnnotatedDataFrame&#39; ## rowNames: 1 2 ... 2504 (1126 total) ## varLabels: sample.id subject.id ... status (6 total) ## varMetadata: labelDescription head(pData(annot)) ## sample.id subject.id Population Population.Description sex ## 1 HG00096 HG00096 GBR British in England and Scotland M ## 2 HG00097 HG00097 GBR British in England and Scotland F ## 3 HG00099 HG00099 GBR British in England and Scotland F ## 4 HG00100 HG00100 GBR British in England and Scotland F ## 5 HG00101 HG00101 GBR British in England and Scotland M ## 6 HG00102 HG00102 GBR British in England and Scotland F ## status ## 1 0 ## 2 1 ## 3 0 ## 4 1 ## 5 0 ## 6 0 varMetadata(annot) ## labelDescription ## sample.id sample identifier ## subject.id subject identifier ## Population population abbreviation ## Population.Description population description ## sex sex ## status simulated case/control status We make a parallel coordinates plot, color-coding by 1000 Genomes population. We load the dplyr package for data.frame manipulation. pc.df &lt;- as.data.frame(pcs) names(pc.df) &lt;- 1:ncol(pcs) pc.df$sample.id &lt;- row.names(pcs) library(dplyr) annot &lt;- pData(annot) %&gt;% dplyr::select(sample.id, Population) pc.df &lt;- left_join(pc.df, annot, by=&quot;sample.id&quot;) library(GGally) library(RColorBrewer) pop.cols &lt;- setNames(brewer.pal(12, &quot;Paired&quot;), c(&quot;ACB&quot;, &quot;ASW&quot;, &quot;CEU&quot;, &quot;GBR&quot;, &quot;CHB&quot;, &quot;JPT&quot;, &quot;CLM&quot;, &quot;MXL&quot;, &quot;LWK&quot;, &quot;YRI&quot;, &quot;GIH&quot;, &quot;PUR&quot;)) ggparcoord(pc.df, columns=1:12, groupColumn=&quot;Population&quot;, scale=&quot;uniminmax&quot;) + scale_color_manual(values=pop.cols) + xlab(&quot;PC&quot;) + ylab(&quot;&quot;) 8.3 PC-Relate The first 2 PCs separate populations, so we use them to compute kinship estimates adjusting for ancestry. The PC-Relate function expects a SeqVarData object, which allows linking sample and variant annotation with a GDS file in a single object. We will cover these in more detail later for association testing, but for now we create a bare object with no annotation. seqResetFilter(gds, verbose=FALSE) library(SeqVarTools) seqData &lt;- SeqVarData(gds) seqSetFilter(seqData, variant.id=pruned) ## # of selected variants: 6,356 iterator &lt;- SeqVarBlockIterator(seqData, verbose=FALSE) pcrel &lt;- pcrelate(iterator, pcs=pcs[,1:2], training.set=sampset$unrels, sample.include=sample.id) names(pcrel) ## [1] &quot;kinBtwn&quot; &quot;kinSelf&quot; PC-Relate is an iterative method. Now that we have ancestry-adjusted kinship estimates, we can use them to better adjust for ancestry in the PCs. This time we use the pcair function, which combines partitioning the sample set and running PCA in one step. First we need to make a kinship matrix from the PC-Relate results. The KING matrix is still used for ancestry divergence. pcrelMat &lt;- pcrelateToMatrix(pcrel, scaleKin=1, verbose=FALSE) seqResetFilter(seqData, verbose=FALSE) pca &lt;- pcair(seqData, kinobj=pcrelMat, kin.thresh=2^(-9/2), divobj=kingMat, div.thresh=-2^(-9/2), sample.include=sample.id, snp.include=pruned, verbose=FALSE) names(pca) ## [1] &quot;vectors&quot; &quot;values&quot; &quot;rels&quot; &quot;unrels&quot; &quot;kin.thresh&quot; ## [6] &quot;div.thresh&quot; &quot;sample.id&quot; &quot;nsamp&quot; &quot;nsnps&quot; &quot;varprop&quot; ## [11] &quot;call&quot; &quot;method&quot; pcs &lt;- pca$vectors pc.df &lt;- as.data.frame(pcs) names(pc.df) &lt;- paste0(&quot;PC&quot;, 1:ncol(pcs)) pc.df$sample.id &lt;- row.names(pcs) pc.df &lt;- left_join(pc.df, annot, by=&quot;sample.id&quot;) ggplot(pc.df, aes(PC1, PC2, color=Population)) + geom_point() + scale_color_manual(values=pop.cols) Now we use the revised PCs to compute new kinship estimates. One can run the iteration multiple times and check for conversion, but usually two rounds are sufficient. seqSetFilter(seqData, variant.id=pruned) ## # of selected variants: 6,356 iterator &lt;- SeqVarBlockIterator(seqData, verbose=FALSE) pcrel &lt;- pcrelate(iterator, pcs=pcs[,1:2], training.set=pca$unrels, sample.include=sample.id) save(pcrel, file=&quot;data/pcrelate_kinship.RData&quot;) We plot the kinship estimates from PC-Relate, and notice that the values for less related pairs are much better behaved. kinship &lt;- pcrel$kinBtwn ggplot(kinship, aes(k0, kin)) + geom_hline(yintercept=2^(-seq(3,9,2)/2), linetype=&quot;dashed&quot;, color=&quot;grey&quot;) + geom_point(alpha=0.5) + ylab(&quot;kinship estimate&quot;) + theme_bw() seqClose(gds) 8.4 Comparison with pedigree We can detect pedigree errors and sample identity problems by comparing the pedigree with empirical kinship estimates. We use a function from the GWASTools package, pedigreePairwiseRelatedness, to get expected pairwise relationships based on the pedigree. pedfile &lt;- &quot;data/pedigree.RData&quot; if (!file.exists(pedfile)) download.file(file.path(workshop.path, pedfile), pedfile) ped &lt;- TopmedPipeline::getobj(pedfile) head(ped) ## family individ father mother sex ## 1 BB01 HG01879 0 0 M ## 2 BB01 HG01880 0 0 F ## 3 BB01 HG01881 HG01879 HG01880 F ## 4 BB02 HG01882 0 0 M ## 5 BB02 HG01883 0 0 F ## 6 BB02 HG01888 HG01882 HG01883 M pw &lt;- GWASTools::pedigreePairwiseRelatedness(ped) names(pw) ## [1] &quot;inbred.fam&quot; &quot;inbred.KC&quot; &quot;relativeprs&quot; rel &lt;- pw$relativeprs head(rel) ## Individ1 Individ2 relation kinship family ## 1 HG01879 HG01880 U 0.00 BB01 ## 2 HG01879 HG01881 PO 0.25 BB01 ## 3 HG01880 HG01881 PO 0.25 BB01 ## 4 HG01882 HG01883 U 0.00 BB02 ## 5 HG01882 HG01888 PO 0.25 BB02 ## 6 HG01883 HG01888 PO 0.25 BB02 table(rel$relation) ## ## Av FS GpGc HAv HS PO U ## 2 6 16 1 3 616 330 distinct(rel, relation, kinship) %&gt;% arrange(-kinship) ## relation kinship ## 1 PO 0.2500 ## 2 FS 0.2500 ## 3 HS 0.1250 ## 4 GpGc 0.1250 ## 5 Av 0.1250 ## 6 HAv 0.0625 ## 7 U 0.0000 ## assign degrees to expected relationship pairs rel &lt;- rel %&gt;% mutate(exp.rel=ifelse(kinship == 0.125, &quot;Deg2&quot;, ifelse(kinship == 0.0625, &quot;Deg3&quot;, relation)), pair=GWASTools::pasteSorted(Individ1, Individ2)) %&gt;% select(pair, family, relation, exp.rel) ## assign degrees to observed relationship pairs cut.dup &lt;- 1/(2^(3/2)) cut.deg1 &lt;- 1/(2^(5/2)) cut.deg2 &lt;- 1/(2^(7/2)) cut.deg3 &lt;- 1/(2^(9/2)) cut.k0 &lt;- 0.1 kinship &lt;- kinship %&gt;% mutate(obs.rel=ifelse(kin &gt; cut.dup, &quot;Dup&quot;, ifelse(kin &gt; cut.deg1 &amp; k0 &lt; cut.k0, &quot;PO&quot;, ifelse(kin &gt; cut.deg1, &quot;FS&quot;, ifelse(kin &gt; cut.deg2, &quot;Deg2&quot;, ifelse(kin &gt; cut.deg3, &quot;Deg3&quot;, &quot;U&quot;)))))) table(kinship$obs.rel) ## ## Deg2 Deg3 FS PO U ## 4 6 2 7 4931 # merge observed and expected relationships kin.obs &lt;- kinship %&gt;% select(ID1, ID2, kin, k0, obs.rel) %&gt;% mutate(pair=GWASTools::pasteSorted(ID1, ID2)) %&gt;% left_join(rel, by=&quot;pair&quot;) %&gt;% select(-pair) %&gt;% mutate(exp.rel=ifelse(is.na(exp.rel), &quot;U&quot;, exp.rel)) %&gt;% filter(!(exp.rel == &quot;U&quot; &amp; obs.rel == &quot;U&quot;)) table(kin.obs$exp.rel, kin.obs$obs.rel) ## ## Deg2 Deg3 FS PO ## U 4 6 2 7 ggplot(kin.obs, aes(k0, kin, color=obs.rel)) + geom_point() All the observed relationships were unexpected. These samples are from 1000 Genomes sequencing, and known relatives were excluded from the released data. Here we have detected some cryptic relatives that were not annotated in the pedigree. 8.5 Exercise Complete one round of iteration using all samples from the test dataset and plot the results. Be sure to examine the parallel coordinates plot to determine the appropriate number of PCs to give as an argument to pcrelate. "],
["mixed-models.html", "9 Mixed models 9.1 Null model 9.2 Single-variant tests 9.3 Exercise", " 9 Mixed models These exercises introduce relatedness to association testing with mixed models. 9.1 Null model The first step in an association test is to fit the null model. In addition to the AnnotatedDataFrame with phenotypes we used previously, we will need the principal components and kinship. We will use the first five PCs to adjust for ancestry. # sample annotation sampfile &lt;- &quot;data/sample_phenotype_annotation.RData&quot; annot &lt;- TopmedPipeline::getobj(sampfile) library(Biobase) head(pData(annot)) ## sample.id subject.id Population Population.Description sex ## 1 HG00096 HG00096 GBR British in England and Scotland M ## 2 HG00097 HG00097 GBR British in England and Scotland F ## 3 HG00099 HG00099 GBR British in England and Scotland F ## 4 HG00100 HG00100 GBR British in England and Scotland F ## 5 HG00101 HG00101 GBR British in England and Scotland M ## 6 HG00102 HG00102 GBR British in England and Scotland F ## status age height study ## 1 0 47 165.300 study_1 ## 2 1 47 144.780 study_3 ## 3 0 40 185.500 study_2 ## 4 1 45 150.622 study_3 ## 5 0 40 177.800 study_3 ## 6 0 49 169.100 study_1 # load the PCs pcfile &lt;- &quot;data/pcs.RData&quot; pcs &lt;- TopmedPipeline::getobj(pcfile) pcs &lt;- pcs[,c(&quot;sample.id&quot;, &quot;PC1&quot;, &quot;PC2&quot;, &quot;PC3&quot;, &quot;PC4&quot;, &quot;PC5&quot;)] head(pcs) ## sample.id PC1 PC2 PC3 PC4 PC5 ## 1 HG00096 -0.02098435 -0.03716014 -0.007539234 -0.004984352 -0.03920777 ## 2 HG00097 -0.01929295 -0.03289496 -0.009176117 -0.005328914 -0.03297778 ## 3 HG00099 -0.02042444 -0.03371227 -0.010983795 -0.004856350 -0.03208595 ## 4 HG00100 -0.01970348 -0.03978044 -0.013302258 -0.004340841 -0.04208343 ## 5 HG00101 -0.01959563 -0.03431033 -0.008571074 -0.002220712 -0.03260015 ## 6 HG00102 -0.02041573 -0.03941142 -0.010696762 0.001506639 -0.02913023 # add PCs to the sample annotation dat &lt;- left_join(pData(annot), pcs, by=&quot;sample.id&quot;) pData(annot) &lt;- dat save(annot, file=&quot;sample_phenotype_pcs.RData&quot;) We create a kinship matrix from the output of pcrelate. We multiply the kinship values by 2 to get values equivalent to a GRM. This matrix is represented in R as a symmetric matrix object from the Matrix package. kinfile &lt;- &quot;data/pcrelate_kinship.RData&quot; pcrel &lt;- TopmedPipeline::getobj(kinfile) kinship &lt;- pcrelateToMatrix(pcrel, scaleKin=2, verbose=FALSE) dim(kinship) ## [1] 100 100 kinship[1:5,1:5] ## 5 x 5 Matrix of class &quot;dsyMatrix&quot; ## HG00110 HG00116 HG00120 HG00128 HG00136 ## HG00110 1.046618916 0.01896886 -0.01635266 -0.006769183 -0.022907033 ## HG00116 0.018968859 0.92512545 0.19178400 0.013529261 -0.018774460 ## HG00120 -0.016352656 0.19178400 0.96012109 -0.014849711 -0.046482113 ## HG00128 -0.006769183 0.01352926 -0.01484971 0.914741469 -0.003540016 ## HG00136 -0.022907033 -0.01877446 -0.04648211 -0.003540016 1.007541773 We fit the null model, adding the PCs to the list of covariates, and specifying the kinship as the covariance matrix with the cov.mat argument. As before, we use study as a grouping variable. library(GENESIS) nullmod &lt;- fitNullModel(annot, outcome=&quot;height&quot;, covars=c(&quot;sex&quot;, &quot;age&quot;, &quot;study&quot;, paste0(&quot;PC&quot;, 1:5)), cov.mat=kinship, group.var=&quot;study&quot;, verbose=FALSE) save(nullmod, file=&quot;null_mixed_model.RData&quot;) 9.2 Single-variant tests Now we can run a single-variant test, accounting for relatedness between the subjects. library(SeqVarTools) gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; gds &lt;- seqOpen(gdsfile) seqData &lt;- SeqVarData(gds, sampleData=annot) iterator &lt;- SeqVarBlockIterator(seqData, verbose=FALSE) assoc &lt;- assocTestSingle(iterator, nullmod) ## # of selected samples: 100 head(assoc) ## variant.id chr pos allele.index n.obs freq Score Score.SE ## 1 1 1 970546 1 100 0.015 -0.08540038 0.14196057 ## 2 2 1 985900 1 100 0.045 -0.22242172 0.23151080 ## 5 5 1 1472676 1 100 0.005 -0.08038064 0.08682388 ## 7 7 1 2185887 1 100 0.005 0.02490900 0.07345651 ## 9 9 1 2629401 1 100 0.025 0.16640007 0.18372229 ## 10 10 1 2710895 1 100 0.060 0.09144953 0.27222156 ## Score.Stat Score.pval ## 1 -0.6015782 0.5474550 ## 2 -0.9607401 0.3366828 ## 5 -0.9257895 0.3545554 ## 7 0.3390986 0.7345355 ## 9 0.9057152 0.3650866 ## 10 0.3359379 0.7369177 qqPlot(assoc$Score.pval) 9.3 Exercise Run a sliding window test using the mixed model and make a QQ plot. "],
["mixed-models-solutions.html", "10 Mixed models - Solutions", " 10 Mixed models - Solutions Run a sliding window test using the mixed model and make a QQ plot. seqResetFilter(seqData, verbose=FALSE) seqSetFilter(seqData, variant.sel=1:100) # temporary for build speed ## # of selected variants: 100 iterator &lt;- SeqVarWindowIterator(seqData, windowSize=5000, windowShift=2000, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;Burden&quot;, AF.max=0.1, weight.beta=c(1,1)) ## # of selected samples: 100 head(assoc$results) ## chr start end n.site n.alt n.sample.alt Score Score.SE ## 1 1 966001 971000 1 3 3 -0.08540038 0.14196057 ## 2 1 982001 987000 1 9 9 -0.22242172 0.23151080 ## 3 1 1022001 1027000 0 0 0 NA NA ## 4 1 1262001 1267000 0 0 0 NA NA ## 5 1 1468001 1473000 1 1 1 -0.08038064 0.08682388 ## 6 1 1732001 1737000 0 0 0 NA NA ## Score.Stat Score.pval ## 1 -0.6015782 0.5474550 ## 2 -0.9607401 0.3366828 ## 3 NA NA ## 4 NA NA ## 5 -0.9257895 0.3545554 ## 6 NA NA head(assoc$variantInfo) ## [[1]] ## variant.id chr pos allele.index n.obs freq weight ## 1 1 1 970546 1 100 0.015 1 ## ## [[2]] ## variant.id chr pos allele.index n.obs freq weight ## 1 2 1 985900 1 100 0.045 1 ## ## [[3]] ## [1] variant.id chr pos allele.index n.obs ## [6] freq weight ## &lt;0 rows&gt; (or 0-length row.names) ## ## [[4]] ## [1] variant.id chr pos allele.index n.obs ## [6] freq weight ## &lt;0 rows&gt; (or 0-length row.names) ## ## [[5]] ## variant.id chr pos allele.index n.obs freq weight ## 1 5 1 1472676 1 100 0.005 1 ## ## [[6]] ## [1] variant.id chr pos allele.index n.obs ## [6] freq weight ## &lt;0 rows&gt; (or 0-length row.names) qqPlot(assoc$results$Score.pval) seqClose(gds) "],
["variant-annotation.html", "11 Variant annotation 11.1 Working with variant annotation 11.2 Aggregating and filtering variants using annotation", " 11 Variant annotation Note: the code and libraries in this section are under active development. This section uses WGSAParsr v 5.0.8 to parse output from WGSA version 0.7. Use this code at your own risk, and be warned that it may break in unexpected ways or be incompatible across different versions of the software. Github issues and contribution are welcome! This module is provided to give workshop participants an example of some of the kinds of analysis tasks that might be performed with TOPMed annotation data. Analysts generally aggregate rare variants for association testing to decrease multiple testing burden and increase statistical power. They can group variants that fall within arbitrary ranges (such as sliding windows), or they can group variants with intent. For example, an analyst could aggregate variants that that fall between transcription start sites and stop sites, within coding regions, within regulatory regions, or other genomic features selected from sources like published gene models or position- or transcript-based variant annotation. An analyst could also choose to filter the variants prior or subsequent to aggregation using annotation-based criteria such as functional impact or quality scores. In this workshop, you will aggregate and filter genomic variants using genomic annotation for subsequent association testing. Starting with an annotation file describing 1,922 genomic variants on chromosome 22 from TOPMed’s Freeze 5 data release that are also in the 1000 Genomes Project, you will define a configuration file to use the WGSAParsr package to select relevant annotation fields, then aggregate the selected variants into genic units and apply filters to restrict the variants in aggreagation units by predicted functional consequence. 11.1 Working with variant annotation Variants called from the TOPMed data set are annotated using the Whole Genome Sequence Annotator (WGSA). Output files from WGSA version 0.7 include 366 annotation fields annotating indel variants, and 438 annotation fields annotating snv variants. In each case, some annotation fields are themselves lists of annotation values. Thus, individual variants may be annotated with more than 1000 individual fields. Not all of these fields will be useful for a particular analysis, and some may be incompatible, so analysts need to parse the WGSA output prior to filtering and aggregation. The WGSA-annotated variant annotation files we will use for this exercise are available via github: workshop.path &lt;- &quot;https://github.com/UW-GAC/topmed_workshop_2018/raw/master/&quot; if (!dir.exists(&quot;data&quot;)) dir.create(&quot;data&quot;) snvfile &lt;- &quot;data/snv.tsv.gz&quot; if (!file.exists(snvfile)) download.file(file.path(workshop.path, snvfile), snvfile) indelfile &lt;- &quot;data/indel.tsv.gz&quot; if (!file.exists(indelfile)) download.file(file.path(workshop.path, indelfile), indelfile) Also, you’ll be using functions from the tidyverse package, so load that library as well: library(tidyverse) WGSA output files are tab-separated text files, with one line per annotated variant. Since there are many annotation fields, these files can be unwieldy to work with directly. As an example, the first two lines of the SNP variant annotation file can be previewed within R: readLines(snvfile, n=2) ## [1] &quot;CHROM\\tPOS\\tREF\\tALT\\tchr_hg19\\tpos_hg19\\tref_hg19\\talt_hg19\\tref_hg19_equals_ref_hg38\\tFILTER\\tSnpEff_ensembl_Effect\\tSnpEff_ensembl_Effect_impact\\tSnpEff_ensembl_Sequence_feature\\tSnpEff_ensembl_Sequence_feature_impact\\tSnpEff_ensembl_Transcript_ID\\tSnpEff_ensembl_Transcript_biotype\\tSnpEff_ensembl_Gene_name\\tSnpEff_ensembl_Gene_ID\\tSnpEff_ensembl_HGVSc\\tSnpEff_ensembl_HGVSp\\tSnpEff_ensembl_Protein_position_or_Protein_len\\tSnpEff_ensembl_CDS_position_or_CDS_len\\tSnpEff_ensembl_cDNA_position_or_cDNA_len\\tSnpEff_ensembl_Exon_or_intron_rank_or_total\\tSnpEff_ensembl_Distance_to_feature\\tSnpEff_ensembl_Warnings\\tSnpEff_ensembl_LOF_or_NMD\\tSnpEff_ensembl_LOF_or_NMD_gene_name\\tSnpEff_ensembl_LOF_or_NMD_gene_ID\\tSnpEff_ensembl_LOF_or_NMD_num_transcripts_affected\\tSnpEff_ensembl_LOF_or_NMD_percent_transcripts_affected\\tSnpEff_ensembl_TF_binding_effect\\tSnpEff_ensembl_TF_name\\tSnpEff_ensembl_TF_ID\\tSnpEff_ensembl_summary\\tVEP_ensembl_Consequence\\tVEP_ensembl_Transcript_ID\\tVEP_ensembl_Gene_Name\\tVEP_ensembl_Gene_ID\\tVEP_ensembl_Protein_ID\\tVEP_ensembl_CCDS\\tVEP_ensembl_SWISSPROT\\tVEP_ensembl_Codon_Change_or_Distance\\tVEP_ensembl_Amino_Acid_Change\\tVEP_ensembl_HGVSc\\tVEP_ensembl_HGVSp\\tVEP_ensembl_cDNA_position\\tVEP_ensembl_CDS_position\\tVEP_ensembl_Protein_position\\tVEP_ensembl_Exon_or_Intron_Rank\\tVEP_ensembl_STRAND\\tVEP_ensembl_CANONICAL\\tVEP_ensembl_LoF\\tVEP_ensembl_LoF_filter\\tVEP_ensembl_LoF_flags\\tVEP_ensembl_LoF_info\\tVEP_ensembl_summary\\tANNOVAR_refseq_Effect\\tANNOVAR_refseq_Transcript_ID\\tANNOVAR_refseq_Gene_ID\\tANNOVAR_refseq_Closest_gene\\tANNOVAR_refseq_HGVSc\\tANNOVAR_refseq_HGVSp\\tANNOVAR_refseq_Exon_Rank\\tANNOVAR_refseq_summary\\tSnpEff_refseq_Effect\\tSnpEff_refseq_Effect_impact\\tSnpEff_refseq_Sequence_feature\\tSnpEff_refseq_Sequence_feature_impact\\tSnpEff_refseq_Transcript_ID\\tSnpEff_refseq_Transcript_biotype\\tSnpEff_refseq_Gene_name\\tSnpEff_refseq_Gene_ID\\tSnpEff_refseq_HGVSc\\tSnpEff_refseq_HGVSp\\tSnpEff_refseq_Protein_position_or_Protein_len\\tSnpEff_refseq_CDS_position_or_CDS_len\\tSnpEff_refseq_cDNA_position_or_cDNA_len\\tSnpEff_refseq_Exon_or_intron_rank_or_total\\tSnpEff_refseq_Distance_to_feature\\tSnpEff_refseq_Warnings\\tSnpEff_refseq_LOF_or_NMD\\tSnpEff_refseq_LOF_or_NMD_gene_name\\tSnpEff_refseq_LOF_or_NMD_gene_ID\\tSnpEff_refseq_LOF_or_NMD_num_transcripts_affected\\tSnpEff_refseq_LOF_or_NMD_percent_transcripts_affected\\tSnpEff_refseq_TF_binding_effect\\tSnpEff_refseq_TF_name\\tSnpEff_refseq_TF_ID\\tSnpEff_refseq_summary\\tVEP_refseq_Consequence\\tVEP_refseq_Transcript_ID\\tVEP_refseq_Gene_Name\\tVEP_refseq_Gene_ID\\tVEP_refseq_Protein_ID(ENSP)\\tVEP_refseq_Codon_Change_or_Distance\\tVEP_refseq_Amino_Acid_Change\\tVEP_refseq_HGVSc\\tVEP_refseq_HGVSp\\tVEP_refseq_cDNA_position\\tVEP_refseq_CDS_position\\tVEP_refseq_Protein_position\\tVEP_refseq_Exon_or_Intron_Rank\\tVEP_refseq_STRAND\\tVEP_refseq_CANONICAL\\tVEP_refseq_LoF\\tVEP_refseq_LoF_filter\\tVEP_refseq_LoF_flags\\tVEP_refseq_LoF_info\\tVEP_refseq_summary\\tANNOVAR_ucsc_Effect\\tANNOVAR_ucsc_Transcript_ID\\tANNOVAR_ucsc_Gene_ID\\tANNOVAR_ucsc_Closest_gene\\tANNOVAR_ucsc_HGVSc\\tANNOVAR_ucsc_HGVSp\\tANNOVAR_ucsc_Exon_Rank\\tANNOVAR_ucsc_summary\\trs_dbSNP150\\tsno_miRNA_name\\tsno_miRNA_type\\tUTR3_miRNA_target\\tTargetScan_context_pp_score_percentile\\tsplicing_consensus_ada_score\\tsplicing_consensus_rf_score\\tGWAS_catalog_rs\\tGWAS_catalog_trait\\tGWAS_catalog_pubmedid\\tGRASP_rs\\tGRASP_PMID\\tGRASP_p_value\\tGRASP_phenotype\\tGRASP_ancestry\\tGRASP_platform\\tclinvar_rs\\tclinvar_clnsig\\tclinvar_trait\\tclinvar_golden_stars\\tGTEx_V6p_gene\\tGTEx_V6p_tissue\\tMAP20\\tMAP35\\tMAP20_149bp\\tMAP35_149\\tGMS_single_end\\tGMS_paired_end\\tKGP_strict_masked\\tRepeatMasker_masked\\tAncestral_allele\\tAltaiNeandertal_genotypes\\tDenisova_genotypes\\tVindijiaNeandertal_genotypes\\tphyloP46way_primate\\tphyloP46way_primate_rankscore\\tphyloP20way_mammalian\\tphyloP20way_mammalian_rankscore\\tphyloP100way_vertebrate\\tphyloP100way_vertebrate_rankscore\\tphastCons46way_primate\\tphastCons46way_primate_rankscore\\tphastCons20way_mammalian\\tphastCons20way_mammalian_rankscore\\tphastCons100way_vertebrate\\tphastCons100way_vertebrate_rankscore\\tGERP_NR\\tGERP_RS\\tGERP_RS_rankscore\\tSiPhy_29way_logOdds\\tSiPhy_29way_logOdds_rankscore\\tintegrated_fitCons_score\\tintegrated_fitCons_rankscore\\tintegrated_confidence_value\\tGM12878_fitCons_score\\tGM12878_fitCons_rankscore\\tGM12878_confidence_value\\tH1_hESC_fitCons_score\\tH1_hESC_fitCons_rankscore\\tH1_hESC_confidence_value\\tHUVEC_fitCons_score\\tHUVEC_fitCons_rankscore\\tHUVEC_confidence_value\\tGenoCanyon_score\\tGenoCanyon_rankscore\\tKGP3_AC\\tKGP3_AF\\tKGP3_AFR_AC\\tKGP3_AFR_AF\\tKGP3_EUR_AC\\tKGP3_EUR_AF\\tKGP3_AMR_AC\\tKGP3_AMR_AF\\tKGP3_EAS_AC\\tKGP3_EAS_AF\\tKGP3_SAS_AC\\tKGP3_SAS_AF\\tUK10K_AC\\tUK10K_AN\\tUK10K_AF\\tTWINSUK_AC\\tTWINSUK_AN\\tTWINSUK_AF\\tALSPAC_AC\\tALSPAC_AN\\tALSPAC_AF\\tESP6500_AC\\tESP6500_AF\\tESP6500_AA_AC\\tESP6500_AA_AF\\tESP6500_EA_AC\\tESP6500_EA_AF\\tExAC_AC\\tExAC_AF\\tExAC_Adj_AC\\tExAC_Adj_AF\\tExAC_AFR_AC\\tExAC_AFR_AF\\tExAC_AMR_AC\\tExAC_AMR_AF\\tExAC_EAS_AC\\tExAC_EAS_AF\\tExAC_FIN_AC\\tExAC_FIN_AF\\tExAC_NFE_AC\\tExAC_NFE_AF\\tExAC_SAS_AC\\tExAC_SAS_AF\\tExAC_nonTCGA_AC\\tExAC_nonTCGA_AF\\tExAC_nonTCGA_Adj_AC\\tExAC_nonTCGA_Adj_AF\\tExAC_nonTCGA_AFR_AC\\tExAC_nonTCGA_AFR_AF\\tExAC_nonTCGA_AMR_AC\\tExAC_nonTCGA_AMR_AF\\tExAC_nonTCGA_EAS_AC\\tExAC_nonTCGA_EAS_AF\\tExAC_nonTCGA_FIN_AC\\tExAC_nonTCGA_FIN_AF\\tExAC_nonTCGA_NFE_AC\\tExAC_nonTCGA_NFE_AF\\tExAC_nonTCGA_SAS_AC\\tExAC_nonTCGA_SAS_AF\\tExAC_nonpsych_AC\\tExAC_nonpsych_AF\\tExAC_nonpsych_Adj_AC\\tExAC_nonpsych_Adj_AF\\tExAC_nonpsych_AFR_AC\\tExAC_nonpsych_AFR_AF\\tExAC_nonpsych_AMR_AC\\tExAC_nonpsych_AMR_AF\\tExAC_nonpsych_EAS_AC\\tExAC_nonpsych_EAS_AF\\tExAC_nonpsych_FIN_AC\\tExAC_nonpsych_FIN_AF\\tExAC_nonpsych_NFE_AC\\tExAC_nonpsych_NFE_AF\\tExAC_nonpsych_SAS_AC\\tExAC_nonpsych_SAS_AF\\tgnomAD_exomes_AC\\tgnomAD_exomes_AN\\tgnomAD_exomes_AF\\tgnomAD_exomes_AFR_AC\\tgnomAD_exomes_AFR_AN\\tgnomAD_exomes_AFR_AF\\tgnomAD_exomes_AMR_AC\\tgnomAD_exomes_AMR_AN\\tgnomAD_exomes_AMR_AF\\tgnomAD_exomes_ASJ_AC\\tgnomAD_exomes_ASJ_AN\\tgnomAD_exomes_ASJ_AF\\tgnomAD_exomes_EAS_AC\\tgnomAD_exomes_EAS_AN\\tgnomAD_exomes_EAS_AF\\tgnomAD_exomes_FIN_AC\\tgnomAD_exomes_FIN_AN\\tgnomAD_exomes_FIN_AF\\tgnomAD_exomes_NFE_AC\\tgnomAD_exomes_NFE_AN\\tgnomAD_exomes_NFE_AF\\tgnomAD_exomes_SAS_AC\\tgnomAD_exomes_SAS_AN\\tgnomAD_exomes_SAS_AF\\tgnomAD_exomes_OTH_AC\\tgnomAD_exomes_OTH_AN\\tgnomAD_exomes_OTH_AF\\tgnomAD_genomes_AC\\tgnomAD_genomes_AN\\tgnomAD_genomes_AF\\tgnomAD_genomes_AFR_AC\\tgnomAD_genomes_AFR_AN\\tgnomAD_genomes_AFR_AF\\tgnomAD_genomes_AMR_AC\\tgnomAD_genomes_AMR_AN\\tgnomAD_genomes_AMR_AF\\tgnomAD_genomes_ASJ_AC\\tgnomAD_genomes_ASJ_AN\\tgnomAD_genomes_ASJ_AF\\tgnomAD_genomes_EAS_AC\\tgnomAD_genomes_EAS_AN\\tgnomAD_genomes_EAS_AF\\tgnomAD_genomes_FIN_AC\\tgnomAD_genomes_FIN_AN\\tgnomAD_genomes_FIN_AF\\tgnomAD_genomes_NFE_AC\\tgnomAD_genomes_NFE_AN\\tgnomAD_genomes_NFE_AF\\tgnomAD_genomes_OTH_AC\\tgnomAD_genomes_OTH_AN\\tgnomAD_genomes_OTH_AF\\tRegulomeDB_motif\\tRegulomeDB_score\\tMotif_breaking\\tnetwork_hub\\tENCODE_annotated\\tsensitive\\tultra_sensitive\\ttarget_gene\\tfunseq_noncoding_score\\tfunseq2_noncoding_score\\tfunseq2_noncoding_rankscore\\tCADD_raw\\tCADD_phred\\tCADD_raw_rankscore\\tDANN_score\\tDANN_rank_score\\tfathmm_MKL_non_coding_score\\tfathmm_MKL_non_coding_rankscore\\tfathmm_MKL_non_coding_pred\\tfathmm_MKL_non_coding_group\\tfathmm_MKL_coding_score\\tfathmm_MKL_coding_rankscore\\tfathmm_MKL_coding_pred\\tfathmm_MKL_coding_group\\tEigen_coding_or_noncoding\\tEigen_raw\\tEigen_phred\\tEigen_PC_raw\\tEigen_PC_phred\\tORegAnno_type\\tORegAnno_PMID\\thESC_Topological_Domain\\tIMR90_Topological_Domain\\tENCODE_TFBS\\tENCODE_TFBS_score\\tENCODE_TFBS_cells\\tENCODE_Dnase_score\\tENCODE_Dnase_cells\\tEnhancerFinder_general_developmental_enhancer\\tEnhancerFinder_brain_enhancer\\tEnhancerFinder_heart_enhancer\\tEnhancerFinder_limb_enhancer\\tSuperEnhancer_tissue_cell\\tSuperEnhancer_RefSeq_id\\tSuperEnhancer_Gene_symbol\\tFANTOM5_enhancer_permissive\\tFANTOM5_enhancer_robust\\tFANTOM5_enhancer_target\\tFANTOM5_enhancer_expressed_tissue_cell\\tFANTOM5_enhancer_differentially_expressed_tissue_cell\\tFANTOM5_CAGE_peak_permissive\\tFANTOM5_CAGE_peak_robust\\tEnsembl_Regulatory_Build_feature_type\\tEnsembl_Regulatory_Build_ID\\tEnsembl_Regulatory_Build_TFBS\\tEnsembl_Regulatory_Build_TFBS_matrix\\taaref\\taaalt\\tgenename\\tcds_strand\\trefcodon\\tcodonpos\\tcodon_degeneracy\\tEnsembl_geneid\\tEnsembl_transcriptid\\tEnsembl_proteinid\\taapos\\tSIFT_score\\tSIFT_converted_rankscore\\tSIFT_pred\\tUniprot_acc_Polyphen2\\tUniprot_id_Polyphen2\\tUniprot_aapos_Polyphen2\\tPolyphen2_HDIV_score\\tPolyphen2_HDIV_rankscore\\tPolyphen2_HDIV_pred\\tPolyphen2_HVAR_score\\tPolyphen2_HVAR_rankscore\\tPolyphen2_HVAR_pred\\tLRT_score\\tLRT_converted_rankscore\\tLRT_pred\\tLRT_Omega\\tMutationTaster_score\\tMutationTaster_converted_rankscore\\tMutationTaster_pred\\tMutationTaster_model\\tMutationTaster_AAE\\tMutationAssessor_UniprotID\\tMutationAssessor_variant\\tMutationAssessor_score\\tMutationAssessor_score_rankscore\\tMutationAssessor_pred\\tFATHMM_score\\tFATHMM_converted_rankscore\\tFATHMM_pred\\tPROVEAN_score\\tPROVEAN_converted_rankscore\\tPROVEAN_pred\\tTranscript_id_VEST3\\tTranscript_var_VEST3\\tVEST3_score\\tVEST3_rankscore\\tMetaSVM_score\\tMetaSVM_rankscore\\tMetaSVM_pred\\tMetaLR_score\\tMetaLR_rankscore\\tMetaLR_pred\\tReliability_index\\tM_CAP_score\\tM_CAP_rankscore\\tM_CAP_pred\\tREVEL_score\\tREVEL_rankscore\\tMutPred_score\\tMutPred_rankscore\\tMutPred_protID\\tMutPred_AAchange\\tMutPred_Top5features\\tSIFT4G_AAref\\tSIFT4G_AAalt\\tSIFT4G_AApos\\tSIFT4G_score\\tSIFT4G_pred\\tVEP_ensembl_precedent_transcript_consequence\\tVEP_ensembl_precedent_consequence\\tVEP_ensembl_precedent_gene\\tunique_variant&quot; ## [2] &quot;22\\t15319214\\tC\\tG\\t14\\t19164877\\tC\\tG\\tY\\tSVM\\tintergenic_region\\tMODIFIER\\t.\\t.\\t.\\t.\\tLA16c-60D12.2-ZNF72P\\tENSG00000279442-ENSG00000184624\\tn.15319214C&gt;G\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tLA16c-60D12.2-ZNF72P(1):intergenic_region(1)\\tintergenic_variant\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.(0):intergenic_variant(1)\\tintergenic\\t.\\t.\\tNONE:NONE(dist=NONE),OR11H1:NM_001005239(dist=208945)\\t.\\t.\\t.\\t.(0):intergenic(1)\\tintergenic_region\\tMODIFIER\\t.\\t.\\t.\\t.\\tLOC102723769-OR11H1\\tLOC102723769-OR11H1\\tn.15319214C&gt;G\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tLOC102723769-OR11H1(1):intergenic_region(1)\\tintergenic_variant\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.(0):intergenic_variant(1)\\tintergenic\\t.\\t.\\tLA16c-60D12.2:uc062beg.1(dist=14658),OR11H1:uc011agd.3(dist=208944)\\t.\\t.\\t.\\t.(0):intergenic(1)\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t0.4875\\t0.5\\t0.117857136\\t0.24025154\\t0.0\\t2.9325\\tN\\tY\\tc\\t./.\\t./.\\t./.\\t0.121\\t0.35824\\t0.145\\t0.48140\\t-0.437\\t0.21305\\t0.022\\t0.42945\\t0.003\\t0.27678\\t0.029\\t0.71313\\t.\\t.\\t.\\t.\\t.\\t0.061011\\t0.46846\\t0\\t0.063388\\t0.47335\\t0\\t0.063197\\t0.58247\\t0\\t0.057018\\t0.25711\\t0\\t1.09986088870014E-6\\t0.12103\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tMotifs|PWM|Foxl1, Motifs|PWM|FOXP1\\t6\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t0\\t0.19668\\t-0.178153\\t1.218\\t0.24498\\t0.13693365151803163\\t0.00553\\t0.05598\\t0.07755\\tN\\tA\\t0.00207\\t0.10909\\tN\\tAEFI\\tn\\t-0.401239710146973\\t0.460042\\t-0.231206471968918\\t0.361134\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tN\\tN\\tN\\tN\\t.\\t.\\t.\\tN\\tN\\t.\\t.\\t.\\tN\\tN\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tintergenic_variant\\tintergenic_variant\\t.\\tY&quot; The TOPMed DCC uses an R package we developed, WGSAParsr, to work with WGSA output files. Briefly, WGSAParsr simplifies the WGSA output files by: 1) selecting a subset of fields; 2) renaming some fields; and 3) simplifying fields that have compound list-entries. The WGSAParsr package is under development, and is available on github at https://github.com/UW-GAC/wgsaparsr. It can be installed using the devtools package, like this: # Commented out because you don&#39;t need to do this in the workshop - it&#39;s already installed on the AMI you&#39;re using: # devtools::install_github(&quot;UW-GAC/wgsaparsr&quot;, ref = &quot;5.0.8&quot;, upgrade_dependencies = FALSE) note: if you get an error Installation failed: error in running command when you’re trying to use install_github(), that may be related to some assumptions devtools makes in downloading packages from github. The error can be resolved if you set the unzip option in your R session before running devtools::install_github(). Here’s how: options(unzip = &quot;internal&quot;) Once the package is installed locally, it can be loaded to the workspace in the usual manner: library(wgsaparsr) Then we can begin using tools in the package. wgsaparsr::get_fields() lists all of the annotation field headers in a WGSA output file: # list all fields in an annotation file (transpose to make pretty): t(get_fields(snvfile)) ## [,1] ## [1,] &quot;CHROM&quot; ## [2,] &quot;POS&quot; ## [3,] &quot;REF&quot; ## [4,] &quot;ALT&quot; ## [5,] &quot;chr_hg19&quot; ## [6,] &quot;pos_hg19&quot; ## [7,] &quot;ref_hg19&quot; ## [8,] &quot;alt_hg19&quot; ## [9,] &quot;ref_hg19_equals_ref_hg38&quot; ## [10,] &quot;FILTER&quot; ## [11,] &quot;SnpEff_ensembl_Effect&quot; ## [12,] &quot;SnpEff_ensembl_Effect_impact&quot; ## [13,] &quot;SnpEff_ensembl_Sequence_feature&quot; ## [14,] &quot;SnpEff_ensembl_Sequence_feature_impact&quot; ## [15,] &quot;SnpEff_ensembl_Transcript_ID&quot; ## [16,] &quot;SnpEff_ensembl_Transcript_biotype&quot; ## [17,] &quot;SnpEff_ensembl_Gene_name&quot; ## [18,] &quot;SnpEff_ensembl_Gene_ID&quot; ## [19,] &quot;SnpEff_ensembl_HGVSc&quot; ## [20,] &quot;SnpEff_ensembl_HGVSp&quot; ## [21,] &quot;SnpEff_ensembl_Protein_position_or_Protein_len&quot; ## [22,] &quot;SnpEff_ensembl_CDS_position_or_CDS_len&quot; ## [23,] &quot;SnpEff_ensembl_cDNA_position_or_cDNA_len&quot; ## [24,] &quot;SnpEff_ensembl_Exon_or_intron_rank_or_total&quot; ## [25,] &quot;SnpEff_ensembl_Distance_to_feature&quot; ## [26,] &quot;SnpEff_ensembl_Warnings&quot; ## [27,] &quot;SnpEff_ensembl_LOF_or_NMD&quot; ## [28,] &quot;SnpEff_ensembl_LOF_or_NMD_gene_name&quot; ## [29,] &quot;SnpEff_ensembl_LOF_or_NMD_gene_ID&quot; ## [30,] &quot;SnpEff_ensembl_LOF_or_NMD_num_transcripts_affected&quot; ## [31,] &quot;SnpEff_ensembl_LOF_or_NMD_percent_transcripts_affected&quot; ## [32,] &quot;SnpEff_ensembl_TF_binding_effect&quot; ## [33,] &quot;SnpEff_ensembl_TF_name&quot; ## [34,] &quot;SnpEff_ensembl_TF_ID&quot; ## [35,] &quot;SnpEff_ensembl_summary&quot; ## [36,] &quot;VEP_ensembl_Consequence&quot; ## [37,] &quot;VEP_ensembl_Transcript_ID&quot; ## [38,] &quot;VEP_ensembl_Gene_Name&quot; ## [39,] &quot;VEP_ensembl_Gene_ID&quot; ## [40,] &quot;VEP_ensembl_Protein_ID&quot; ## [41,] &quot;VEP_ensembl_CCDS&quot; ## [42,] &quot;VEP_ensembl_SWISSPROT&quot; ## [43,] &quot;VEP_ensembl_Codon_Change_or_Distance&quot; ## [44,] &quot;VEP_ensembl_Amino_Acid_Change&quot; ## [45,] &quot;VEP_ensembl_HGVSc&quot; ## [46,] &quot;VEP_ensembl_HGVSp&quot; ## [47,] &quot;VEP_ensembl_cDNA_position&quot; ## [48,] &quot;VEP_ensembl_CDS_position&quot; ## [49,] &quot;VEP_ensembl_Protein_position&quot; ## [50,] &quot;VEP_ensembl_Exon_or_Intron_Rank&quot; ## [51,] &quot;VEP_ensembl_STRAND&quot; ## [52,] &quot;VEP_ensembl_CANONICAL&quot; ## [53,] &quot;VEP_ensembl_LoF&quot; ## [54,] &quot;VEP_ensembl_LoF_filter&quot; ## [55,] &quot;VEP_ensembl_LoF_flags&quot; ## [56,] &quot;VEP_ensembl_LoF_info&quot; ## [57,] &quot;VEP_ensembl_summary&quot; ## [58,] &quot;ANNOVAR_refseq_Effect&quot; ## [59,] &quot;ANNOVAR_refseq_Transcript_ID&quot; ## [60,] &quot;ANNOVAR_refseq_Gene_ID&quot; ## [61,] &quot;ANNOVAR_refseq_Closest_gene&quot; ## [62,] &quot;ANNOVAR_refseq_HGVSc&quot; ## [63,] &quot;ANNOVAR_refseq_HGVSp&quot; ## [64,] &quot;ANNOVAR_refseq_Exon_Rank&quot; ## [65,] &quot;ANNOVAR_refseq_summary&quot; ## [66,] &quot;SnpEff_refseq_Effect&quot; ## [67,] &quot;SnpEff_refseq_Effect_impact&quot; ## [68,] &quot;SnpEff_refseq_Sequence_feature&quot; ## [69,] &quot;SnpEff_refseq_Sequence_feature_impact&quot; ## [70,] &quot;SnpEff_refseq_Transcript_ID&quot; ## [71,] &quot;SnpEff_refseq_Transcript_biotype&quot; ## [72,] &quot;SnpEff_refseq_Gene_name&quot; ## [73,] &quot;SnpEff_refseq_Gene_ID&quot; ## [74,] &quot;SnpEff_refseq_HGVSc&quot; ## [75,] &quot;SnpEff_refseq_HGVSp&quot; ## [76,] &quot;SnpEff_refseq_Protein_position_or_Protein_len&quot; ## [77,] &quot;SnpEff_refseq_CDS_position_or_CDS_len&quot; ## [78,] &quot;SnpEff_refseq_cDNA_position_or_cDNA_len&quot; ## [79,] &quot;SnpEff_refseq_Exon_or_intron_rank_or_total&quot; ## [80,] &quot;SnpEff_refseq_Distance_to_feature&quot; ## [81,] &quot;SnpEff_refseq_Warnings&quot; ## [82,] &quot;SnpEff_refseq_LOF_or_NMD&quot; ## [83,] &quot;SnpEff_refseq_LOF_or_NMD_gene_name&quot; ## [84,] &quot;SnpEff_refseq_LOF_or_NMD_gene_ID&quot; ## [85,] &quot;SnpEff_refseq_LOF_or_NMD_num_transcripts_affected&quot; ## [86,] &quot;SnpEff_refseq_LOF_or_NMD_percent_transcripts_affected&quot; ## [87,] &quot;SnpEff_refseq_TF_binding_effect&quot; ## [88,] &quot;SnpEff_refseq_TF_name&quot; ## [89,] &quot;SnpEff_refseq_TF_ID&quot; ## [90,] &quot;SnpEff_refseq_summary&quot; ## [91,] &quot;VEP_refseq_Consequence&quot; ## [92,] &quot;VEP_refseq_Transcript_ID&quot; ## [93,] &quot;VEP_refseq_Gene_Name&quot; ## [94,] &quot;VEP_refseq_Gene_ID&quot; ## [95,] &quot;VEP_refseq_Protein_ID(ENSP)&quot; ## [96,] &quot;VEP_refseq_Codon_Change_or_Distance&quot; ## [97,] &quot;VEP_refseq_Amino_Acid_Change&quot; ## [98,] &quot;VEP_refseq_HGVSc&quot; ## [99,] &quot;VEP_refseq_HGVSp&quot; ## [100,] &quot;VEP_refseq_cDNA_position&quot; ## [101,] &quot;VEP_refseq_CDS_position&quot; ## [102,] &quot;VEP_refseq_Protein_position&quot; ## [103,] &quot;VEP_refseq_Exon_or_Intron_Rank&quot; ## [104,] &quot;VEP_refseq_STRAND&quot; ## [105,] &quot;VEP_refseq_CANONICAL&quot; ## [106,] &quot;VEP_refseq_LoF&quot; ## [107,] &quot;VEP_refseq_LoF_filter&quot; ## [108,] &quot;VEP_refseq_LoF_flags&quot; ## [109,] &quot;VEP_refseq_LoF_info&quot; ## [110,] &quot;VEP_refseq_summary&quot; ## [111,] &quot;ANNOVAR_ucsc_Effect&quot; ## [112,] &quot;ANNOVAR_ucsc_Transcript_ID&quot; ## [113,] &quot;ANNOVAR_ucsc_Gene_ID&quot; ## [114,] &quot;ANNOVAR_ucsc_Closest_gene&quot; ## [115,] &quot;ANNOVAR_ucsc_HGVSc&quot; ## [116,] &quot;ANNOVAR_ucsc_HGVSp&quot; ## [117,] &quot;ANNOVAR_ucsc_Exon_Rank&quot; ## [118,] &quot;ANNOVAR_ucsc_summary&quot; ## [119,] &quot;rs_dbSNP150&quot; ## [120,] &quot;sno_miRNA_name&quot; ## [121,] &quot;sno_miRNA_type&quot; ## [122,] &quot;UTR3_miRNA_target&quot; ## [123,] &quot;TargetScan_context_pp_score_percentile&quot; ## [124,] &quot;splicing_consensus_ada_score&quot; ## [125,] &quot;splicing_consensus_rf_score&quot; ## [126,] &quot;GWAS_catalog_rs&quot; ## [127,] &quot;GWAS_catalog_trait&quot; ## [128,] &quot;GWAS_catalog_pubmedid&quot; ## [129,] &quot;GRASP_rs&quot; ## [130,] &quot;GRASP_PMID&quot; ## [131,] &quot;GRASP_p_value&quot; ## [132,] &quot;GRASP_phenotype&quot; ## [133,] &quot;GRASP_ancestry&quot; ## [134,] &quot;GRASP_platform&quot; ## [135,] &quot;clinvar_rs&quot; ## [136,] &quot;clinvar_clnsig&quot; ## [137,] &quot;clinvar_trait&quot; ## [138,] &quot;clinvar_golden_stars&quot; ## [139,] &quot;GTEx_V6p_gene&quot; ## [140,] &quot;GTEx_V6p_tissue&quot; ## [141,] &quot;MAP20&quot; ## [142,] &quot;MAP35&quot; ## [143,] &quot;MAP20_149bp&quot; ## [144,] &quot;MAP35_149&quot; ## [145,] &quot;GMS_single_end&quot; ## [146,] &quot;GMS_paired_end&quot; ## [147,] &quot;KGP_strict_masked&quot; ## [148,] &quot;RepeatMasker_masked&quot; ## [149,] &quot;Ancestral_allele&quot; ## [150,] &quot;AltaiNeandertal_genotypes&quot; ## [151,] &quot;Denisova_genotypes&quot; ## [152,] &quot;VindijiaNeandertal_genotypes&quot; ## [153,] &quot;phyloP46way_primate&quot; ## [154,] &quot;phyloP46way_primate_rankscore&quot; ## [155,] &quot;phyloP20way_mammalian&quot; ## [156,] &quot;phyloP20way_mammalian_rankscore&quot; ## [157,] &quot;phyloP100way_vertebrate&quot; ## [158,] &quot;phyloP100way_vertebrate_rankscore&quot; ## [159,] &quot;phastCons46way_primate&quot; ## [160,] &quot;phastCons46way_primate_rankscore&quot; ## [161,] &quot;phastCons20way_mammalian&quot; ## [162,] &quot;phastCons20way_mammalian_rankscore&quot; ## [163,] &quot;phastCons100way_vertebrate&quot; ## [164,] &quot;phastCons100way_vertebrate_rankscore&quot; ## [165,] &quot;GERP_NR&quot; ## [166,] &quot;GERP_RS&quot; ## [167,] &quot;GERP_RS_rankscore&quot; ## [168,] &quot;SiPhy_29way_logOdds&quot; ## [169,] &quot;SiPhy_29way_logOdds_rankscore&quot; ## [170,] &quot;integrated_fitCons_score&quot; ## [171,] &quot;integrated_fitCons_rankscore&quot; ## [172,] &quot;integrated_confidence_value&quot; ## [173,] &quot;GM12878_fitCons_score&quot; ## [174,] &quot;GM12878_fitCons_rankscore&quot; ## [175,] &quot;GM12878_confidence_value&quot; ## [176,] &quot;H1_hESC_fitCons_score&quot; ## [177,] &quot;H1_hESC_fitCons_rankscore&quot; ## [178,] &quot;H1_hESC_confidence_value&quot; ## [179,] &quot;HUVEC_fitCons_score&quot; ## [180,] &quot;HUVEC_fitCons_rankscore&quot; ## [181,] &quot;HUVEC_confidence_value&quot; ## [182,] &quot;GenoCanyon_score&quot; ## [183,] &quot;GenoCanyon_rankscore&quot; ## [184,] &quot;KGP3_AC&quot; ## [185,] &quot;KGP3_AF&quot; ## [186,] &quot;KGP3_AFR_AC&quot; ## [187,] &quot;KGP3_AFR_AF&quot; ## [188,] &quot;KGP3_EUR_AC&quot; ## [189,] &quot;KGP3_EUR_AF&quot; ## [190,] &quot;KGP3_AMR_AC&quot; ## [191,] &quot;KGP3_AMR_AF&quot; ## [192,] &quot;KGP3_EAS_AC&quot; ## [193,] &quot;KGP3_EAS_AF&quot; ## [194,] &quot;KGP3_SAS_AC&quot; ## [195,] &quot;KGP3_SAS_AF&quot; ## [196,] &quot;UK10K_AC&quot; ## [197,] &quot;UK10K_AN&quot; ## [198,] &quot;UK10K_AF&quot; ## [199,] &quot;TWINSUK_AC&quot; ## [200,] &quot;TWINSUK_AN&quot; ## [201,] &quot;TWINSUK_AF&quot; ## [202,] &quot;ALSPAC_AC&quot; ## [203,] &quot;ALSPAC_AN&quot; ## [204,] &quot;ALSPAC_AF&quot; ## [205,] &quot;ESP6500_AC&quot; ## [206,] &quot;ESP6500_AF&quot; ## [207,] &quot;ESP6500_AA_AC&quot; ## [208,] &quot;ESP6500_AA_AF&quot; ## [209,] &quot;ESP6500_EA_AC&quot; ## [210,] &quot;ESP6500_EA_AF&quot; ## [211,] &quot;ExAC_AC&quot; ## [212,] &quot;ExAC_AF&quot; ## [213,] &quot;ExAC_Adj_AC&quot; ## [214,] &quot;ExAC_Adj_AF&quot; ## [215,] &quot;ExAC_AFR_AC&quot; ## [216,] &quot;ExAC_AFR_AF&quot; ## [217,] &quot;ExAC_AMR_AC&quot; ## [218,] &quot;ExAC_AMR_AF&quot; ## [219,] &quot;ExAC_EAS_AC&quot; ## [220,] &quot;ExAC_EAS_AF&quot; ## [221,] &quot;ExAC_FIN_AC&quot; ## [222,] &quot;ExAC_FIN_AF&quot; ## [223,] &quot;ExAC_NFE_AC&quot; ## [224,] &quot;ExAC_NFE_AF&quot; ## [225,] &quot;ExAC_SAS_AC&quot; ## [226,] &quot;ExAC_SAS_AF&quot; ## [227,] &quot;ExAC_nonTCGA_AC&quot; ## [228,] &quot;ExAC_nonTCGA_AF&quot; ## [229,] &quot;ExAC_nonTCGA_Adj_AC&quot; ## [230,] &quot;ExAC_nonTCGA_Adj_AF&quot; ## [231,] &quot;ExAC_nonTCGA_AFR_AC&quot; ## [232,] &quot;ExAC_nonTCGA_AFR_AF&quot; ## [233,] &quot;ExAC_nonTCGA_AMR_AC&quot; ## [234,] &quot;ExAC_nonTCGA_AMR_AF&quot; ## [235,] &quot;ExAC_nonTCGA_EAS_AC&quot; ## [236,] &quot;ExAC_nonTCGA_EAS_AF&quot; ## [237,] &quot;ExAC_nonTCGA_FIN_AC&quot; ## [238,] &quot;ExAC_nonTCGA_FIN_AF&quot; ## [239,] &quot;ExAC_nonTCGA_NFE_AC&quot; ## [240,] &quot;ExAC_nonTCGA_NFE_AF&quot; ## [241,] &quot;ExAC_nonTCGA_SAS_AC&quot; ## [242,] &quot;ExAC_nonTCGA_SAS_AF&quot; ## [243,] &quot;ExAC_nonpsych_AC&quot; ## [244,] &quot;ExAC_nonpsych_AF&quot; ## [245,] &quot;ExAC_nonpsych_Adj_AC&quot; ## [246,] &quot;ExAC_nonpsych_Adj_AF&quot; ## [247,] &quot;ExAC_nonpsych_AFR_AC&quot; ## [248,] &quot;ExAC_nonpsych_AFR_AF&quot; ## [249,] &quot;ExAC_nonpsych_AMR_AC&quot; ## [250,] &quot;ExAC_nonpsych_AMR_AF&quot; ## [251,] &quot;ExAC_nonpsych_EAS_AC&quot; ## [252,] &quot;ExAC_nonpsych_EAS_AF&quot; ## [253,] &quot;ExAC_nonpsych_FIN_AC&quot; ## [254,] &quot;ExAC_nonpsych_FIN_AF&quot; ## [255,] &quot;ExAC_nonpsych_NFE_AC&quot; ## [256,] &quot;ExAC_nonpsych_NFE_AF&quot; ## [257,] &quot;ExAC_nonpsych_SAS_AC&quot; ## [258,] &quot;ExAC_nonpsych_SAS_AF&quot; ## [259,] &quot;gnomAD_exomes_AC&quot; ## [260,] &quot;gnomAD_exomes_AN&quot; ## [261,] &quot;gnomAD_exomes_AF&quot; ## [262,] &quot;gnomAD_exomes_AFR_AC&quot; ## [263,] &quot;gnomAD_exomes_AFR_AN&quot; ## [264,] &quot;gnomAD_exomes_AFR_AF&quot; ## [265,] &quot;gnomAD_exomes_AMR_AC&quot; ## [266,] &quot;gnomAD_exomes_AMR_AN&quot; ## [267,] &quot;gnomAD_exomes_AMR_AF&quot; ## [268,] &quot;gnomAD_exomes_ASJ_AC&quot; ## [269,] &quot;gnomAD_exomes_ASJ_AN&quot; ## [270,] &quot;gnomAD_exomes_ASJ_AF&quot; ## [271,] &quot;gnomAD_exomes_EAS_AC&quot; ## [272,] &quot;gnomAD_exomes_EAS_AN&quot; ## [273,] &quot;gnomAD_exomes_EAS_AF&quot; ## [274,] &quot;gnomAD_exomes_FIN_AC&quot; ## [275,] &quot;gnomAD_exomes_FIN_AN&quot; ## [276,] &quot;gnomAD_exomes_FIN_AF&quot; ## [277,] &quot;gnomAD_exomes_NFE_AC&quot; ## [278,] &quot;gnomAD_exomes_NFE_AN&quot; ## [279,] &quot;gnomAD_exomes_NFE_AF&quot; ## [280,] &quot;gnomAD_exomes_SAS_AC&quot; ## [281,] &quot;gnomAD_exomes_SAS_AN&quot; ## [282,] &quot;gnomAD_exomes_SAS_AF&quot; ## [283,] &quot;gnomAD_exomes_OTH_AC&quot; ## [284,] &quot;gnomAD_exomes_OTH_AN&quot; ## [285,] &quot;gnomAD_exomes_OTH_AF&quot; ## [286,] &quot;gnomAD_genomes_AC&quot; ## [287,] &quot;gnomAD_genomes_AN&quot; ## [288,] &quot;gnomAD_genomes_AF&quot; ## [289,] &quot;gnomAD_genomes_AFR_AC&quot; ## [290,] &quot;gnomAD_genomes_AFR_AN&quot; ## [291,] &quot;gnomAD_genomes_AFR_AF&quot; ## [292,] &quot;gnomAD_genomes_AMR_AC&quot; ## [293,] &quot;gnomAD_genomes_AMR_AN&quot; ## [294,] &quot;gnomAD_genomes_AMR_AF&quot; ## [295,] &quot;gnomAD_genomes_ASJ_AC&quot; ## [296,] &quot;gnomAD_genomes_ASJ_AN&quot; ## [297,] &quot;gnomAD_genomes_ASJ_AF&quot; ## [298,] &quot;gnomAD_genomes_EAS_AC&quot; ## [299,] &quot;gnomAD_genomes_EAS_AN&quot; ## [300,] &quot;gnomAD_genomes_EAS_AF&quot; ## [301,] &quot;gnomAD_genomes_FIN_AC&quot; ## [302,] &quot;gnomAD_genomes_FIN_AN&quot; ## [303,] &quot;gnomAD_genomes_FIN_AF&quot; ## [304,] &quot;gnomAD_genomes_NFE_AC&quot; ## [305,] &quot;gnomAD_genomes_NFE_AN&quot; ## [306,] &quot;gnomAD_genomes_NFE_AF&quot; ## [307,] &quot;gnomAD_genomes_OTH_AC&quot; ## [308,] &quot;gnomAD_genomes_OTH_AN&quot; ## [309,] &quot;gnomAD_genomes_OTH_AF&quot; ## [310,] &quot;RegulomeDB_motif&quot; ## [311,] &quot;RegulomeDB_score&quot; ## [312,] &quot;Motif_breaking&quot; ## [313,] &quot;network_hub&quot; ## [314,] &quot;ENCODE_annotated&quot; ## [315,] &quot;sensitive&quot; ## [316,] &quot;ultra_sensitive&quot; ## [317,] &quot;target_gene&quot; ## [318,] &quot;funseq_noncoding_score&quot; ## [319,] &quot;funseq2_noncoding_score&quot; ## [320,] &quot;funseq2_noncoding_rankscore&quot; ## [321,] &quot;CADD_raw&quot; ## [322,] &quot;CADD_phred&quot; ## [323,] &quot;CADD_raw_rankscore&quot; ## [324,] &quot;DANN_score&quot; ## [325,] &quot;DANN_rank_score&quot; ## [326,] &quot;fathmm_MKL_non_coding_score&quot; ## [327,] &quot;fathmm_MKL_non_coding_rankscore&quot; ## [328,] &quot;fathmm_MKL_non_coding_pred&quot; ## [329,] &quot;fathmm_MKL_non_coding_group&quot; ## [330,] &quot;fathmm_MKL_coding_score&quot; ## [331,] &quot;fathmm_MKL_coding_rankscore&quot; ## [332,] &quot;fathmm_MKL_coding_pred&quot; ## [333,] &quot;fathmm_MKL_coding_group&quot; ## [334,] &quot;Eigen_coding_or_noncoding&quot; ## [335,] &quot;Eigen_raw&quot; ## [336,] &quot;Eigen_phred&quot; ## [337,] &quot;Eigen_PC_raw&quot; ## [338,] &quot;Eigen_PC_phred&quot; ## [339,] &quot;ORegAnno_type&quot; ## [340,] &quot;ORegAnno_PMID&quot; ## [341,] &quot;hESC_Topological_Domain&quot; ## [342,] &quot;IMR90_Topological_Domain&quot; ## [343,] &quot;ENCODE_TFBS&quot; ## [344,] &quot;ENCODE_TFBS_score&quot; ## [345,] &quot;ENCODE_TFBS_cells&quot; ## [346,] &quot;ENCODE_Dnase_score&quot; ## [347,] &quot;ENCODE_Dnase_cells&quot; ## [348,] &quot;EnhancerFinder_general_developmental_enhancer&quot; ## [349,] &quot;EnhancerFinder_brain_enhancer&quot; ## [350,] &quot;EnhancerFinder_heart_enhancer&quot; ## [351,] &quot;EnhancerFinder_limb_enhancer&quot; ## [352,] &quot;SuperEnhancer_tissue_cell&quot; ## [353,] &quot;SuperEnhancer_RefSeq_id&quot; ## [354,] &quot;SuperEnhancer_Gene_symbol&quot; ## [355,] &quot;FANTOM5_enhancer_permissive&quot; ## [356,] &quot;FANTOM5_enhancer_robust&quot; ## [357,] &quot;FANTOM5_enhancer_target&quot; ## [358,] &quot;FANTOM5_enhancer_expressed_tissue_cell&quot; ## [359,] &quot;FANTOM5_enhancer_differentially_expressed_tissue_cell&quot; ## [360,] &quot;FANTOM5_CAGE_peak_permissive&quot; ## [361,] &quot;FANTOM5_CAGE_peak_robust&quot; ## [362,] &quot;Ensembl_Regulatory_Build_feature_type&quot; ## [363,] &quot;Ensembl_Regulatory_Build_ID&quot; ## [364,] &quot;Ensembl_Regulatory_Build_TFBS&quot; ## [365,] &quot;Ensembl_Regulatory_Build_TFBS_matrix&quot; ## [366,] &quot;aaref&quot; ## [367,] &quot;aaalt&quot; ## [368,] &quot;genename&quot; ## [369,] &quot;cds_strand&quot; ## [370,] &quot;refcodon&quot; ## [371,] &quot;codonpos&quot; ## [372,] &quot;codon_degeneracy&quot; ## [373,] &quot;Ensembl_geneid&quot; ## [374,] &quot;Ensembl_transcriptid&quot; ## [375,] &quot;Ensembl_proteinid&quot; ## [376,] &quot;aapos&quot; ## [377,] &quot;SIFT_score&quot; ## [378,] &quot;SIFT_converted_rankscore&quot; ## [379,] &quot;SIFT_pred&quot; ## [380,] &quot;Uniprot_acc_Polyphen2&quot; ## [381,] &quot;Uniprot_id_Polyphen2&quot; ## [382,] &quot;Uniprot_aapos_Polyphen2&quot; ## [383,] &quot;Polyphen2_HDIV_score&quot; ## [384,] &quot;Polyphen2_HDIV_rankscore&quot; ## [385,] &quot;Polyphen2_HDIV_pred&quot; ## [386,] &quot;Polyphen2_HVAR_score&quot; ## [387,] &quot;Polyphen2_HVAR_rankscore&quot; ## [388,] &quot;Polyphen2_HVAR_pred&quot; ## [389,] &quot;LRT_score&quot; ## [390,] &quot;LRT_converted_rankscore&quot; ## [391,] &quot;LRT_pred&quot; ## [392,] &quot;LRT_Omega&quot; ## [393,] &quot;MutationTaster_score&quot; ## [394,] &quot;MutationTaster_converted_rankscore&quot; ## [395,] &quot;MutationTaster_pred&quot; ## [396,] &quot;MutationTaster_model&quot; ## [397,] &quot;MutationTaster_AAE&quot; ## [398,] &quot;MutationAssessor_UniprotID&quot; ## [399,] &quot;MutationAssessor_variant&quot; ## [400,] &quot;MutationAssessor_score&quot; ## [401,] &quot;MutationAssessor_score_rankscore&quot; ## [402,] &quot;MutationAssessor_pred&quot; ## [403,] &quot;FATHMM_score&quot; ## [404,] &quot;FATHMM_converted_rankscore&quot; ## [405,] &quot;FATHMM_pred&quot; ## [406,] &quot;PROVEAN_score&quot; ## [407,] &quot;PROVEAN_converted_rankscore&quot; ## [408,] &quot;PROVEAN_pred&quot; ## [409,] &quot;Transcript_id_VEST3&quot; ## [410,] &quot;Transcript_var_VEST3&quot; ## [411,] &quot;VEST3_score&quot; ## [412,] &quot;VEST3_rankscore&quot; ## [413,] &quot;MetaSVM_score&quot; ## [414,] &quot;MetaSVM_rankscore&quot; ## [415,] &quot;MetaSVM_pred&quot; ## [416,] &quot;MetaLR_score&quot; ## [417,] &quot;MetaLR_rankscore&quot; ## [418,] &quot;MetaLR_pred&quot; ## [419,] &quot;Reliability_index&quot; ## [420,] &quot;M_CAP_score&quot; ## [421,] &quot;M_CAP_rankscore&quot; ## [422,] &quot;M_CAP_pred&quot; ## [423,] &quot;REVEL_score&quot; ## [424,] &quot;REVEL_rankscore&quot; ## [425,] &quot;MutPred_score&quot; ## [426,] &quot;MutPred_rankscore&quot; ## [427,] &quot;MutPred_protID&quot; ## [428,] &quot;MutPred_AAchange&quot; ## [429,] &quot;MutPred_Top5features&quot; ## [430,] &quot;SIFT4G_AAref&quot; ## [431,] &quot;SIFT4G_AAalt&quot; ## [432,] &quot;SIFT4G_AApos&quot; ## [433,] &quot;SIFT4G_score&quot; ## [434,] &quot;SIFT4G_pred&quot; ## [435,] &quot;VEP_ensembl_precedent_transcript_consequence&quot; ## [436,] &quot;VEP_ensembl_precedent_consequence&quot; ## [437,] &quot;VEP_ensembl_precedent_gene&quot; ## [438,] &quot;unique_variant&quot; Only a subset of these annotations will be necessary for a particular association test, and it is unweildy to work with all of them, so it is useful to process the WGSA output file to select fields of interest. An additional complication in working with the WGSA output files is that some of the annotation fields are transcript-based, rather than position-based. Thus, if a variant locus is within multiple transcripts, those fields will have multiple entries (often separated by a | character). For example, annotation fields such as VEP_ensembl_Transcript_ID may have many values within a single tab-separated field. WGSAParsr’s parse_to_file() addresses this by splitting such list-fields into multiple rows. Other annotation fields for that variant are duplicated, and associated columns are filled with the same value for each transcript that a particular variant falls within. A consequence of this approach is that the processed annotation file has more lines than the WGSA output file. In freeze 4, processing expanded the annotation by a factor of about 5 - the 220 million annotations result in a 1-billion row database for subsequent aggregation. parse_to_file() function arguments include a path to a WGSA annotation file, a user-defined configuration file, and output destinations. It reads the input annotation file in chunks, processes them following the specification provided in the user-defined configuration file, and writes to the output destinations. It produces a tab-separated output file useful for subsequent analysis. The first task, then, is to build the configuration file for parse_to_file(). 11.1.1 WGSAParsr Configuration Details of the configuration file are documented in the wgsaparsr::load_config() function documentation, ?load_config From the documentation, you can see that the configuration file is a tab-separated text file that must have the following columns (in any order): field, SNV, indel, dbnsfp, pivotGroup, pivotChar, parseGroup, and transformation. You will look at each of these fields in turn as you build your configuration file. Additionally, the configuration file that the TOPMed DCC used to parse the freeze 5 data release is included as an example in the WGSAParsr package. The configuration file you’ll make in this workshop will not be as extensive or complicated as the example, but if you’d like, you can load it into your working session to examine: freeze_5_config &lt;- load_config(wgsaparsr_example(&quot;fr_5_config.tsv&quot;)) ## Warning: Prefixing `UQ()` with the rlang namespace is deprecated as of rlang 0.3.0. ## Please use the non-prefixed form or `!!` instead. ## ## # Bad: ## rlang::expr(mean(rlang::UQ(var) * 100)) ## ## # Ok: ## rlang::expr(mean(UQ(var) * 100)) ## ## # Good: ## rlang::expr(mean(!!var * 100)) ## ## This warning is displayed once per session. Recall that our objective is to aggregate the variants into genic units and to apply filters to restrict the variants in aggreagation units by predicted functional consequence. To achieve this, we will use the following annotation fields: CHROM, POS, REF, ALT, VEP_ensembl_Gene_ID, VEP_ensembl_Consequence, and CADD_phred. This list of fields is the first variable we’ll need for the configuration file: field &lt;- c(&quot;CHROM&quot;, &quot;POS&quot;, &quot;REF&quot;, &quot;ALT&quot;, &quot;VEP_ensembl_Gene_ID&quot;, &quot;VEP_ensembl_Consequence&quot;, &quot;CADD_phred&quot;) The next required variable is SNV, a logical value indiciating whether these fields are present in the SNV annotation file. In this case, all of the fields are present in SNV annotation: SNV &lt;- c(rep(TRUE, 7)) Then comes indel, a logical value indicating whether these fields are present in the indel annotation file. In this case, all of the fields are present in indel annotation: indel &lt;- c(rep(TRUE, 7)) dbNSFP is an annotation resource included in WGSA. These annotation fields reference gene-oriented features rather than transcript-oriented features, so must be parsed separately if needed for analysis. We do not need to use any dbNSFP variables in this exercise, so the dbnsfp variable is FALSE in our configuration: dbnsfp &lt;- c(rep(FALSE, 7)) The next two variables are related to the pivoting of annotation list-fields to make them “tidy”. Recall that some annotation fields have many values within a single tab-separated field. For example, there is a variant on chromosome 22 at position 15699830 that is annotated with this VEP_ensembl_Gene_ID: ENSG00000198062|ENSG00000236666|ENSG00000212216|ENSG00000198062|ENSG00000198062 and this VEP_ensembl_Consequence: intron_variant,NMD_transcript_variant|non_coding_transcript_exon_variant,non_coding_transcript_variant|upstream_gene_variant|intron_variant|intron_variant. Such list-fields are awkward to work with, so they should be split into 5 lines, with the corresponding fields on the same line (e.g. the first VEP_ensembl_Gene_ID entry and the first VEP_ensembl_Consequence should go together). This is specified in the configuration file using the pivotGroup variable and the pivotChar variable is used to specify the character that is the list delimiter - | in this case. Build the pivotGroup and pivotChar variables like this for your configuration: pivotGroup &lt;- c(rep(NA, 4), rep(as.integer(1), 2), NA) pivotChar &lt;- c(rep(NA, 4), rep(&quot;|&quot;, 2), NA) The final required variables for the configuration are parseGroup, and transformation. parseGroup defines sets of annotation fields that should be modified together (this primarily applies to sets of dbnsfp annotation fields), and transformation defines the modification that should happen. Valid values for transformation include max, min, pick_Y, pick_N, pick_A, clean, and distinct. WGSAParsr applies the specified transformation to the field specified in the configuration file, and selects the corresponding value from other fields in the same parseGroup. No transformation or parseGroup is needed for this exercise, but to give an example for completeness, position 21791443 of chromosome 22 has a variant from reference A, the alternative AACAT. This variant is annotated with this Eigen_PC_raw value: .{2}-0.08822322727842{1}-0.0955006471597487{1}. A transformation of max would select the maximum numeric value of this annotation field - the value likely to have the most functional impact - of -0.08822322727842. If there were another field with corresponding entries, such as that variant’s Eigen_raw value: .{2}-0.27473415163451{1}-0.313313344373439{1}, membership in the same parseGroup would pick the value in that field that corresponded to the maximum value in the Eigen_PC_raw annotation - in this case, -0.27473415163451. Note that the transformation would not return the maximum Eigen_raw value in this case. Other possible transformations include the following: min selects the minimum value, pick_Y picks the character Y if present,pick_N picks the character N if present, pick_A picks the character A (used for the MutationTaster_pred annotation), clean removes unneeded bracketed number strings (used for Ensembl_Regulatory_Build_feature_type, hESC_Topological_Domain, and IMR90_Topological_Domain fields), and distinct splits a field to disticnt values (used for Ensembl_Regulatory_Build_TFBS). None of these transformations are needed for our filtering and aggregation, so we can define the variables for the configuration this way: parseGroup &lt;- c(rep(as.integer(NA), 7)) transformation &lt;- c(rep(as.character(NA), 7)) Finally, add an optional configuration variable: order. The order variable spcifies the column-order in the output file - this is particularly useful if you’re working with many annotations, but want to make sure that CHROM, POS, REF, and ALT are at the beginning. Note: when using order un-numbered fields will go after numbered fields. order &lt;- seq(1,7) Put the configuration variables together in a tibble for validation and saving (a tibble is a particular kind of data frame): my_config &lt;- tibble( field, SNV, indel, dbnsfp, pivotGroup, pivotChar, parseGroup, transformation, order ) Now inspect the configuration tibble: my_config ## # A tibble: 7 x 9 ## field SNV indel dbnsfp pivotGroup pivotChar parseGroup transformation ## &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 CHROM TRUE TRUE FALSE NA &lt;NA&gt; NA &lt;NA&gt; ## 2 POS TRUE TRUE FALSE NA &lt;NA&gt; NA &lt;NA&gt; ## 3 REF TRUE TRUE FALSE NA &lt;NA&gt; NA &lt;NA&gt; ## 4 ALT TRUE TRUE FALSE NA &lt;NA&gt; NA &lt;NA&gt; ## 5 VEP_… TRUE TRUE FALSE 1 | NA &lt;NA&gt; ## 6 VEP_… TRUE TRUE FALSE 1 | NA &lt;NA&gt; ## 7 CADD… TRUE TRUE FALSE NA &lt;NA&gt; NA &lt;NA&gt; ## # … with 1 more variable: order &lt;int&gt; WGSAParsr includes a configuration validation function, validate_config(). A valid configuration tibble or file should get no errors from the validation function: validate_config(my_config) save my_config write_tsv(my_config, &quot;data/my_config.tsv&quot;) # a bit of cleanup needed for the workshop if (file.exists(&quot;data/snv_parsed.tsv&quot;))(file.remove(&quot;data/snv_parsed.tsv&quot;)) if (file.exists(&quot;data/indel_parsed.tsv&quot;))(file.remove(&quot;data/indel_parsed.tsv&quot;)) 11.1.2 Parsing with WGSAParsr parse the example files parse_to_file(source_file = snvfile, config = &quot;data/my_config.tsv&quot;, destination = &quot;data/snv_parsed.tsv&quot;, chunk_size = 100, verbose = FALSE) parse_to_file(source_file = indelfile, config = &quot;data/my_config.tsv&quot;, destination = &quot;data/indel_parsed.tsv&quot;, chunk_size = 100, verbose = FALSE) Although the output file has fewer columns than the the raw WGSA output file, this .tsv file is still not particularly nice to work with directly: readLines(&quot;data/snv_parsed.tsv&quot;, n=2) ## [1] &quot;CHROM\\tPOS\\tREF\\tALT\\tVEP_ensembl_Gene_ID\\tVEP_ensembl_Consequence\\tCADD_phred&quot; ## [2] &quot;22\\t15319214\\tC\\tG\\t.\\tintergenic_variant\\t1.218&quot; But get_fields() works as expected on the parsed file: # list all fields in an annotation file: get_fields(&quot;data/snv_parsed.tsv&quot;) ## [,1] [,2] [,3] [,4] [,5] ## [1,] &quot;CHROM&quot; &quot;POS&quot; &quot;REF&quot; &quot;ALT&quot; &quot;VEP_ensembl_Gene_ID&quot; ## [,6] [,7] ## [1,] &quot;VEP_ensembl_Consequence&quot; &quot;CADD_phred&quot; And in this case, the parsed files are small enough that we can load them into the R session and work with the resulting dataframes for subsequent analysis. (At full scale, the TOPMed DCC imports the parsed files to a database, and uses the annotation data that way): snv_annotation &lt;- read_tsv(&quot;data/snv_parsed.tsv&quot;, col_types = cols( CHROM = col_character(), POS = col_integer(), REF = col_character(), ALT = col_character(), VEP_ensembl_Gene_ID = col_character(), VEP_ensembl_Consequence = col_character(), CADD_phred = col_double() )) ## Warning: 14 parsing failures. ## row col expected actual file ## 2 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 6 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 365 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 366 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 367 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## ... .......... ........ ...... ..................... ## See problems(...) for more details. Since there are warnings on that loading, check them out: problems(snv_annotation) ## # A tibble: 14 x 5 ## row col expected actual file ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 2 6 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 3 365 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 4 366 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 5 367 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 6 368 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 7 369 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 8 370 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 9 377 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 10 394 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 11 395 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 12 2243 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 13 2244 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; ## 14 2253 CADD_phred a double . &#39;data/snv_parsed.tsv&#39; Ah, so not really anything to worry about - “.” values will be replaced with NA when casting to type double. Go ahead and read the indel file: indel_annotation &lt;- read_tsv(&quot;data/indel_parsed.tsv&quot;, col_types = cols( CHROM = col_character(), POS = col_integer(), REF = col_character(), ALT = col_character(), VEP_ensembl_Gene_ID = col_character(), VEP_ensembl_Consequence = col_character(), CADD_phred = col_double() )) And since that’s fine, go ahead and put them together for subsequent analysis: combined_annotation &lt;- bind_rows(snv_annotation, indel_annotation) 11.2 Aggregating and filtering variants using annotation With the now-tidy variant annotation, the process of aggregating and filtering variants for association testing is almost trivial. For example, an analyst could remove variants that are not associated with a Gene, group the variants by gene, and filter the variants for intron_variants with a CADD_phred score greater than 3 in just a few lines of code: combined_annotation %&gt;% filter(VEP_ensembl_Gene_ID != &quot;.&quot;) %&gt;% # remove variants not annotated with a Gene_ID group_by(VEP_ensembl_Gene_ID) %&gt;% # aggregate by gene filter(CADD_phred &gt; 3) %&gt;% # filter variants to keep only CADD_phred greater than 3 filter(str_detect(VEP_ensembl_Consequence, &quot;intron_variant&quot;)) %&gt;% # keep intron variants glimpse() # view the result - 592 variants ## Observations: 592 ## Variables: 7 ## Groups: VEP_ensembl_Gene_ID [170] ## $ CHROM &lt;chr&gt; &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;… ## $ POS &lt;int&gt; 15699830, 15699830, 16437047, 16445862, … ## $ REF &lt;chr&gt; &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;C&quot;, &quot;C&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, … ## $ ALT &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;T&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, … ## $ VEP_ensembl_Gene_ID &lt;chr&gt; &quot;ENSG00000198062&quot;, &quot;ENSG00000198062&quot;, &quot;E… ## $ VEP_ensembl_Consequence &lt;chr&gt; &quot;intron_variant,NMD_transcript_variant&quot;,… ## $ CADD_phred &lt;dbl&gt; 3.612, 3.612, 9.729, 3.895, 7.530, 5.332… Now that you’ve got a set of variants that you can aggregate into genic units, the tibble needs to be reformatted for input to the GENESIS analysis pipeline. The input to the GENESIS pipeline is a data frame with variables called group_id, chr, pos, ref, and alt. Prepare this data frame and save it for testing (You do not need to filter the variants for this exercise): aggregates &lt;- combined_annotation %&gt;% filter(VEP_ensembl_Gene_ID != &quot;.&quot;) %&gt;% # remove variants not annotated with a Gene_ID group_by(VEP_ensembl_Gene_ID) %&gt;% # aggregate by gene select(group_id = VEP_ensembl_Gene_ID, chr = CHROM, pos = POS, ref = REF, alt = ALT) %&gt;% glimpse # inspect the tibble ## Observations: 2,603 ## Variables: 5 ## Groups: group_id [598] ## $ group_id &lt;chr&gt; &quot;ENSG00000230643&quot;, &quot;ENSG00000226474&quot;, &quot;ENSG00000231565&quot;… ## $ chr &lt;chr&gt; &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;… ## $ pos &lt;int&gt; 15589963, 15613723, 15613723, 15628559, 15699830, 15699… ## $ ref &lt;chr&gt; &quot;G&quot;, &quot;A&quot;, &quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, &quot;G&quot;, … ## $ alt &lt;chr&gt; &quot;T&quot;, &quot;G&quot;, &quot;G&quot;, &quot;T&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;T&quot;, &quot;T&quot;, &quot;T&quot;, … This set can be saved for futher analysis, if you’d like. save(aggregates, file = &quot;data/chr_22_by_gene.RData&quot;) You can also compute some summary information about these aggregates, such as counting how many genic units we’re using: distinct(as.tibble(aggregates$group_id)) ## Warning: `as.tibble()` is deprecated, use `as_tibble()` (but mind the new semantics). ## This warning is displayed once per session. ## # A tibble: 598 x 1 ## value ## &lt;chr&gt; ## 1 ENSG00000230643 ## 2 ENSG00000226474 ## 3 ENSG00000231565 ## 4 ENSG00000224435 ## 5 ENSG00000198062 ## 6 ENSG00000236666 ## 7 ENSG00000212216 ## 8 ENSG00000223875 ## 9 ENSG00000233866 ## 10 ENSG00000229658 ## # … with 588 more rows We can look at the distribution of the number of variants per aggregation unit: counts &lt;- aggregates %&gt;% group_by(group_id) %&gt;% summarize(n = n()) ggplot(counts, aes(x = n)) + geom_bar() Feel free to look at other summary statistics and do other exploratory data analysis as you’d like! "],
["aggregate-tests.html", "12 Aggregate tests 12.1 Aggregate unit for association testing exercise 12.2 Association testing with aggregate units 12.3 Exercise", " 12 Aggregate tests 12.1 Aggregate unit for association testing exercise Now you can proceed to an assocation testing exercise. You will be using a slightly different gene-based aggregation unit for the assocation testing exercise. In this exercise, the genic units include SNP variants from all chromosomes (no indels, and not just chromosome 22 as before), each genic unit is expanded to include the set of SNPs falling within a GENCODE-defined gene along with 20 kb flanking regions upstream and downstream of that range, and the positions are in genome build hg19 (so that the annotation positions are consistent with the build used for genotyping data in the workshop). This set of aggregation units is not filtered by CADD score or consequence. As before, the aggregation units are defined in an R dataframe. Each row of the dataframe specifies a variant (chr, pos, ref, alt) and the group identifier (group_id) it is a part of. Mutiple rows with different group identifiers can be specified to assign a variant to different groups (a variant can be assigned to mutiple genes). Begin by loading the aggregation units using TopmedPipeline::getobj(): aggfile &lt;- &quot;data/variants_by_gene.RData&quot; aggunit &lt;- TopmedPipeline::getobj(aggfile) names(aggunit) ## [1] &quot;group_id&quot; &quot;chr&quot; &quot;pos&quot; &quot;ref&quot; &quot;alt&quot; head(aggunit) ## # A tibble: 6 x 5 ## group_id chr pos ref alt ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ENSG00000131591.13 1 1025045 C T ## 2 ENSG00000169962.4 1 1265550 C T ## 3 ENSG00000205090.4 1 1472676 T C ## 4 ENSG00000171603.12 1 9788518 G A ## 5 ENSG00000204624.6 1 11593461 C T ## 6 ENSG00000270914.1 1 12068870 G A # an example of variant that is present in mutiple groups mult &lt;- aggunit %&gt;% group_by(chr, pos) %&gt;% summarise(n=n()) %&gt;% filter(n &gt; 1) inner_join(aggunit, mult[2,1:2]) ## # A tibble: 2 x 5 ## group_id chr pos ref alt ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ENSG00000187952.8 1 21742183 G A ## 2 ENSG00000227001.2 1 21742183 G A 12.2 Association testing with aggregate units We can run a burden test or SKAT on each of these units using assocTestAggregate. We define a SeqVarListIterator object where each list element is an aggregate unit. The constructor expects a GRangesList, so we use the TopmedPipeline function aggregateGRangesList to quickly convert our single dataframe to the required format. This function can account for multiallelic variants (the same chromosome, position, and ref, but different alt alleles). library(TopmedPipeline) library(SeqVarTools) gdsfile &lt;- &quot;data/1KG_phase3_subset_chr1.gds&quot; gds &lt;- seqOpen(gdsfile) annotfile &lt;- &quot;data/sample_phenotype_pcs.RData&quot; annot &lt;- getobj(annotfile) seqData &lt;- SeqVarData(gds, sampleData=annot) # subset to chromosome 1 aggunit &lt;- filter(aggunit, chr == 1) aggVarList &lt;- aggregateGRangesList(aggunit) length(aggVarList) ## [1] 127 head(names(aggVarList)) ## [1] &quot;ENSG00000131591.13&quot; &quot;ENSG00000169962.4&quot; &quot;ENSG00000205090.4&quot; ## [4] &quot;ENSG00000171603.12&quot; &quot;ENSG00000204624.6&quot; &quot;ENSG00000270914.1&quot; aggVarList[[1]] ## GRanges object with 1 range and 2 metadata columns: ## seqnames ranges strand | ref alt ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | &lt;character&gt; &lt;character&gt; ## [1] 1 1025045 * | C T ## ------- ## seqinfo: 23 sequences from an unspecified genome; no seqlengths iterator &lt;- SeqVarListIterator(seqData, variantRanges=aggVarList, verbose=FALSE) As in the previous section, we must load the null model before running the association test. if (!exists(&quot;nullmod&quot;)) { nmfile &lt;- &quot;data/null_mixed_model.RData&quot; nullmod &lt;- getobj(nmfile) } assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;Burden&quot;, AF.max=0.1, weight.beta=c(1,1)) ## # of selected samples: 100 names(assoc) ## [1] &quot;results&quot; &quot;variantInfo&quot; head(assoc$results) ## n.site n.alt n.sample.alt Score Score.SE ## ENSG00000131591.13 0 0 0 NA NA ## ENSG00000169962.4 0 0 0 NA NA ## ENSG00000205090.4 1 1 1 -0.08038064 0.08682388 ## ENSG00000171603.12 0 0 0 NA NA ## ENSG00000204624.6 0 0 0 NA NA ## ENSG00000270914.1 1 1 1 -0.05287495 0.08051531 ## Score.Stat Score.pval ## ENSG00000131591.13 NA NA ## ENSG00000169962.4 NA NA ## ENSG00000205090.4 -0.9257895 0.3545554 ## ENSG00000171603.12 NA NA ## ENSG00000204624.6 NA NA ## ENSG00000270914.1 -0.6567068 0.5113695 head(names(assoc$variantInfo)) ## [1] &quot;ENSG00000131591.13&quot; &quot;ENSG00000169962.4&quot; &quot;ENSG00000205090.4&quot; ## [4] &quot;ENSG00000171603.12&quot; &quot;ENSG00000204624.6&quot; &quot;ENSG00000270914.1&quot; head(assoc$variantInfo[[1]]) ## [1] variant.id chr pos ref alt ## [6] allele.index n.obs freq weight ## &lt;0 rows&gt; (or 0-length row.names) qqPlot(assoc$results$Score.pval) 12.3 Exercise Since we are working with a subset of the data, many of the genes listed in group_id have a very small number of variants. Create a new set of units based on position rather than gene name, using the TopmedPipeline function aggregateGRanges. Then run SKAT using those units and a SeqVarRangeIterator. "],
["annotation-solutions.html", "13 Annotation - Solutions", " 13 Annotation - Solutions Since we are working with a subset of the data, many of the genes listed in group_id have a very small number of variants. Create a new set of units based on position rather than gene name, using the TopmedPipeline function aggregateGRanges. Then run SKAT using those units and a SeqVarRangeIterator. agg2 &lt;- aggunit %&gt;% mutate(chr=factor(chr, levels=c(1:22, &quot;X&quot;))) %&gt;% distinct(chr, pos) %&gt;% group_by(chr) %&gt;% summarise(min=min(pos), max=max(pos)) head(agg2) ## # A tibble: 1 x 3 ## chr min max ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1025045 248761613 aggByPos &lt;- bind_rows(lapply(1:nrow(agg2), function(i) { data.frame(chr=agg2$chr[i], start=seq(agg2$min[i], agg2$max[i]-1e6, length.out=10), end=seq(agg2$min[i]+1e6, agg2$max[i], length.out=10)) })) %&gt;% mutate(group_id=1:n()) head(aggByPos) ## chr start end group_id ## 1 1 1025045 2025045 1 ## 2 1 28440219 29440219 2 ## 3 1 55855393 56855393 3 ## 4 1 83270568 84270568 4 ## 5 1 110685742 111685742 5 ## 6 1 138100916 139100916 6 aggVarList &lt;- aggregateGRanges(aggByPos) aggVarList[1:2] ## GRanges object with 2 ranges and 0 metadata columns: ## seqnames ranges strand ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; ## 1 1 1025045-2025045 * ## 2 1 28440219-29440219 * ## ------- ## seqinfo: 23 sequences from an unspecified genome; no seqlengths seqResetFilter(seqData, verbose=FALSE) iterator &lt;- SeqVarRangeIterator(seqData, variantRanges=aggVarList, verbose=FALSE) assoc &lt;- assocTestAggregate(iterator, nullmod, test=&quot;SKAT&quot;, AF.max=0.1, weight.beta=c(1,25)) ## # of selected samples: 100 head(assoc$results) ## n.site n.alt n.sample.alt Q_0 pval_0 err_0 ## 1 1 1 1 3.1746130 0.3545554 0 ## 2 3 11 10 4.0726476 0.8026375 0 ## 3 1 5 5 1.6067817 0.5885020 0 ## 4 2 3 3 0.8778105 0.8930184 0 ## 5 0 0 0 NA NA NA ## 6 0 0 0 NA NA NA seqClose(gds) "],
["analysis-pipeline.html", "14 Analysis Pipeline 14.1 Running on a local cluster", " 14 Analysis Pipeline The DCC’s analysis pipeline is hosted on github: https://github.com/UW-GAC/analysis_pipeline 14.1 Running on a local cluster To run a burden test on our local SGE cluster, first we create a config file and call it assoc_window_burden.config: out_prefix &quot;test&quot; gds_file &quot;testdata/1KG_phase3_subset_chr .gds&quot; phenotype_file &quot;testdata/1KG_phase3_subset_annot.RData&quot; pcrelate_file &quot;testdata/round2_pcrelate.gds&quot; pca_file &quot;testdata/round2_pcair.RData&quot; sample_include_file &quot;testdata/sample_include.RData&quot; variant_include_file &quot;testdata/variant_include_chr .RData&quot; outcome outcome covars &quot;sex&quot; n_pcs 4 alt_freq_max &quot;0.1&quot; test &quot;burden&quot; test_type &quot;score&quot; We will use the python script assoc.py to submit all jobs. First we look at the available options: setenv PIPELINE /projects/topmed/working_code/analysis_pipeline $PIPELINE/assoc.py --help Let’s run a sliding window test on chromosomes 1-10. We will also specify the cluster type, although UW_Cluster is actually the default. The cluster file is a JSON file that can override default values for the cluster configuration. In this case, we are changing the memory requirements for each job to only reserve a small amount of memory on each cluster node. The last argument is our config file. First, we print the commands that will be be run without actually submitting jobs: $PIPELINE/assoc.py \\ --chromosomes 1-10 \\ --cluster_type UW_Cluster \\ --cluster_file test_cluster_cfg.json \\ --print_only \\ window \\ testdata/assoc_window_burden.config The default segment length is 10,000 kb, but we can change that to 50,000 kb when we submit: $PIPELINE/assoc.py \\ --chromosomes 1-10 \\ --cluster_type UW_Cluster \\ --cluster_file test_cluster_cfg.json \\ --segment_length 50000 \\ window \\ testdata/assoc_window_burden.config We can use the qstat command to check the status of our jobs. "],
["analysis-commons.html", "15 Analysis Commons 15.1 Outline 15.2 Web Interface and Running an Analysis Application 15.3 Command line interface 15.4 Writing your own Apps", " 15 Analysis Commons 15.1 Outline Introduction to web-interface Running a single variant analysis Workflows and monitoring jobs Running aggregate tests (SKAT) Run batch jobs from the command line Writing your own Apps 15.2 Web Interface and Running an Analysis Application 15.2.1 Exercise 1) Run a single variant analysis. Log into http://dnanexus.com using the Analysis Commons user name and password listed on the website. Should be in the form of Username:topmed_# and Password:TOPMed_#. Ignore warning about default billing account. 15.2.1.1 Part 1: Run null model Navigate to and select (wgs:tools/genesis_nullmodel) File inputs: * phenofile -&gt; phenotype/1KG_pheno.csv * kinship -&gt; kinship/1KG_kins.Rda Parameter inputs: * output folder: /output/YOURFOLDERNAME * outcome (Column name of the outcome variable): outcome * covariates (case sepecific): Population,sex * prefix for output filename: nullmodel_outcome * pheno_id: sample.id * Note: Other options can be left as their defaults * Note: The job may finish instantaneously if you don’t change the output file name. It knows that you are running the exact same job and will just reuse results from previous analyses. 15.2.1.2 Part 2: Run association tests Navigate to and select (wgs:tools/genesis_tests) File inputs: * null_model -&gt; /output/YOURFOLDERNAME/nullmodel_outcome.Rda (output from part1. If yours has not completed, you can select output/DEMO/nullmodel_outcome.Rda) * genotypes -&gt; genotypes/GDS/1KG_phase3_subset_chr1.gds Parameter inputs: * output folder: output/YOURFOLDERNAME * prefix for output filename: chr1_single * test_type: Single * Note: Other options can be left as their defaults 15.2.2 Exercise 2) Run SKAT test grouping variants into gene transcript regions and limit the variants to those with a CADD phred score &gt; 2 and MAF &lt;= 5%. File inputs: * null_model -&gt; /output/YOURFOLDERNAME/nullmodel_outcome.Rda (output from part1. If yours has not completed, you can select output/DEMO/nullmodel_outcome.Rda) * genotypefile -&gt; genotypes/1KG_phase3_subset_chr1.gds * annotation -&gt; annotation/1KG_annotation_CHR1.txt * genefile -&gt; aggregation/AggUnit_CHR1_ucscgene.csv Parameter inputs: * output folder: output/YOURFOLDERNAME * outputfilename: skat_chr1_geneBased_CADDgt2 * test_type: SKAT * snp_filter: CADD_phred&gt;2 * min_mac:0 * top_maf: 0.05 * weights: c(1,25) 15.3 Command line interface References: * Command Line Interface Quickstart * Index of dx commands 15.3.1 Log in to AWI Replace topmed_## with the user ID from your handout $ ssh topmed_##@34.208.147.133 You will be prompted for your password, e.g. TOPMed_## (Note capitalization) _Please ignore login warnings $ source /usr/local/dx-toolkit/environment $ dx login --timeout 2h Enter the following at the prompts username: topmed_## password: TOPMed_## project:wgs ( type 0 to select wgs ) You can select or change project once you are logged in $ dx select wgs 15.3.2 Exercise 3) Navigate directories, make output directory, examine files File paths: &lt;project&gt;:/path/to/file.txt Example: wgs:/phenotypes/1KG_pheno.csv List directory contents: $ dx select wgs $ dx ls $ dx ls /tools $ dx ls wgs:/tools Get results from project $ dx download wgs:/phenotype/1KG_pheno.csv $ ls $ head 1KG_pheno.csv 15.3.3 Exercise 4) Run single variant analysis from command line using bash script Open the single_multichrom.sh bash script and edit to replace the output directory “YOURNAME” to your folder $ dx describe tools/genesis_tests Either edit using nano $ nano single_multichrom.sh Run the App. Will loop over 2 chromosomes running the single variant analyses $ ./single_multichrom.sh 15.4 Writing your own Apps 15.4.1 Exercise 5) Write an App that creates phenotype residuals and performs an inverse normal transform Use app wizard to create template $ dx-app-wizard App Name: make_residuals Title []: Create inverse normal transformed residuals 1st input name (&lt;ENTER&gt; to finish): phenofile Label (optional human-readable name) []: CSV phenotype file Choose a class (&lt;TAB&gt; twice for choices): file This is an optional parameter [y/n]: n 2nd input name (&lt;ENTER&gt; to finish): model Label (optional human-readable name) []: model for creating residuals (e.g. outcome~sex+Population ) Choose a class (&lt;TAB&gt; twice for choices): string This is an optional parameter [y/n]: n 3rd input name (&lt;ENTER&gt; to finish): prefix Label (optional human-readable name) []: Output filename prefix Choose a class (&lt;TAB&gt; twice for choices): string This is an optional parameter [y/n]: n 4th input name (&lt;ENTER&gt; to finish): &lt;ENTER&gt; 1st output name (&lt;ENTER&gt; to finish): output Label (optional human-readable name) []: Choose a class (&lt;TAB&gt; twice for choices): file Timeout policy [48h]: 1h Programming language: bash *Use defaults for other options* Look at the files created by the wizard cd make_residuals/ ls more dxapp.json Edit App executable to run an R script $ vi src/make_residuals.sh main() { echo &quot;Value of phenofile: &#39;$phenofile&#39;&quot; echo &quot;Value of model: &#39;$model&#39;&quot; echo &quot;Value of prefix: &#39;$prefix&#39;&quot; dx download &quot;$phenofile&quot; -o phenofile ## ADD THIS LINE ## Rscript /make_resid.R $model output=$(dx upload output --brief) ## ADD THIS LINE ## dx mv ${output} ${prefix}.csv dx-jobutil-add-output output &quot;$output&quot; --class=file } Create an R script that does the ‘work’ $ vi resources/make_resid.R args&lt;-commandArgs(TRUE) model &lt;- as.formula(args[1]) print(model) pheno = read.csv(&quot;phenofile&quot;,as.is=T) pheno$resid = residuals(lm(model,data=pheno)) pheno$invnt_resid = with(pheno,qnorm((rank(resid,na.last=&quot;keep&quot;)-0.5)/sum(!is.na(resid)))) write.csv(pheno,file=&quot;output&quot;,row.names=F) Build the App $ dx build -f make_residuals --destination=output/YOURNAME/make_residuals Run the App $ dx run output/YOURNAME/make_residuals -iphenofile=phenotype/1KG_pheno.csv \\ -imodel=outcome~sex+Population -iprefix=1kg_pheno_invnt \\ --destination=output/YOURNAME --yes Monitor Progress $ dx watch jobid 15.4.2 Optional Exercise 6) Make QQ plot Make QQ plot of your single variant results. Select results from the multiple chromosome run (chr21 and chr22). You will need to identify the p-value column name. To view the results file try these options: dx download to download the results for viewing. View file through web interface using Visualize ( next to Monitor near top of the page ) and select Gzipped File Previewer Pipe zipped file though regular linux commands dx cat to view column names $ dx cat output/folder/file | gunzip | head Once you know the name of the p-value column, run qqplot first through web interface and then try running interactivly from the web interface then from the command line. $ dx run tools/qqplot Note: the plot label must not contain spaces. 15.4.3 Optional Exercise 8) Create a regional association plot using LD extracted from your data set This process requires two steps, one to extract the LD for all variants in the region and one to create the plot. Sequencing data sets often contain variants not in external refernce panels, so it is helpful to create your own LD reference. Step 1: Run GILD (GDS Into LD) App (tools/gild_v1) File inputs: * gds_file -&gt; genotypes/1KG_phase3_subset_chr22.gds Parameter inputs: lead_snp -&gt; 22:17105517 start_pos -&gt; 1 stop_pos -&gt; 51237069 label for results file -&gt; “LD_chr22” output_LD_filename output/YOURNAME Note: this can take 10-15 mins to complete Step 2: Run AssocPlot (tools/assocplot) File inputs: datafile -&gt; single variant association results output for chr22 ldfile -&gt; Output file from Step 1 with .ld suffix Parameter inputs (Minimum required to have the App run successfully with GENESIS output): Output folder -&gt; output/YOURNAME Marker Column Name -&gt; snpID P value Column Name -&gt; Score.pval Index SNP -&gt; 22:17105517 "]
]
